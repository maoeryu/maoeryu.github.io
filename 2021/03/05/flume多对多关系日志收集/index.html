<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="根据需求,利用flume实现1个agent时,多source&#x2F;多channel&#x2F;多sink关系日志收集.日常工作中使用到的各组件类型有,exec&#x2F;taildir soure,memory&#x2F;file channel,kafka&#x2F;hdfs sink,数据流如下,">
<meta property="og:type" content="article">
<meta property="og:title" content="flume多对多关系日志收集">
<meta property="og:url" content="https://maoeryu.github.io/2021/03/05/flume%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="根据需求,利用flume实现1个agent时,多source&#x2F;多channel&#x2F;多sink关系日志收集.日常工作中使用到的各组件类型有,exec&#x2F;taildir soure,memory&#x2F;file channel,kafka&#x2F;hdfs sink,数据流如下,">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_1.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_11.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_12.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_21.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_22.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_23.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_31.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_32.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_33.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_34.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_41.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_42.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_43.png">
<meta property="og:image" content="https://maoeryu.github.io/images/flume_44.png">
<meta property="article:published_time" content="2021-03-04T16:00:00.000Z">
<meta property="article:modified_time" content="2022-07-26T02:52:17.193Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="logstash">
<meta property="article:tag" content="flume">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://maoeryu.github.io/images/flume_1.png">


<link rel="canonical" href="https://maoeryu.github.io/2021/03/05/flume%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>flume多对多关系日志收集 | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E5%87%86%E5%A4%87"><span class="nav-number">1.</span> <span class="nav-text">测试准备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9C%E7%A8%8B%E9%9B%86%E7%BE%A41"><span class="nav-number">1.1.</span> <span class="nav-text">远程集群1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9C%E7%A8%8B%E9%9B%86%E7%BE%A42"><span class="nav-number">1.2.</span> <span class="nav-text">远程集群2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tomcat%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="nav-number">1.3.</span> <span class="nav-text">tomcat服务器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flume%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">1.4.</span> <span class="nav-text">flume启动命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">1.5.</span> <span class="nav-text">kafka消费者启动命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E5%9C%BA%E6%99%AF"><span class="nav-number">1.6.</span> <span class="nav-text">测试场景</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95"><span class="nav-number">2.</span> <span class="nav-text">测试</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF1"><span class="nav-number">2.1.</span> <span class="nav-text">场景1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#sink%E9%85%8D%E7%BD%AE"><span class="nav-number">2.1.1.</span> <span class="nav-text">sink配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%88%AB%E5%90%AF%E5%8A%A8kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%8F%8Aflume"><span class="nav-number">2.1.2.</span> <span class="nav-text">分别启动kafka消费者及flume</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Bkafka%E6%B6%88%E8%B4%B9%E6%83%85%E5%86%B5"><span class="nav-number">2.1.3.</span> <span class="nav-text">查看kafka消费情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF2"><span class="nav-number">2.2.</span> <span class="nav-text">场景2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAhive%E8%A1%A8"><span class="nav-number">2.2.1.</span> <span class="nav-text">创建hive表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sink%E9%85%8D%E7%BD%AE-1"><span class="nav-number">2.2.2.</span> <span class="nav-text">sink配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%88%AB%E5%90%AF%E5%8A%A8kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%8F%8Aflume-1"><span class="nav-number">2.2.3.</span> <span class="nav-text">分别启动kafka消费者及flume</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Bkafka%E6%B6%88%E8%B4%B9%E6%83%85%E5%86%B5-hdfs%E6%96%87%E4%BB%B6"><span class="nav-number">2.2.4.</span> <span class="nav-text">查看kafka消费情况&#x2F;hdfs文件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF3"><span class="nav-number">2.3.</span> <span class="nav-text">场景3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAhive%E8%A1%A8-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">创建hive表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sink%E9%85%8D%E7%BD%AE-2"><span class="nav-number">2.3.2.</span> <span class="nav-text">sink配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8flume"><span class="nav-number">2.3.3.</span> <span class="nav-text">启动flume</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Bhdfs%E6%96%87%E4%BB%B6-hive%E8%A1%A8%E6%95%B0%E6%8D%AE"><span class="nav-number">2.3.4.</span> <span class="nav-text">查看hdfs文件&#x2F;hive表数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E5%88%87%E6%8D%A2hadoop-active%E8%8A%82%E7%82%B9"><span class="nav-number">2.3.5.</span> <span class="nav-text">手动切换hadoop active节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE"><span class="nav-number">2.3.6.</span> <span class="nav-text">查看数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%99%84%E5%BD%951"><span class="nav-number">3.</span> <span class="nav-text">附录1</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFSEventSink"><span class="nav-number">3.1.</span> <span class="nav-text">HDFSEventSink</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B0%E5%A2%9E%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F-%E6%8F%8F%E8%BF%B0hdfs-ha%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">3.1.1.</span> <span class="nav-text">新增成员变量,描述hdfs ha的环境变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%A8configure%E6%96%B9%E6%B3%95%E4%B8%AD%E5%88%9D%E5%A7%8B%E5%8C%96hdfsEnv%E9%85%8D%E7%BD%AE"><span class="nav-number">3.1.2.</span> <span class="nav-text">在configure方法中初始化hdfsEnv配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B0%E5%A2%9E%E6%96%B9%E6%B3%95-%E5%88%9D%E5%A7%8B%E5%8C%96hdfs%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="nav-number">3.2.</span> <span class="nav-text">新增方法,初始化hdfs环境配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9initializeBucketWriter%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.1.</span> <span class="nav-text">修改initializeBucketWriter方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BucketWriter"><span class="nav-number">3.3.</span> <span class="nav-text">BucketWriter</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B0%E5%A2%9E%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F-%E6%8F%8F%E8%BF%B0hdfs-ha%E9%85%8D%E7%BD%AE"><span class="nav-number">3.3.1.</span> <span class="nav-text">新增成员变量,描述hdfs ha配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#BucketWriter%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95%E4%B8%AD-%E5%A2%9E%E5%8A%A0Configuration%E5%8F%82%E6%95%B0%E5%B9%B6%E8%B5%8B%E5%80%BC"><span class="nav-number">3.3.2.</span> <span class="nav-text">BucketWriter构造方法中,增加Configuration参数并赋值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%A8%E9%87%8A%E6%8E%89open%E6%96%B9%E6%B3%95%E4%B8%AD%E5%88%9D%E5%A7%8B%E5%8C%96Configuration%E5%8F%98%E9%87%8F"><span class="nav-number">3.3.3.</span> <span class="nav-text">注释掉open方法中初始化Configuration变量</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%99%84%E5%BD%952"><span class="nav-number">4.</span> <span class="nav-text">附录2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#logstash%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB%E5%AF%BC%E5%85%A5%E5%88%B0HDFS-HDFS"><span class="nav-number">4.1.</span> <span class="nav-text">logstash多对多关系导入到HDFS&#x2F;HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BDlogstash"><span class="nav-number">4.1.1.</span> <span class="nav-text">下载logstash</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%BB%E5%8A%A0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">4.2.</span> <span class="nav-text">添加配置文件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hive%E5%88%9B%E5%BB%BA%E8%A1%A8%E5%8F%8A%E5%88%86%E5%8C%BA-%E5%81%9C%E6%AD%A2tomcat-%E6%A0%B8%E5%AF%B9%E6%97%A5%E5%BF%97"><span class="nav-number">4.2.1.</span> <span class="nav-text">hive创建表及分区,停止tomcat,核对日志</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">221</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2021/03/05/flume%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          flume多对多关系日志收集
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-05 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-05T00:00:00+08:00">2021-03-05</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-07-26 10:52:17" itemprop="dateModified" datetime="2022-07-26T10:52:17+08:00">2022-07-26</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%8F%E5%90%8C%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">协同框架</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>根据需求,利用flume实现1个agent时,多source/多channel/多sink关系日志收集.<br>日常工作中使用到的各组件类型有,<br>exec/taildir soure,memory/file channel,kafka/hdfs sink,<br>数据流如下,</p>
<img src="/images/flume_1.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<span id="more"></span>
<h2 id="测试准备"><a href="#测试准备" class="headerlink" title="测试准备"></a>测试准备</h2><h3 id="远程集群1"><a href="#远程集群1" class="headerlink" title="远程集群1"></a>远程集群1</h3><p>ip:xxx<br>namespace:ns1<br>kafka:xxx</p>
<h3 id="远程集群2"><a href="#远程集群2" class="headerlink" title="远程集群2"></a>远程集群2</h3><p>ip:xxx<br>namespace:ns2<br>kafka:xxx</p>
<h3 id="tomcat服务器"><a href="#tomcat服务器" class="headerlink" title="tomcat服务器"></a>tomcat服务器</h3><p>ip:xxx<br>path1:/data/xxx/logs1/app*.log<br>path2:/data/xxx/logs2/app*.log</p>
<p>服务器已安装flume-1.7.0,使用shell脚本模拟服务器日志,<br>日志包含3个字段,id/name/age,其中字段分隔符为\t,<br>shell脚本内容如下,分别打印奇偶数到两个文件.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>((i=1;i&lt;=1000000;i++));<span class="keyword">do</span></span><br><span class="line"><span class="keyword">if</span> [ $(expr <span class="variable">$i</span> % 2) -eq 0 ];<span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span>$<span class="string">&#x27;\t&#x27;</span><span class="variable">$&#123;i&#125;</span>$<span class="string">&#x27;tom\t&#x27;</span><span class="variable">$&#123;i&#125;</span> &gt;&gt; /data/xxx/logs1/app.log;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span>$<span class="string">&#x27;\t&#x27;</span><span class="variable">$&#123;i&#125;</span>$<span class="string">&#x27;tom\t&#x27;</span><span class="variable">$&#123;i&#125;</span> &gt;&gt; /data/xxx/logs2/app.log;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">sleep 5s;</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>日志内容如下,</p>
<table>
<thead>
<tr>
<th align="left">id</th>
<th align="left">name</th>
<th align="left">age</th>
</tr>
</thead>
<tbody><tr>
<td align="left">2</td>
<td align="left">2tom</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">4tom</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left">6</td>
<td align="left">6tom</td>
<td align="left">6</td>
</tr>
</tbody></table>
<h3 id="flume启动命令"><a href="#flume启动命令" class="headerlink" title="flume启动命令"></a>flume启动命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/data/flume-1.7.0/bin/flume-ng agent -c /data/flume-1.7.0/conf -f /data/flume-1.7.0/conf/kafka-xxx.properties -n a1 -Dflume.monitoring.type=com.flume.test1.FlumeSinkMonitor -Dflume.monitoring.log4j.prop=/data/flume-1.7.0/conf/sink-monitor-xxx.properties -Dflume.monitoring.interval=12000 &gt;&gt; /data/flume-1.7.0/logs/kafka-xxx.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<h3 id="kafka消费者启动命令"><a href="#kafka消费者启动命令" class="headerlink" title="kafka消费者启动命令"></a>kafka消费者启动命令</h3><p>/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server xxx:9092 --topic xxx</p>
<h3 id="测试场景"><a href="#测试场景" class="headerlink" title="测试场景"></a>测试场景</h3><p>source为taildir,channel为file,sink如下,</p>
<ul>
<li>kafka/kafka</li>
<li>kafka/HDFS</li>
<li>HDFS/HDFS</li>
</ul>
<p>source/channel公共配置如下,</p>
<p>a1.sources = r1 r2<br>a1.channels = c1 c2<br>a1.sinks = k1 k2</p>
<p># 这里是第一个流的配置<br>a1.sources.r1.channels = c1<br>a1.sinks.k1.channel = c1</p>
<p># 这里是第二个流的配置<br>a1.sources.r2.channels = c2<br>a1.sinks.k2.channel = c2</p>
<p>#the source1<br>a1.sources.r1.type = com.xxx.flume.source.TaildirSource<br>a1.sources.r1.positionFile = /data/flume-1.7.0/.r1_position.json<br>a1.sources.r1.filegroups = f1<br>a1.sources.r1.filegroups.f1 = /data/xxx/logs1/app.*.log<br>a1.sources.r1.fileHeader = true<br>a1.sources.r1.maxBatchCount = 1000</p>
<p>#the channel1<br>a1.channels.c1.type = file<br>a1.channels.c1.checkpointDir = /data/flume-1.7.0/.r1_checkpoint/<br>a1.channels.c1.dataDirs = /data/flume-1.7.0/.r1_data/<br>a1.channels.c1.maxFileSize = 1000000000</p>
<p>#the source2<br>a1.sources.r2.type = com.xxx.flume.source.TaildirSource<br>a1.sources.r2.positionFile = /data/flume-1.7.0/.r2_position.json<br>a1.sources.r2.filegroups = f1<br>a1.sources.r2.filegroups.f1 = /data/xxx/logs2/app.*.log<br>a1.sources.r2.fileHeader = true<br>a1.sources.r2.maxBatchCount = 1000</p>
<p>#the channel2<br>a1.channels.c2.type = file<br>a1.channels.c2.checkpointDir = /data/flume-1.7.0/.r2_checkpoint/<br>a1.channels.c2.dataDirs = /data/flume-1.7.0/.r2_data/<br>a1.channels.c2.maxFileSize = 1000000000</p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="场景1"><a href="#场景1" class="headerlink" title="场景1"></a>场景1</h3><h4 id="sink配置"><a href="#sink配置" class="headerlink" title="sink配置"></a>sink配置</h4><p># the sink1<br>a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink<br>a1.sinks.k1.kafka.topic = xx1<br>a1.sinks.k1.kafka.bootstrap.servers = xxx:9092</p>
<p># the sink2<br>a1.sinks.k2.type = org.apache.flume.sink.kafka.KafkaSink<br>a1.sinks.k2.kafka.topic = xx2<br>a1.sinks.k2.kafka.bootstrap.servers = xxx:9092</p>
<h4 id="分别启动kafka消费者及flume"><a href="#分别启动kafka消费者及flume" class="headerlink" title="分别启动kafka消费者及flume"></a>分别启动kafka消费者及flume</h4><h4 id="查看kafka消费情况"><a href="#查看kafka消费情况" class="headerlink" title="查看kafka消费情况"></a>查看kafka消费情况</h4><p>两个topic消费的数据分别是对应的日志,测试正常.</p>
<img src="/images/flume_11.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_12.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="场景2"><a href="#场景2" class="headerlink" title="场景2"></a>场景2</h3><h4 id="创建hive表"><a href="#创建hive表" class="headerlink" title="创建hive表"></a>创建hive表</h4><p>ns1集群中创建hive分区表,将hadoop配置文件core-sie.xml/hdfs-site.xml复制到flume conf目录下.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition<span class="operator">=</span><span class="literal">true</span>; </span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> IF <span class="keyword">EXISTS</span> default.flumemultest;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> default.flumemultest</span><br><span class="line">(</span><br><span class="line"> id <span class="type">int</span>,</span><br><span class="line"> name string ,</span><br><span class="line"> age <span class="type">int</span></span><br><span class="line">)partitioned <span class="keyword">by</span> (dt string)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> TEXTFILE ;</span><br><span class="line"></span><br><span class="line"><span class="comment">--添加分区</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> default.flumemultest <span class="keyword">add</span> <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;20200521&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h4 id="sink配置-1"><a href="#sink配置-1" class="headerlink" title="sink配置"></a>sink配置</h4><p># the sink1<br>a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink<br>a1.sinks.k1.kafka.topic = xx1<br>a1.sinks.k1.kafka.bootstrap.servers = xxx:9092</p>
<p>#the sink2<br>a1.sinks.k2.type = hdfs<br>a1.sinks.k2.hdfs.path = hdfs://ns1/user/hive/warehouse/flumemultest/dt=%Y%m%d<br>a1.sinks.k2.hdfs.filePrefix = 108_%Y%m%d%H%M<br>a1.sinks.k2.hdfs.fileSuffix = .log.xxx<br>a1.sinks.k2.hdfs.inUsePrefix = .<br>a1.sinks.k2.hdfs.rollSize = 0<br>a1.sinks.k2.hdfs.rollCount = 0<br>a1.sinks.k2.hdfs.rollInterval = 600<br>a1.sinks.k2.hdfs.minBlockReplicas=1<br>a1.sinks.k2.hdfs.batchSize = 2000<br>a1.sinks.k2.hdfs.batchDurationMillis = 10000<br>a1.sinks.k2.hdfs.round = true<br>a1.sinks.k2.hdfs.roundUnit = minute<br>a1.sinks.k2.hdfs.roundValue = 10<br>a1.sinks.k2.hdfs.threadsPoolSize = 25<br>a1.sinks.k2.hdfs.useLocalTimeStamp = true<br>a1.sinks.k2.hdfs.fileType = DataStream<br>a1.sinks.k2.hdfs.callTimeout = 300000<br>a1.sinks.k2.hdfs.idleTimeout = 600<br>a1.sinks.k2.hdfs.rollTimerPoolSize = 10</p>
<h4 id="分别启动kafka消费者及flume-1"><a href="#分别启动kafka消费者及flume-1" class="headerlink" title="分别启动kafka消费者及flume"></a>分别启动kafka消费者及flume</h4><h4 id="查看kafka消费情况-hdfs文件"><a href="#查看kafka消费情况-hdfs文件" class="headerlink" title="查看kafka消费情况/hdfs文件"></a>查看kafka消费情况/hdfs文件</h4><p>该topic消费的数据和hive表中的数据分别是对应的日志,测试正常.</p>
<img src="/images/flume_21.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_22.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_23.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="场景3"><a href="#场景3" class="headerlink" title="场景3"></a>场景3</h3><p>因flume只支持一个hadoop HA集群,需要修改源码来识别两个HA集群的namespace,修改源码见附录1.</p>
<h4 id="创建hive表-1"><a href="#创建hive表-1" class="headerlink" title="创建hive表"></a>创建hive表</h4><p>分别在两个集群中创建hive分区表,不需要复制hadoop配置文件到flume conf目录下.</p>
<h4 id="sink配置-2"><a href="#sink配置-2" class="headerlink" title="sink配置"></a>sink配置</h4><p>#the sink1<br>a1.sinks.k1.type = com.xxx.flume.sink.hdfs.HDFSEventSink<br>a1.sinks.k1.hdfs.path = hdfs://ns2/user/hive/warehouse/flumemultest/dt=%Y%m%d<br>a1.sinks.k1.hdfs.filePrefix = 108_%Y%m%d%H%M<br>a1.sinks.k1.hdfs.fileSuffix = .log.xxx<br>a1.sinks.k1.hdfs.inUsePrefix = .<br>a1.sinks.k1.hdfs.rollSize = 0<br>a1.sinks.k1.hdfs.rollCount = 0<br>a1.sinks.k1.hdfs.rollInterval = 600<br>a1.sinks.k1.hdfs.minBlockReplicas=1<br>a1.sinks.k1.hdfs.batchSize = 2000<br>a1.sinks.k1.hdfs.batchDurationMillis = 10000<br>a1.sinks.k1.hdfs.round = true<br>a1.sinks.k1.hdfs.roundUnit = minute<br>a1.sinks.k1.hdfs.roundValue = 10<br>a1.sinks.k1.hdfs.threadsPoolSize = 25<br>a1.sinks.k1.hdfs.useLocalTimeStamp = true<br>a1.sinks.k1.hdfs.fileType = DataStream<br>a1.sinks.k1.hdfs.callTimeout = 300000<br>a1.sinks.k1.hdfs.idleTimeout = 600<br>a1.sinks.k1.hdfs.rollTimerPoolSize = 10</p>
<p>#<strong><em>以下是新增的参数,hdfs.isHaEnv值为false表示不是HA集群</em></strong><br>a1.sinks.k1.hdfs.isHaEnv = true<br>a1.sinks.k1.hdfs.namenodeserver = ns2<br>a1.sinks.k1.hdfs.active.host = master1<br>a1.sinks.k1.hdfs.active.port = 8020<br>a1.sinks.k1.hdfs.active.name = nn1<br>a1.sinks.k1.hdfs.standby.host = master2<br>a1.sinks.k1.hdfs.standby.port = 8020<br>a1.sinks.k1.hdfs.standby.name = nn2</p>
<p>#the sink2<br>a1.sinks.k2.type = com.xxx.flume.sink.hdfs.HDFSEventSink<br>a1.sinks.k2.hdfs.path = hdfs://ns1/user/hive/warehouse/flumemultest/dt=%Y%m%d<br>a1.sinks.k2.hdfs.filePrefix = 108_%Y%m%d%H%M<br>a1.sinks.k2.hdfs.fileSuffix = .log.xxx<br>a1.sinks.k2.hdfs.inUsePrefix = .<br>a1.sinks.k2.hdfs.rollSize = 0<br>a1.sinks.k2.hdfs.rollCount = 0<br>a1.sinks.k2.hdfs.rollInterval = 600<br>a1.sinks.k2.hdfs.minBlockReplicas=1<br>a1.sinks.k2.hdfs.batchSize = 2000<br>a1.sinks.k2.hdfs.batchDurationMillis = 10000<br>a1.sinks.k2.hdfs.round = true<br>a1.sinks.k2.hdfs.roundUnit = minute<br>a1.sinks.k2.hdfs.roundValue = 10<br>a1.sinks.k2.hdfs.threadsPoolSize = 25<br>a1.sinks.k2.hdfs.useLocalTimeStamp = true<br>a1.sinks.k2.hdfs.fileType = DataStream<br>a1.sinks.k2.hdfs.callTimeout = 300000<br>a1.sinks.k2.hdfs.idleTimeout = 600<br>a1.sinks.k2.hdfs.rollTimerPoolSize = 10</p>
<p>#<strong><em>以下是新增的参数,hdfs.isHaEnv值为false表示不是HA集群</em></strong><br>a1.sinks.k2.hdfs.isHaEnv = true<br>a1.sinks.k2.hdfs.namenodeserver = ns1<br>a1.sinks.k2.hdfs.active.host = xxx1<br>a1.sinks.k2.hdfs.active.port = 8020<br>a1.sinks.k2.hdfs.active.name = nn1<br>a1.sinks.k2.hdfs.standby.host = xxx2<br>a1.sinks.k2.hdfs.standby.port = 8020<br>a1.sinks.k2.hdfs.standby.name = nn2</p>
<h4 id="启动flume"><a href="#启动flume" class="headerlink" title="启动flume"></a>启动flume</h4><h4 id="查看hdfs文件-hive表数据"><a href="#查看hdfs文件-hive表数据" class="headerlink" title="查看hdfs文件/hive表数据"></a>查看hdfs文件/hive表数据</h4><p>两个hive表中的数据分别是对应的日志,测试正常.</p>
<img src="/images/flume_31.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_32.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_33.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_34.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<h4 id="手动切换hadoop-active节点"><a href="#手动切换hadoop-active节点" class="headerlink" title="手动切换hadoop active节点"></a>手动切换hadoop active节点</h4><p>hdfs haadmin -failover nn1 nn2</p>
<h4 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h4><p>停止tomcat服务器,核对日志条数,hive中数据与日志数据一致,无数据丢失,测试正常.</p>
<h2 id="附录1"><a href="#附录1" class="headerlink" title="附录1"></a>附录1</h2><p>修改flume源码,<br>下载flume-1.7.0源码,将<code>flume-hdfs-sink</code>模块源文件复制到自己的项目中,然后修改<code>HDFSEventSink</code>和<code>BucketWriter</code>两个java文件.</p>
<h3 id="HDFSEventSink"><a href="#HDFSEventSink" class="headerlink" title="HDFSEventSink"></a>HDFSEventSink</h3><h4 id="新增成员变量-描述hdfs-ha的环境变量"><a href="#新增成员变量-描述hdfs-ha的环境变量" class="headerlink" title="新增成员变量,描述hdfs ha的环境变量"></a>新增成员变量,描述hdfs ha的环境变量</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Configuration hdfsEnv;</span><br></pre></td></tr></table></figure>

<h4 id="在configure方法中初始化hdfsEnv配置"><a href="#在configure方法中初始化hdfsEnv配置" class="headerlink" title="在configure方法中初始化hdfsEnv配置"></a>在configure方法中初始化hdfsEnv配置</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//新增代码,如果是ha架构,初始化hdfsEnv配置</span></span><br><span class="line">hdfsEnv = <span class="keyword">new</span> Configuration();</span><br><span class="line"><span class="keyword">if</span> (context.getBoolean(<span class="string">&quot;hdfs.isHaEnv&quot;</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">  initHdfsEvn(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="新增方法-初始化hdfs环境配置"><a href="#新增方法-初始化hdfs环境配置" class="headerlink" title="新增方法,初始化hdfs环境配置"></a>新增方法,初始化hdfs环境配置</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initHdfsEvn</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">  String nns = Preconditions.checkNotNull(context.getString(<span class="string">&quot;hdfs.namenodeserver&quot;</span>), <span class="string">&quot;namenodeserver is required&quot;</span>);</span><br><span class="line">  String active_name = Preconditions.checkNotNull(context.getString(<span class="string">&quot;hdfs.active.name&quot;</span>), <span class="string">&quot;actice.name is required&quot;</span>);</span><br><span class="line">  String active_host = Preconditions.checkNotNull(context.getString(<span class="string">&quot;hdfs.active.host&quot;</span>), <span class="string">&quot;actice.host is required&quot;</span>);</span><br><span class="line">  String active_port = Preconditions.checkNotNull(context.getString(<span class="string">&quot;hdfs.active.port&quot;</span>), <span class="string">&quot;actice.port is required&quot;</span>);</span><br><span class="line">  String standby_name = Preconditions.checkNotNull( context.getString(<span class="string">&quot;hdfs.standby.name&quot;</span>), <span class="string">&quot;standby.name is required&quot;</span>);</span><br><span class="line">  String standby_host = Preconditions.checkNotNull(context.getString(<span class="string">&quot;hdfs.standby.host&quot;</span>), <span class="string">&quot;standby.host is required&quot;</span>);</span><br><span class="line">  String standby_port = Preconditions.checkNotNull(context.getString(<span class="string">&quot;hdfs.standby.port&quot;</span>), <span class="string">&quot;standby.port is required&quot;</span>);</span><br><span class="line">  hdfsEnv.set(<span class="string">&quot;fs.defaultFS&quot;</span>, String.format(<span class="string">&quot;hdfs://%s&quot;</span>, nns));</span><br><span class="line">  hdfsEnv.set(<span class="string">&quot;dfs.nameservices&quot;</span>, nns);</span><br><span class="line">  hdfsEnv.set(String.format(<span class="string">&quot;dfs.ha.namenodes.%s&quot;</span>,nns), String.format(<span class="string">&quot;%s,%s&quot;</span>, active_name, standby_name));</span><br><span class="line">  hdfsEnv.set(String.format(<span class="string">&quot;dfs.namenode.rpc-address.%s.%s&quot;</span>, nns, active_name), String.format(<span class="string">&quot;%s:%s&quot;</span>, active_host, active_port));</span><br><span class="line">  hdfsEnv.set(String.format(<span class="string">&quot;dfs.namenode.rpc-address.%s.%s&quot;</span>, nns, standby_name), String.format(<span class="string">&quot;%s:%s&quot;</span>,standby_host, standby_port));</span><br><span class="line">  hdfsEnv.set(String.format(<span class="string">&quot;dfs.client.failover.proxy.provider.%s&quot;</span>, nns), <span class="string">&quot;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&quot;</span>);</span><br><span class="line">  hdfsEnv.setBoolean(<span class="string">&quot;fs.automatic.close&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="修改initializeBucketWriter方法"><a href="#修改initializeBucketWriter方法" class="headerlink" title="修改initializeBucketWriter方法"></a>修改initializeBucketWriter方法</h4><p>在初始化bucketWriter方法时,增加hdfsEnv参数.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BucketWriter bucketWriter = <span class="keyword">new</span> BucketWriter(rollInterval,</span><br><span class="line">rollSize, rollCount,</span><br><span class="line">batchSize, context, realPath, realName, inUsePrefix, inUseSuffix,</span><br><span class="line">suffix, codeC, compType, hdfsWriter, timedRollerPool,</span><br><span class="line">privExecutor, sinkCounter, idleTimeout, closeCallback,</span><br><span class="line">lookupPath, callTimeout, callTimeoutPool, retryInterval,</span><br><span class="line">tryCount, hdfsEnv);</span><br></pre></td></tr></table></figure>

<h3 id="BucketWriter"><a href="#BucketWriter" class="headerlink" title="BucketWriter"></a>BucketWriter</h3><h4 id="新增成员变量-描述hdfs-ha配置"><a href="#新增成员变量-描述hdfs-ha配置" class="headerlink" title="新增成员变量,描述hdfs ha配置"></a>新增成员变量,描述hdfs ha配置</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Configuration config;</span><br></pre></td></tr></table></figure>

<h4 id="BucketWriter构造方法中-增加Configuration参数并赋值"><a href="#BucketWriter构造方法中-增加Configuration参数并赋值" class="headerlink" title="BucketWriter构造方法中,增加Configuration参数并赋值"></a>BucketWriter构造方法中,增加Configuration参数并赋值</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.config = config;</span><br></pre></td></tr></table></figure>

<h4 id="注释掉open方法中初始化Configuration变量"><a href="#注释掉open方法中初始化Configuration变量" class="headerlink" title="注释掉open方法中初始化Configuration变量"></a>注释掉open方法中初始化Configuration变量</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//final Configuration config = new Configuration();</span></span><br><span class="line"><span class="comment">//config.setBoolean(&quot;fs.automatic.close&quot;, false);</span></span><br></pre></td></tr></table></figure>

<h2 id="附录2"><a href="#附录2" class="headerlink" title="附录2"></a>附录2</h2><h3 id="logstash多对多关系导入到HDFS-HDFS"><a href="#logstash多对多关系导入到HDFS-HDFS" class="headerlink" title="logstash多对多关系导入到HDFS/HDFS"></a>logstash多对多关系导入到HDFS/HDFS</h3><h4 id="下载logstash"><a href="#下载logstash" class="headerlink" title="下载logstash"></a>下载logstash</h4><p><a target="_blank" rel="noopener" href="https://www.elastic.co/cn/downloads/past-releases#logstash">https://www.elastic.co/cn/downloads/past-releases#logstash</a></p>
<p>下载tar文件,解压到相应目录,安装相应插件.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/logstash-plugin install logstash-input-file</span><br><span class="line">./bin/logstash-plugin install logstash-output-webhdfs</span><br></pre></td></tr></table></figure>

<h3 id="添加配置文件"><a href="#添加配置文件" class="headerlink" title="添加配置文件"></a>添加配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  file&#123;</span><br><span class="line">    start_position &#x3D;&gt; &quot;beginning&quot;</span><br><span class="line">    mode &#x3D;&gt; &#39;tail&#39;</span><br><span class="line">    path &#x3D;&gt; [&quot;&#x2F;data&#x2F;xxx&#x2F;logs1&#x2F;app*.log&quot;]</span><br><span class="line">    type &#x3D;&gt; &#39;log1&#39;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  file&#123;</span><br><span class="line">    start_position &#x3D;&gt; &quot;beginning&quot;</span><br><span class="line">    mode &#x3D;&gt; &#39;tail&#39;</span><br><span class="line">    path &#x3D;&gt; [&quot;&#x2F;data&#x2F;xxx&#x2F;logs2&#x2F;app*.log&quot;]</span><br><span class="line">    type &#x3D;&gt; &#39;log2&#39;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    date &#123;</span><br><span class="line">      match &#x3D;&gt; [&quot;time_local&quot;,&quot;dd&#x2F;MMM&#x2F;yyyy:HH:mm:ss Z&quot;]</span><br><span class="line">      target &#x3D;&gt; &quot;@timestamp&quot;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ruby &#123;</span><br><span class="line">      code &#x3D;&gt; &quot;event.set(&#39;index.date&#39;, event.get(&#39;@timestamp&#39;).time.localtime.strftime(&#39;%Y%m%d&#39;))&quot;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ruby &#123;</span><br><span class="line">      code &#x3D;&gt; &quot;event.set(&#39;index.hour&#39;, event.get(&#39;@timestamp&#39;).time.localtime.strftime(&#39;%H&#39;))&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">if [type] &#x3D;&#x3D; &quot;log1&quot; &#123;</span><br><span class="line">    webhdfs &#123;</span><br><span class="line">      host &#x3D;&gt; &quot;xxx2&quot;</span><br><span class="line">      standby_host &#x3D;&gt; &quot;xxx1&quot;</span><br><span class="line">      user &#x3D;&gt; &quot;hadoop&quot;</span><br><span class="line">      path &#x3D;&gt; &quot;user&#x2F;hive&#x2F;warehouse&#x2F;flumemultest&#x2F;dt&#x3D;%&#123;index.date&#125;&#x2F;xxx-logstash-%&#123;index.hour&#125;.log&quot;</span><br><span class="line">      idle_flush_time &#x3D;&gt; 10</span><br><span class="line">      retry_interval &#x3D;&gt; 3</span><br><span class="line">      codec &#x3D;&gt; line &#123;</span><br><span class="line">      format &#x3D;&gt; &quot;%&#123;message&#125;&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    webhdfs &#123;</span><br><span class="line">      host &#x3D;&gt; &quot;master2&quot;</span><br><span class="line">      standby_host &#x3D;&gt; &quot;master1&quot;</span><br><span class="line">      user &#x3D;&gt; &quot;hadoop&quot;</span><br><span class="line">      path &#x3D;&gt; &quot;user&#x2F;hive&#x2F;warehouse&#x2F;flumemultest&#x2F;dt&#x3D;%&#123;index.date&#125;&#x2F;xxx-logstash-%&#123;index.hour&#125;.log&quot;</span><br><span class="line">      idle_flush_time &#x3D;&gt; 10</span><br><span class="line">      retry_interval &#x3D;&gt; 3</span><br><span class="line">      codec &#x3D;&gt; line &#123;</span><br><span class="line">      format &#x3D;&gt; &quot;%&#123;message&#125;&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line">    stdout &#123; codec &#x3D;&gt; rubydebug &#125; #测试时开启,方便查看日志</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="hive创建表及分区-停止tomcat-核对日志"><a href="#hive创建表及分区-停止tomcat-核对日志" class="headerlink" title="hive创建表及分区,停止tomcat,核对日志"></a>hive创建表及分区,停止tomcat,核对日志</h4><p>hive中数据与日志数据一致,无数据丢失,测试正常.</p>
<img src="/images/flume_41.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_42.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_43.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/flume_44.png" width="600" style="margin-left: 0px; padding-bottom: 10px;">
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/logstash/" rel="tag"># logstash</a>
              <a href="/tags/flume/" rel="tag"># flume</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/03/05/flume%E6%8B%A6%E6%88%AA%E5%99%A8/" rel="prev" title="flume拦截器">
                  <i class="fa fa-chevron-left"></i> flume拦截器
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/03/05/flume-logstash-filebeat%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%8A%9F%E8%83%BD%E5%AF%B9%E6%AF%94/" rel="next" title="flume-logstash-filebeat日志收集功能对比">
                  flume-logstash-filebeat日志收集功能对比 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
