<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="hbase版本为1.2.6,默认配置在hbase-common jar包中.">
<meta property="og:type" content="article">
<meta property="og:title" content="hbase默认配置参数">
<meta property="og:url" content="https://maoeryu.github.io/2022/03/03/hbase%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="hbase版本为1.2.6,默认配置在hbase-common jar包中.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-03-02T16:00:00.000Z">
<meta property="article:modified_time" content="2023-02-09T06:55:06.370Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="hbase">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://maoeryu.github.io/2022/03/03/hbase%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>hbase默认配置参数 | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8D%E8%A6%81%E9%85%8D%E7%BD%AE"><span class="nav-number">1.</span> <span class="nav-text">重要配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#master"><span class="nav-number">2.</span> <span class="nav-text">master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#regionserver"><span class="nav-number">3.</span> <span class="nav-text">regionserver</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#zookeeper"><span class="nav-number">4.</span> <span class="nav-text">zookeeper</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#client"><span class="nav-number">5.</span> <span class="nav-text">client</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E5%AE%83%E9%85%8D%E7%BD%AE"><span class="nav-number">6.</span> <span class="nav-text">其它配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E5%85%A8"><span class="nav-number">7.</span> <span class="nav-text">安全</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#web"><span class="nav-number">8.</span> <span class="nav-text">web</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#wal"><span class="nav-number">9.</span> <span class="nav-text">wal</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#timeout"><span class="nav-number">10.</span> <span class="nav-text">timeout</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">223</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2022/03/03/hbase%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hbase默认配置参数
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-03 00:00:00" itemprop="dateCreated datePublished" datetime="2022-03-03T00:00:00+08:00">2022-03-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-02-09 14:55:06" itemprop="dateModified" datetime="2023-02-09T14:55:06+08:00">2023-02-09</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>hbase版本为1.2.6,默认配置在hbase-common jar包中.</p>
<span id="more"></span>
<h3 id="重要配置"><a href="#重要配置" class="headerlink" title="重要配置"></a>重要配置</h3><p>hbase.tmp.dir<br><code>$&#123;java.io.tmpdir&#125;/hbase-$&#123;user.name&#125;</code><br>本地文件系统上的临时目录.<br>将此设置更改为指向比&quot;/tmp&quot;更永久的位置,这是 java.io.tmpdir 的通常解析,因为&quot;/tmp&quot;目录在机器重启时被清除.</p>
<p><font color="red">hbase.rootdir</font><br><code>$&#123;hbase.tmp.dir&#125;/hbase</code><br>区域服务器共享的目录以及 HBase 持久存在的目录.<br>该 URL 应该是&quot;完全合格的&quot;以包含文件系统方案.<br>例如,要指定 HDFS 实例的名称节点在端口 9000 上的 namenode.example.org 上运行的 HDFS 目录&quot;/hbase&quot;,请将此值设置为:hdfs://namenode.example.org:9000/hbase.<br>默认情况下,我们也写入 ${hbase.tmp.dir} 设置的任何内容--通常是 /tmp--因此请更改此配置,否则所有数据都将在机器重启时丢失.</p>
<p>hbase.fs.tmp.dir<br><code>/user/$&#123;user.name&#125;/hbase-staging</code><br>默认文件系统 (HDFS) 中用于保存临时数据的暂存目录.</p>
<p>hbase.bulkload.staging.dir<br><code>$&#123;hbase.fs.tmp.dir&#125;</code><br>默认文件系统 (HDFS) 中用于批量加载的暂存目录.</p>
<p><font color="red">hbase.cluster.distributed</font><br>false<br>集群将处于的模式.<br>可能的值对于独立模式是 false,对于分布式模式是 true.<br>如果为 false,启动将在一个 JVM 中一起运行所有 HBase 和 ZooKeeper 守护进程.</p>
<p><font color="red">hbase.zookeeper.quorum</font><br>localhost<br>ZooKeeper 集合中的逗号分隔服务器列表(此配置应该命名为 hbase.zookeeper.ensemble).<br>例如,&quot;host1.mydomain.com/host2.mydomain.com/host3.mydomain.com&quot;.<br>默认情况下,对于本地和伪分布式操作模式,这设置为 localhost.<br>对于完全分布式设置,这应该设置为 ZooKeeper 集成服务器的完整列表.<br>如果在 hbase-env.sh 中设置了 HBASE_MANAGES_ZK,这是 hbase 将作为集群启动/停止的一部分启动/停止 ZooKeeper 的服务器列表.<br>在客户端,我们将采用这个集合成员列表并将其与 hbase.zookeeper.clientPort 配置放在一起.<br>并将其作为 connectString 参数传递给 zookeeper 构造函数.</p>
<p>hbase.local.dir<br><code>$&#123;hbase.tmp.dir&#125;/local/</code><br>本地文件系统上用作本地存储的目录.</p>
<h3 id="master"><a href="#master" class="headerlink" title="master"></a>master</h3><p>hbase.master.port<br>16000<br>HBase Master 应该绑定到的端口.</p>
<p>hbase.master.info.port<br>16010<br>HBase Master Web UI 的端口.<br>如果您不想运行 UI 实例,请设置为 -1.</p>
<p>hbase.master.info.bindAddress<br>0.0.0.0<br>HBase Master web UI 的绑定地址</p>
<p>hbase.master.logcleaner.plugins<br>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner<br>LogsCleaner 服务调用的 BaseLogCleanerDelegate 的逗号分隔列表.<br>这些 WAL 清理器是按顺序调用的,因此将修剪最多文件的清理器放在前面.<br>要实现您自己的 BaseLogCleanerDelegate,只需将其放在 HBase 的类路径中并在此处添加完全限定的类名.<br>始终在列表中添加上述默认日志清理器.</p>
<p><font color="red">hbase.master.logcleaner.ttl</font><br>600000<br>WAL 可以保留在 .oldlogdir 目录中的最长时间,之后它将被主线程清除.</p>
<p><font color="red">hbase.master.hfilecleaner.plugins</font><br>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner<br>HFileCleaner 服务调用的 BaseHFileCleanerDelegate 的逗号分隔列表.<br>这些 HFiles 清理器是按顺序调用的,因此将修剪最多文件的清理器放在前面.<br>要实现您自己的 BaseHFileCleanerDelegate,只需将其放在 HBase 的类路径中并在此处添加完全限定的类名.<br>始终在列表中添加上述默认日志清理器,因为它们将在 hbase-site.xml 中被覆盖.</p>
<p>hbase.master.catalog.timeout<br>600000<br>Catalog Janitor 从 master 到 META 的超时值.</p>
<p>hbase.master.infoserver.redirect<br>true<br>Master是否监听Master web UI端口(hbase.master.info.port)并将请求重定向到Master和RegionServer共享的web UI服务器.</p>
<h3 id="regionserver"><a href="#regionserver" class="headerlink" title="regionserver"></a>regionserver</h3><p>hbase.regionserver.port<br>16020<br>HBase RegionServer 绑定到的端口.</p>
<p>hbase.regionserver.info.port<br>16030<br>如果您不想运行 RegionServer UI,则将 HBase RegionServer Web UI 的端口设置为 -1.</p>
<p>hbase.regionserver.info.bindAddress<br>0.0.0.0<br>HBase RegionServer Web UI 的地址</p>
<p>hbase.regionserver.info.port.auto<br>false<br>Master 或 RegionServer UI 是否应搜索要绑定的端口.<br>如果 hbase.regionserver.info.port 已在使用中,则启用自动端口搜索.<br>用于测试,默认关闭.</p>
<p><font color="red">hbase.regionserver.handler.count</font><br>30<br>在 RegionServers 上启动的 RPC Listener 实例计数.<br>Master 使用相同的属性来计算 master 处理程序的数量.</p>
<p>hbase.ipc.server.callqueue.handler.factor<br>0.1<br>确定呼叫队列数量的因素.<br>值 0 表示在所有处理程序之间共享一个队列.<br>值 1 表示每个处理程序都有自己的队列.</p>
<p>hbase.ipc.server.callqueue.read.ratio<br>0<br>将呼叫队列拆分为读取和写入队列.<br>指定的时间间隔(应介于 0.0 和 1.0 之间)将乘以呼叫队列的数量.<br>值为 0 表示不拆分调用队列,这意味着读取和写入请求将被推送到同一组队列.<br>低于 0.5 的值意味着读取队列将少于写入队列.<br>值为 0.5 意味着将有相同数量的读取和写入队列.<br>大于 0.5 的值意味着读取队列将多于写入队列.<br>值 1.0 表示除一个队列外的所有队列都用于分派读取请求.<br>示例:假设呼叫队列总数为 10,<br>read.ratio 为 0 意味着:10 个队列将同时包含读/写请求.<br>read.ratio 为 0.3 意味着:3 个队列将仅包含读取请求,而 7 个队列将仅包含写入请求.<br>read.ratio 为 0.5 意味着:5 个队列将仅包含读取请求,5 个队列将仅包含写入请求.<br>read.ratio 为 0.8 意味着:8 个队列将仅包含读取请求,2 个队列将仅包含写入请求.<br>read.ratio 为 1 意味着:9 个队列将仅包含读取请求,1 个队列将仅包含写入请求.</p>
<p>hbase.ipc.server.callqueue.scan.ratio<br>0<br>给定读取调用队列的数量(根据调用队列总数乘以 callqueue.read.ratio 计算得出),scan.ratio 属性会将读取调用队列拆分为小读取队列和长读取队列.<br>低于 0.5 的值意味着长读队列比短读队列少.<br>值 0.5 意味着将有相同数量的短读和长读队列.<br>大于 0.5 的值表示长读队列将多于短读队列.<br>值为 0 或 1 表示使用同一组队列进行获取和扫描.<br>示例:假设读取调用队列的总数为 8,则<br>scan.ratio 为 0 或 1 意味着:8 个队列将同时包含长读取请求和短读取请求.<br>scan.ratio 为 0.3 意味着:2 个队列将仅包含长读请求,6 个队列将仅包含短读请求.<br>scan.ratio 为 0.5 意味着:4 个队列将仅包含长读请求,4 个队列将仅包含短读请求.<br>scan.ratio 为 0.8 意味着:6 个队列将仅包含长读请求,2 个队列将仅包含短读请求.</p>
<p>hbase.regionserver.msginterval<br>3000<br>从 RegionServer 到 Master 的消息间隔,以毫秒为单位.</p>
<p>hbase.regionserver.logroll.period<br>3600000<br>我们将滚动提交日志的时间段,无论它有多少编辑.</p>
<p>hbase.regionserver.logroll.errors.tolerated<br>2<br>在触发服务器中止之前,我们将允许的连续 WAL 关闭错误数.<br>如果在日志滚动期间关闭当前 WAL 编写器失败,则设置为 0 将导致区域服务器中止.<br>即使是很小的值(2 或 3)也将允许区域服务器克服瞬态 HDFS 错误.</p>
<p>hbase.regionserver.hlog.reader.impl<br>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader<br>WAL 文件读取器实现.</p>
<p>hbase.regionserver.hlog.writer.impl<br>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter<br>WAL 文件编写器实现.</p>
<p><font color="red">hbase.regionserver.global.memstore.size</font><br>未配置<br>在阻止新更新并强制刷新之前,区域服务器中所有内存存储的最大大小.<br>默认为堆的 40% (0.4).<br>更新被阻止并强制刷新,直到区域服务器中所有内存存储的大小达到 hbase.regionserver.global.memstore.size.lower.limit.<br>此配置中的默认值有意保留为空,以便遵守旧的 hbase.regionserver.global.memstore.upperLimit 属性(如果存在).</p>
<p><font color="red">hbase.regionserver.global.memstore.size.lower.limit</font><br>未配置<br>强制刷新之前区域服务器中所有内存存储的最大大小.<br>默认为 hbase.regionserver.global.memstore.size (0.95) 的 95%.<br>此值的 100% 值会导致在由于 memstore 限制而阻止更新时发生最小可能的刷新.<br>此配置中的默认值有意保留为空,以便遵守旧的 hbase.regionserver.global.memstore.lowerLimit 属性(如果存在).</p>
<p><font color="red">hbase.regionserver.optionalcacheflushinterval</font><br>3600000<br>编辑在自动刷新之前在内存中存在的最长时间.<br>默认 1 小时.<br>将其设置为 0 以禁用自动刷新.</p>
<p>hbase.regionserver.catalog.timeout<br>600000<br>Catalog Janitor 从区域服务器到 META 的超时值.</p>
<p>hbase.regionserver.dns.interface<br>default<br>区域服务器应从中报告其 IP 地址的网络接口的名称.</p>
<p>hbase.regionserver.dns.nameserver<br>default<br>区域服务器应使用名称服务器 (DNS) 的主机名或 IP 地址来确定主服务器用于通信和显示目的的主机名.</p>
<p>hbase.regionserver.region.split.policy<br>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy<br>拆分策略确定何时应拆分区域.<br>目前可用的各种其他拆分策略有 ConstantSizeRegionSplitPolicy/DisabledRegionSplitPolicy/DelimitedKeyPrefixRegionSplitPolicy/KeyPrefixRegionSplitPolicy 等.</p>
<p><font color="red">hbase.regionserver.regionSplitLimit</font><br>1000<br>限制区域数量,之后不应再进行区域拆分.<br>这不是区域数量的硬性限制,而是作为区域服务器在一定限制后停止分裂的指南.<br>默认设置为 1000.</p>
<h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><p><font color="red">zookeeper.session.timeout</font><br>90000<br>ZooKeeper 会话超时(以毫秒为单位).<br>它以两种不同的方式使用.<br>首先,此值用于 HBase 用于连接到集成的 ZK 客户端.<br>HBase 在启动 ZK 服务器时也会使用它,并作为&quot;maxSessionTimeout&quot;传递.<br>请参阅<a target="_blank" rel="noopener" href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions">http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions</a>. 例如,如果 HBase 区域服务器连接到也由 HBase 管理的 ZK 集合,则会话超时将是此配置指定的超时.<br>但是,连接到使用不同配置管理的整体的区域服务器将受到该整体的 maxSessionTimeout 的约束.<br>因此,即使 HBase 可能建议使用 90 秒,集成的最大超时时间也可以低于此值,并且它会优先.<br>ZK 附带的当前默认值是 40 秒,低于 HBase 的.</p>
<p>zookeeper.znode.parent<br>/hbase<br>ZooKeeper 中 HBase 的根 ZNode.<br>所有配置有相对路径的 HBase 的 ZooKeeper 文件都将位于该节点下.<br>默认情况下,所有HBase的ZooKeeper文件路径都配置了相对路径,所以除非更改,否则都会在这个目录下.</p>
<p>zookeeper.znode.rootserver<br>root-region-server<br>持有根区域位置的 ZNode 的路径.<br>这是由 master 写入并由客户端和区域服务器读取的.<br>如果给出了相对路径,则父文件夹将为 <code>$&#123;zookeeper.znode.parent&#125;</code>.<br>默认情况下,这意味着根位置存储在 /hbase/root-region-server.</p>
<p>zookeeper.znode.acl.parent<br>acl<br>用于访问控制列表的根 ZNode.</p>
<p>hbase.zookeeper.dns.interface<br>default<br>ZooKeeper 服务器应从中报告其 IP 地址的网络接口的名称.</p>
<p>hbase.zookeeper.dns.nameserver<br>default<br>ZooKeeper 服务器应该使用名称服务器 (DNS) 的主机名或 IP 地址来确定主服务器用于通信和显示目的的主机名.</p>
<p>hbase.zookeeper.peerport<br>2888<br>ZooKeeper 对等点用来相互交谈的端口.<br>有关详细信息,请参阅<a target="_blank" rel="noopener" href="http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper">http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper</a>.</p>
<p>hbase.zookeeper.leaderport<br>3888<br>ZooKeeper 用于领导人选举的端口.<br>有关详细信息,请参阅<a target="_blank" rel="noopener" href="http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper">http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper</a>.</p>
<p>hbase.zookeeper.useMulti<br>true<br>指示 HBase 使用 ZooKeeper 的多更新功能.<br>这允许某些 ZooKeeper 操作更快地完成并防止一些罕见的复制失败场景的问题(有关示例,请参见 HBASE-2611 的发行说明).<br>重要提示:如果集群中的所有 ZooKeeper 服务器都在 3.4+ 版本并且不会降级,则仅将此设置为 true.<br>ZooKeeper 3.4 之前的版本不支持多重更新,如果调用多重更新,则不会正常失败(请参阅 ZOOKEEPER-1495).</p>
<p>hbase.config.read.zookeeper.config<br>false<br>设置为 true 以允许 HBaseConfiguration 读取 ZooKeeper 属性的 zoo.cfg 文件.<br>不建议将此设置为 true,因为从 zoo.cfg 文件读取 ZK 属性的功能已被弃用.</p>
<p>hbase.zookeeper.property.initLimit<br>10<br>ZooKeeper 的配置 zoo.cfg 中的属性.<br>初始同步阶段可以进行的滴答数.</p>
<p>hbase.zookeeper.property.syncLimit<br>5<br>ZooKeeper 的配置 zoo.cfg 中的属性.<br>在发送请求和获得确认之间可以经过的滴答数.</p>
<p><font color="red">hbase.zookeeper.property.dataDir</font><br><code>$&#123;hbase.tmp.dir&#125;/zookeeper</code><br>ZooKeeper 的配置 zoo.cfg 中的属性.<br>存储快照的目录.</p>
<p>hbase.zookeeper.property.clientPort<br>2181<br>ZooKeeper 的配置 zoo.cfg 中的属性.<br>客户端将连接的端口.</p>
<p><font color="red">hbase.zookeeper.property.maxClientCnxns</font><br>300<br>ZooKeeper 的配置 zoo.cfg 中的属性.<br>限制由 IP 地址标识的单个客户端可以与 ZooKeeper 集合体的单个成员建立的并发连接数(在套接字级别).<br>设置高以避免独立运行和伪分布式运行的 zk 连接问题.</p>
<h3 id="client"><a href="#client" class="headerlink" title="client"></a>client</h3><p><font color="red">hbase.client.write.buffer</font><br>2097152<br>HTable 客户端写入缓冲区的默认大小(以字节为单位).<br>更大的缓冲区占用更多内存--在客户端和服务器端,因为服务器实例化传递的写入缓冲区来处理它--但更大的缓冲区大小减少了 RPC 的数量.<br>对于服务器端内存使用的估计,评估 hbase.client.write.buffer * hbase.regionserver.handler.count</p>
<p><font color="red">hbase.client.pause</font><br>100<br>一般客户端暂停值.<br>主要用作在重试失败的获取/区域查找等之前等待的值.<br>请参阅 hbase.client.retries.number 以了解我们如何从这个初始暂停量退避以及这个暂停如何与重试一起工作.</p>
<p><font color="red">hbase.client.retries.number</font><br>35<br>最大重试次数.<br>用作所有可重试操作的最大值,例如获取单元格的值/开始行更新等.<br>重试间隔是基于 hbase.client.pause 的粗略函数.<br>起初我们按此间隔重试,但随后使用退避,我们很快达到每 10 秒重试一次.<br>请参阅 HConstants#RETRY_BACKOFF 了解备份如何增加.<br>更改此设置和 hbase.client.pause 以适合您的工作负载.</p>
<p>hbase.client.max.total.tasks<br>100<br>单个 HTable 实例将发送到集群的最大并发任务数.</p>
<p>hbase.client.max.perserver.tasks<br>5<br>单个 HTable 实例将发送到单个区域服务器的最大并发任务数.</p>
<p>hbase.client.max.perregion.tasks<br>1<br>客户端将维护到单个区域的最大并发连接数.<br>也就是说,如果该区域已经有 hbase.client.max.perregion.tasks 写入正在进行中,则在某些写入完成之前不会将新的 put 发送到该区域.</p>
<p><font color="red">hbase.client.scanner.caching</font><br>2147483647<br>如果不是从(本地,客户端)内存提供服务,则在扫描仪上调用 next 时我们尝试获取的行数.<br>此配置与 hbase.client.scanner.max.result.size 一起使用以尝试有效地使用网络.<br>默认值为 Integer.MAX_VALUE,这样网络将填充由 hbase.client.scanner.max.result.size 定义的块大小,而不是受特定行数的限制,因为行的大小因表而异. 如果您提前知道您不需要超过一定数量的扫描行,则应通过 Scan#setCaching 将此配置设置为该行限制.<br>较高的缓存值将启用更快的扫描器,但会占用更多内存,并且当缓存为空时,某些 next 调用可能需要越来越长的时间.<br>不要设置这个值使得调用之间的时间大于扫描器超时.<br>即 hbase.client.scanner.timeout.period</p>
<p>hbase.client.keyvalue.maxsize<br>10485760<br>指定 KeyValue 实例的组合最大允许大小.<br>这是为存储文件中保存的单个条目设置上限.<br>由于它们无法拆分,因此有助于避免由于数据太大而无法进一步拆分区域.<br>将其设置为最大区域大小的一小部分似乎是明智的.<br>将其设置为零或更少会禁用检查.</p>
<p>hbase.client.localityCheck.threadPoolSize<br>2<br>无描述</p>
<h3 id="其它配置"><a href="#其它配置" class="headerlink" title="其它配置"></a>其它配置</h3><p>hbase.bulkload.retries.number<br>10<br>最大重试次数.<br>这是面对拆分操作时尝试进行原子批量加载的最大迭代次数,0 表示永不放弃.</p>
<p>hbase.balancer.period<br>300000<br>区域平衡器在 Master 中运行的时间段.</p>
<p>hbase.normalizer.period<br>1800000<br>区域标准化器在 Master 中运行的时间段.</p>
<p>hbase.regions.slop<br>0.2<br>如果任何区域服务器具有平均 +(平均 * slop)区域,则重新平衡.</p>
<p><font color="red">hbase.server.thread.wakefrequency</font><br>10000<br>两次搜索工作之间的休眠时间(以毫秒为单位).<br>由服务线程(例如 log roller)用作睡眠间隔.</p>
<p>hbase.server.versionfile.writeattempts<br>3<br>在中止之前重试尝试写入版本文件的次数.<br>每次尝试都由 hbase.server.thread.wakefrequency 毫秒分隔.</p>
<p><font color="red">hbase.hregion.memstore.flush.size</font><br>134217728<br>如果 memstore 的大小超过此字节数,Memstore 将被刷新到磁盘.<br>值由运行每个 hbase.server.thread.wakefrequency 的线程检查.</p>
<p>hbase.hregion.percolumnfamilyflush.size.lower.bound<br>16777216<br>如果使用 FlushLargeStoresPolicy,那么每次我们达到总 memstore 限制时,我们找出所有 memstores 超过此值的列族,并仅刷新它们,同时保留其他 memstores 低于此限制的列族.<br>如果没有一个家族的 memstore 大小超过这个值,所有的 memstore 都将被刷新(就像往常一样).<br>此值应小于总 memstore 阈值 (hbase.hregion.memstore.flush.size) 的一半.</p>
<p>hbase.hregion.preclose.flush.size<br>5242880<br>如果在我们关闭时某个区域中的 memstores 是这个大小或更大,请运行&quot;预刷新&quot;以清除 memstores,然后再放置区域关闭标志并使该区域脱机.<br>关闭时,在关闭标志下运行刷新以清空内存.<br>在此期间,该区域处于离线状态,我们不进行任何写入.<br>如果 memstore 内容很大,则此刷新可能需要很长时间才能完成.<br>preflush 的目的是在设置关闭标志并使该区域脱机之前清除 memstore 的大部分,因此在关闭标志下运行的刷新几乎没有关系.</p>
<p><font color="red">hbase.hregion.memstore.block.multiplier</font><br>4<br>如果 memstore 有 hbase.hregion.memstore.block.multiplier 乘以 hbase.hregion.memstore.flush.size 字节,则阻止更新.<br>在更新流量高峰期间防止 memstore 失控很有用.<br>如果没有上限,memstore 会在刷新时填充生成的刷新文件需要很长时间才能压缩或拆分,或者更糟的是,我们 OOME.</p>
<p><font color="red">hbase.hregion.memstore.mslab.enabled</font><br>true<br>启用 MemStore-Local Allocation Buffer,该功能可防止在重写负载下出现堆碎片.<br>这可以减少大型堆上 stop-the-world GC 暂停的频率.</p>
<p><font color="red">hbase.hregion.max.filesize</font><br>10737418240<br>最大 HStoreFile 大小.<br>如果任何一个列族的 HStoreFiles 增长到超过此值,则托管 HRegion 将一分为二.</p>
<p><font color="red">hbase.hregion.majorcompaction</font><br>604800000<br>区域中所有 HStoreFiles 的&quot;主要&quot;压缩之间的时间(以毫秒为单位).<br>默认值:设置为 7 天.<br>主要压缩往往恰好在您最不需要它们的时候发生,因此启用它们以便它们在您的部署的非高峰期运行.<br>或者,由于此设置的周期性不太可能与您的负载相匹配,因此可以通过 cron 作业或类似作业的外部调用来运行压缩.</p>
<p><font color="red">hbase.hregion.majorcompaction.jitter</font><br>0.50<br>主要压缩的抖动外部边界.<br>在每个区域服务器上,我们将 hbase.region.majorcompaction 间隔乘以这个最大值范围内的某个随机分数.<br>然后我们将这个 + 或 - 乘积添加到下一个主要压缩运行的时间.<br>这个想法是主要压缩确实在每个区域服务器上同时发生.<br>这个数字越小,压缩就越紧密.</p>
<p><font color="red">hbase.hstore.compactionThreshold</font><br>3<br>如果任何一个 HStore 中的 HStoreFiles 数量超过此数量(每次刷新 memstore 写入一个 HStoreFile),则运行压缩以将所有 HStoreFiles 文件重写为一个.<br>较大的数字会推迟压缩,但当它运行时,需要更长的时间才能完成.</p>
<p>hbase.hstore.flusher.count<br>2<br>冲洗线程的数量.<br>使用较少的线程,内存存储刷新将排队.<br>线程多了,flush会并行执行,增加hdfs的负载.<br>这也可能导致更多的压缩.</p>
<p><font color="red">hbase.hstore.blockingStoreFiles</font><br>10<br>如果任何一个 Store 中的 StoreFiles 数量超过此数量(每次刷新 MemStore 写入一个 StoreFile),则此 HRegion 的更新将被阻止,直到压缩完成,或直到超过 hbase.hstore.blockingWaitTime.</p>
<p><font color="red">hbase.hstore.blockingWaitTime</font><br>90000<br>HRegion 在达到 hbase.hstore.blockingStoreFiles 定义的 StoreFile 限制后阻止更新的时间.<br>这段时间过去后,HRegion 将停止阻止更新,即使压缩尚未完成.</p>
<p><font color="red">hbase.hstore.compaction.max</font><br>10<br>每个&quot;次要&quot;压缩要压缩的 HStoreFiles 的最大数量.</p>
<p>hbase.hstore.compaction.kv.max<br>10<br>刷新或压缩时批量读取和写入多少个 KeyValue.<br>如果 KeyValues 大且 OOME 出现问题,则少做.<br>如果宽而小,则多做一些.</p>
<p>hbase.hstore.time.to.purge.deletes<br>0<br>延迟清除具有未来时间戳的删除标记的时间量.<br>如果未设置或设置为 0,则在下一次主要压缩期间清除所有删除标记,包括具有未来时间戳的标记.<br>否则,将保留删除标记,直到主要压缩发生在标记的时间戳加上此设置的值(以毫秒为单位)之后.</p>
<p>hbase.storescanner.parallel.seek.enable<br>false<br>在 StoreScanner 中启用 StoreFileScanner 并行搜索,该功能可以减少特殊条件下的响应延迟.</p>
<p>hbase.storescanner.parallel.seek.threads<br>10<br>如果启用了并行搜索功能,则默认线程池大小.</p>
<p><font color="red">hfile.block.cache.size</font><br>0.4<br>分配给 HFile/StoreFile 使用的块缓存的最大堆(-Xmx 设置)的百分比.<br>默认值 0.4 表示分配 40%.<br>设置为 0 禁用,但不推荐.<br>您至少需要足够的缓存来保存存储文件索引.</p>
<p>hfile.block.index.cacheonwrite<br>false<br>这允许在写入索引时将非根多级索引块放入块缓存中.</p>
<p>hfile.index.block.max.size<br>131072<br>当多级块索引中的叶级/中间级或根级索引块的大小增长到这个大小时,该块被写出并开始一个新块.</p>
<p><font color="red">hbase.bucketcache.ioengine</font><br>未配置<br>存储 bucketcache 内容的位置.<br>其中之一:heap/offheap/file.<br>如果是文件,将其设置为文件:PATH_TO_FILE.<br>有关详细信息,请参阅<a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html#offheap.blockcache">http://hbase.apache.org/book.html#offheap.blockcache</a>.</p>
<p><font color="red">hbase.bucketcache.combinedcache.enabled</font><br>true<br>bucketcache 是否与 LRU 堆上块缓存结合使用.<br>在这种模式下,index 和 blooms 保存在 LRU blockcache 中,数据块保存在 bucketcache 中.</p>
<p><font color="red">hbase.bucketcache.size</font><br>未配置<br>一个浮点数,它代表分配给缓存的总堆内存大小的百分比(如果 &lt; 1.0),或者它是 BucketCache 的总容量(以兆字节为单位).<br>默认值:0.0</p>
<p>hbase.bucketcache.sizes<br>未配置<br>bucketcache 的桶大小的逗号分隔列表.<br>可以是多种尺寸.<br>按从小到大的顺序列出块大小.<br>您使用的大小将取决于您的数据访问模式.<br>必须是 1024 的倍数,否则当您从缓存中读取时会遇到&quot;java.io.IOException: Invalid HFile block magic&quot;.<br>如果您在此处未指定任何值,那么您将选择代码中设置的默认桶大小(请参阅 BucketAllocator#DEFAULT_BUCKET_SIZES).</p>
<p>hfile.format.version<br>3<br>用于新文件的 HFile 格式版本.<br>版本 3 添加了对 hfile 中标签的支持(参见<a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html#hbase.tags">http://hbase.apache.org/book.html#hbase.tags</a>).<br>分布式日志重播要求启用标签.<br>另请参阅配置&quot;hbase.replication.rpc.codec&quot;.</p>
<p>hfile.block.bloom.cacheonwrite<br>false<br>为复合布隆过滤器的内联块启用写时缓存.</p>
<p>io.storefile.bloom.block.size<br>131072<br>复合布隆过滤器的单个块(&quot;块&quot;)的大小(以字节为单位).<br>这个大小是近似值,因为 Bloom 块只能插入到数据块边界,并且每个数据块的键数各不相同.</p>
<p>hbase.rs.cacheblocksonwrite<br>false<br>当块完成时,是否应将 HFile 块添加到块缓存中.</p>
<p>hbase.cells.scanned.per.heartbeat.check<br>10000<br>在检测信号检查之间扫描的单元数.<br>心跳检查发生在扫描处理期间,以确定服务器是否应停止扫描以便将心跳消息发送回客户端.<br>心跳消息用于在长时间运行的扫描期间保持客户端-服务器连接处于活动状态.<br>较小的值意味着心跳检查将更频繁地发生,因此将对扫描的执行时间提供更严格的限制.<br>较大的值意味着心跳检查发生的频率较低</p>
<p>hbase.rpc.shortoperation.timeout<br>10000<br>这是&quot;hbase.rpc.timeout&quot;的另一个版本.<br>对于集群内的那些RPC操作,我们依靠这个配置来为短操作设置一个短的超时限制.<br>例如,区域服务器尝试向活动主服务器报告的较短 rpc 超时可以有利于更快的主服务器故障转移过程.</p>
<p>hbase.ipc.client.tcpnodelay<br>true<br>在 rpc 套接字连接上设置无延迟.<br>参见<a target="_blank" rel="noopener" href="http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay">http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay</a>( )</p>
<p>hbase.regionserver.hostname<br>未配置<br>此配置适用于专家:除非您真的知道自己在做什么,否则不要设置它的值.<br>当设置为非空值时,这表示底层服务器的(面向外部的)主机名.<br>有关详细信息,请参阅<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HBASE-12954">https://issues.apache.org/jira/browse/HBASE-12954</a>.</p>
<p>hbase.master.keytab.file<br>未配置<br>用于登录配置的 HMaster 服务器主体的 kerberos 密钥表文件的完整路径.</p>
<p>hbase.master.kerberos.principal<br>未配置<br>前任.<br>&quot;hbase/<code>_HOST@EXAMPLE.COM</code>&quot;.<br>应该用于运行 HMaster 进程的 kerberos 主体名称.<br>主体名称的格式应为:用户/主机名@DOMAIN.<br>如果&quot;<code>_HOST</code>&quot;用作主机名部分,它将被替换为正在运行的实例的实际主机名.</p>
<p>hbase.regionserver.keytab.file<br>未配置<br>用于登录配置的 HRegionServer 服务器主体的 kerberos keytab 文件的完整路径.</p>
<p>hbase.regionserver.kerberos.principal<br>未配置<br>前任.<br>&quot;hbase/<code>_HOST@EXAMPLE.COM</code>&quot;.<br>应该用于运行 HRegionServer 进程的 kerberos 主体名称.<br>主体名称的格式应为:用户/主机名@DOMAIN.<br>如果&quot;<code>_HOST</code>&quot;用作主机名部分,它将被替换为正在运行的实例的实际主机名.<br>此主体的条目必须存在于 hbase.regionserver.keytab.file 中指定的文件中</p>
<h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>hadoop.policy.file<br>hbase-policy.xml<br>RPC 服务器用来对客户端请求做出授权决定的策略配置文件.<br>仅在启用 HBase 安全性时使用.</p>
<p><font color="red">hbase.superuser</font><br>未配置<br>用户或组的列表(以逗号分隔),无论存储的 ACL 如何,都可以在集群中拥有完全权限.<br>仅在启用 HBase 安全性时使用.</p>
<p>hbase.auth.key.update.interval<br>86400000<br>服务器中身份验证令牌的主密钥更新间隔,以毫秒为单位.<br>仅在启用 HBase 安全性时使用.</p>
<p>hbase.auth.token.max.lifetime<br>604800000<br>身份验证令牌过期后的最长生命周期(以毫秒为单位).<br>仅在启用 HBase 安全性时使用.</p>
<p>hbase.ipc.client.fallback-to-simple-auth-allowed<br>false<br>当客户端配置为尝试安全连接,但尝试连接到不安全的服务器时,该服务器可能会指示客户端切换到 SASL SIMPLE(不安全)身份验证.<br>此设置控制客户端是否接受来自服务器的此指令.<br>如果为 false(默认值),客户端将不允许回退到 SIMPLE 身份验证,并将中止连接.</p>
<p>hbase.ipc.server.fallback-to-simple-auth-allowed<br>false<br>当服务器配置为需要安全连接时,它将拒绝来自使用 SASL SIMPLE(不安全)身份验证的客户端的连接尝试.<br>此设置允许安全服务器在客户端请求时接受来自客户端的 SASL SIMPLE 连接.<br>如果为 false(默认值),服务器将不允许回退到 SIMPLE 身份验证,并将拒绝连接.<br>警告:此设置仅应用作将客户端转换为安全身份验证时的临时措施.<br>为了安全操作,必须禁用它.</p>
<p>hbase.coprocessor.enabled<br>true<br>启用或禁用协处理器加载.<br>如果为&quot;false&quot;(禁用),将忽略任何其他与协处理器相关的配置.</p>
<p>hbase.coprocessor.user.enabled<br>true<br>启用或禁用用户(又名表)协处理器加载.<br>如果为&quot;false&quot;(禁用),表描述符中的任何表协处理器属性都将被忽略.<br>如果&quot;hbase.coprocessor.enabled&quot;为&quot;false&quot;,则此设置无效.</p>
<p><font color="red">hbase.coprocessor.region.classes</font><br>未配置<br>默认情况下在所有表上加载的以逗号分隔的协处理器列表.<br>对于任何覆盖协处理器方法,这些类将按顺序调用.<br>实现自己的 Coprocessor 后,只需将其放在 HBase 的类路径中,并在此处添加完全限定的类名即可.<br>协处理器也可以通过设置 HTableDescriptor 按需加载.</p>
<p>hbase.rest.port<br>8080<br>HBase REST 服务器的端口.</p>
<p>hbase.rest.readonly<br>false<br>定义 REST 服务器将启动的模式.<br>可能的值是: false:允许所有 HTTP 方法 - GET/PUT/POST/DELETE.<br>true:只允许使用 GET 方法.</p>
<p>hbase.rest.threads.max<br>100<br>REST 服务器线程池的最大线程数.<br>池中的线程被重用来处理 REST 请求.<br>这控制并发处理的最大请求数.<br>它可能有助于控制 REST 服务器使用的内存以避免 OOM 问题.<br>如果线程池已满,传入的请求将排队等待一些空闲线程.</p>
<p>hbase.rest.threads.min<br>2<br>REST 服务器线程池的最小线程数.<br>线程池始终至少有这些数量的线程,以便 REST 服务器准备好为传入的请求提供服务.</p>
<p>hbase.rest.support.proxyuser<br>false<br>允许运行 REST 服务器以支持代理用户模式.</p>
<p>hbase.defaults.for.version.skip<br>false<br>设置为 true 以跳过 &#39;hbase.defaults.for.version&#39; 检查.<br>将此设置为 true 在 maven 生成的另一端以外的上下文中可能很有用.<br>即在ide中运行.<br>您需要将此布尔值设置为 true 以避免看到 RuntimException 投诉:&quot;hbase-default.xml 文件似乎适用于旧版本的 HBase (<code>$&#123;hbase.version&#125;</code>),此版本为 XXX-SNAPSHOT&quot;</p>
<p><font color="red">hbase.coprocessor.master.classes</font><br>未配置<br>默认情况下在活动 HMaster 进程上加载的 org.apache.hadoop.hbase.coprocessor.MasterObserver 协处理器的逗号分隔列表.<br>对于任何已实现的协处理器方法,将按顺序调用列出的类.<br>实现自己的 MasterObserver 后,只需将其放在 HBase 的类路径中,并在此处添加完全限定的类名即可.</p>
<p>hbase.coprocessor.abortonerror<br>true<br>如果协处理器无法加载/无法初始化或抛出意外的 Throwable 对象,则设置为 true 会导致托管服务器(主服务器或区域服务器)中止.<br>将此设置为 false 将允许服务器继续执行,但所讨论的协处理器的系统范围状态将变得不一致,因为它将仅在服务器的子集中正确执行,因此这仅对调试最有用.</p>
<p>hbase.online.schema.update.enable<br>true<br>设置为 true 以启用在线架构更改.</p>
<p>hbase.table.lock.enable<br>true<br>设置为 true 以启用锁定 zookeeper 中的表以进行模式更改操作.<br>来自 master 的表锁定可防止并发模式修改损坏的表状态.</p>
<p>hbase.table.max.rowsize<br>1073741824<br>Get&#39;ting 或 Scan&#39;ning 未设置行内扫描标志的单行最大大小(默认为 1 Gb).<br>如果行大小超过此限制,则向客户端抛出 RowTooBigException.</p>
<p>hbase.thrift.minWorkerThreads<br>16<br>线程池的&quot;核心大小&quot;.<br>在创建这么多线程之前,每个连接都会创建新线程.</p>
<p>hbase.thrift.maxWorkerThreads<br>1000<br>线程池的最大大小.<br>当待处理的请求队列溢出时,会创建新的线程,直到它们的数量达到这个数量.<br>之后,服务器开始断开连接.</p>
<p>hbase.thrift.maxQueuedRequests<br>1000<br>在队列中等待的最大挂起 Thrift 连接数.<br>如果池中没有空闲线程,则服务器将请求排队.<br>只有当队列溢出时,才添加新线程,最多 hbase.thrift.maxQueuedRequests 个线程.</p>
<p>hbase.thrift.htablepool.size.max<br>1000<br>Thrift 网关服务器中使用的表池的上限.<br>由于这是每个表名称,我们假设有一个表,因此对于 1000 个默认工作线程最大值,这被设置为一个匹配的数字.<br>对于其他工作负载,可以根据需要调整此数字.</p>
<p>hbase.regionserver.thrift.framed<br>false<br>在服务器端使用 Thrift TFramedTransport.<br>这是为 thrift 服务器推荐的传输方式,并且需要在客户端进行类似的设置.<br>将此更改为 false 将选择默认传输,当由于 THRIFT-601 发出格式错误的请求时容易受到 DoS 攻击.</p>
<p>hbase.regionserver.thrift.framed.max_frame_size_in_mb<br>2<br>使用成帧传输时的默认帧大小</p>
<p>hbase.regionserver.thrift.compact<br>false<br>使用 Thrift TCompactProtocol 二进制序列化协议.</p>
<p>hbase.rootdir.perms<br>700<br>安全 (kerberos) 设置中根目录的 FS 权限.<br>当 master 启动时,它会创建具有此权限的 rootdir,如果不匹配则设置权限.</p>
<p>hbase.data.umask.enable<br>false<br>启用,如果为真,文件权限应该分配给区域服务器写入的文件</p>
<p>hbase.data.umask<br>000<br>当 hbase.data.umask.enable 为真时应该用于写入数据文件的文件权限</p>
<p>hbase.metrics.showTableName<br>true<br>是否在每列系列指标中包含前缀&quot;tbl.tablename&quot;.<br>如果为真,对于每个指标 M,将为 tbl.T.cf.CF.M 报告每个 cf 指标,如果为假,则每个 cf 指标将按列族跨表聚合,并为 cf.CF 报告.<br>M. 在这两种情况下,将报告跨表和 cfs 的聚合指标 M.</p>
<p>hbase.metrics.exposeOperationTimes<br>true<br>是否报告有关在区域服务器上执行操作所花费的时间的指标.<br>Get/Put/Delete/Increment 和 Append 都可以通过每个 CF 和每个区域的 Hadoop 指标公开它们的时间.</p>
<p>hbase.snapshot.enabled<br>true<br>设置为 true 以允许拍摄/恢复/克隆快照.</p>
<p>hbase.snapshot.restore.take.failsafe.snapshot<br>true<br>设置为 true 以在还原操作之前拍摄快照.<br>拍摄的快照将在发生故障时用于恢复以前的状态.<br>在恢复操作结束时,该快照将被删除</p>
<p>hbase.snapshot.restore.failsafe.name<br><code>hbase-failsafe-&#123;snapshot.name&#125;-&#123;restore.timestamp&#125;</code><br>还原操作拍摄的故障安全快照的名称.<br>您可以使用 {snapshot.name}/{table.name} 和 {restore.timestamp} 变量根据要恢复的内容创建名称.</p>
<p><font color="red">hbase.server.compactchecker.interval.multiplier</font><br>1000<br>决定我们扫描以查看是否需要压缩的频率的数字.<br>通常,压缩是在某些事件(例如 memstore flush)之后进行的,但是如果区域在一段时间内没有收到大量写入,或者由于不同的压缩策略,则可能需要定期检查它.<br>检查之间的间隔是 hbase.server.compactchecker.interval.multiplier 乘以 hbase.server.thread.wakefrequency.</p>
<p>hbase.lease.recovery.timeout<br>900000<br>在放弃之前,我们总共等待 dfs 租赁回收多长时间.</p>
<p>hbase.lease.recovery.dfs.timeout<br>64000<br>dfs 恢复租约调用之间的时间间隔.<br>应该大于namenode作为datanode的一部分发出块恢复命令所花费的时间总和.<br>dfs.heartbeat.interval和primary datanode花费的时间,执行block recovery到一个dead datanode超时.<br>通常是 dfs.client.socket-timeout.<br>有关更多信息,请参阅 HBASE-8389 的结尾.</p>
<p>hbase.column.max.version<br>1<br>新的列族描述符将使用此值作为要保留的默认版本数.</p>
<p>hbase.dfs.client.read.shortcircuit.buffer.size<br>131072<br>如果 DFSClient 配置 dfs.client.read.shortcircuit.buffer.size 未设置,我们将使用此处配置的内容作为短路读取默认直接字节缓冲区大小.<br>DFSClient原生默认为1MB.<br>HBase 保持其 HDFS 文件处于打开状态,因此文件块数量 * 1MB 很快就会开始增加,并由于直接内存不足而威胁到 OOME.<br>所以,我们把它从默认设置下来.<br>使其 &gt; 在 HColumnDescriptor 中设置的默认 hbase 块大小通常为 64k.</p>
<p>hbase.regionserver.checksum.verify<br>true<br>如果设置为 true(默认值),HBase 会验证 hfile 块的校验和.<br>HBase 在写出 hfile 时将校验和与数据内联写入.<br>HDFS(在撰写本文时)将校验和写入一个单独的文件,而不是需要额外查找的数据文件.<br>设置这个标志可以节省一些 i/o.<br>设置此标志后,HDFS 的校验和验证将在内部禁用 hfile 流.<br>如果 hbase-checksum 验证失败,我们将切换回使用 HDFS 校验和(因此不要禁用 HDFS 校验和！而且此功能仅适用于 hfile,不适用于 WAL).<br>如果此参数设置为 false,则 hbase 将不会验证任何校验和,而是取决于在 HDFS 客户端中进行的校验和验证.</p>
<p>hbase.hstore.bytes.per.checksum<br>16384<br>为 hfile 块中的 HBase 级校验和新创建的校验和块中的字节数.</p>
<p>hbase.hstore.checksum.algorithm<br>CRC32C<br>用于计算校验和的算法的名称.<br>可能的值为 NULL/CRC32/CRC32C.</p>
<p>hbase.client.scanner.max.result.size<br>2097152<br>调用扫描仪的 next 方法时返回的最大字节数.<br>请注意,当单行大于此限制时,该行仍会完整返回.<br>默认值为 2MB,适合 1ge 网络.<br>对于更快和/或高延迟的网络,应该增加该值.</p>
<p>hbase.server.scanner.max.result.size<br>104857600<br>调用扫描仪的 next 方法时返回的最大字节数.<br>请注意,当单行大于此限制时,该行仍会完整返回.<br>默认值为 100MB.<br>这是保护服务器免受 OOM 情况影响的安全设置.</p>
<p>hbase.status.published<br>false<br>此设置激活区域服务器状态的主人发布.<br>当区域服务器挂掉并开始恢复时,master 会将此信息推送到客户端应用程序,让它们立即断开连接,而不是等待超时.</p>
<p>hbase.status.publisher.class<br>org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher<br>使用多播消息实现状态发布.</p>
<p>hbase.status.listener.class<br>org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener<br>使用多播消息实现状态侦听器.</p>
<p>hbase.status.multicast.address.ip<br>226.1.1.3<br>用于通过多播进行状态发布的多播地址.</p>
<p>hbase.status.multicast.address.port<br>16100<br>用于通过多播进行状态发布的多播端口.</p>
<p>hbase.dynamic.jars.dir<br><code>$&#123;hbase.rootdir&#125;/lib</code><br>区域服务器可以从中动态加载自定义过滤器/协处理器 jar 的目录,而无需重新启动.<br>但是,不会卸载已经加载的过滤器/协处理器类.<br>有关详细信息,请参阅 HBASE-1936.</p>
<p>hbase.security.authentication<br>simple<br>控制是否为 HBase 启用安全身份验证.<br>可能的值是&quot;简单&quot;(无身份验证)和&quot;kerberos&quot;.</p>
<p>hbase.rest.filter.classes<br>org.apache.hadoop.hbase.rest.filter.GzipFilter<br>REST 服务的 Servlet 过滤器.</p>
<p>hbase.master.loadbalancer.class<br>org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer<br>用于在周期发生时执行区域平衡的类.<br>有关其工作原理的更多信息,请参阅类评论<a target="_blank" rel="noopener" href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html%E5%AE%83%E5%8F%96%E4%BB%A3%E4%BA%86">http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html它取代了</a> DefaultLoadBalancer 作为默认值(因为更名为 SimpleLoadBalancer ).</p>
<p>hbase.security.exec.permission.checks<br>false<br>如果启用此设置并且基于 ACL 的访问控制处于活动状态(AccessController 协处理器安装为系统协处理器或作为表协处理器安装在表上),那么如果所有相关用户需要执行协处理器端点的能力,则必须授予所有相关用户 EXEC 权限电话.<br>与任何其他权限一样,EXEC 权限可以全局授予用户,也可以按表或命名空间授予用户.<br>有关协处理器端点的更多信息,请参阅 HBase 联机手册的协处理器部分.<br>有关使用 AccessController 授予或撤销权限的更多信息,请参阅 HBase 在线手册的安全部分.</p>
<p>hbase.procedure.regionserver.classes<br>未配置<br>org.apache.hadoop.hbase.procedure.RegionServerProcedureManager 过程管理器的逗号分隔列表,默认加载到活动的 HRegionServer 进程上.<br>生命周期方法 (init/start/stop) 将由活动的 HRegionServer 进程调用以执行特定的全局屏障过程.<br>实现自己的 RegionServerProcedureManager 后,只需将其放在 HBase 的类路径中并在此处添加完全限定的类名即可.</p>
<p>hbase.procedure.master.classes<br>未配置<br>org.apache.hadoop.hbase.procedure.MasterProcedureManager 过程管理器的逗号分隔列表,默认情况下在活动 HMaster 进程上加载.<br>程序由其签名标识,用户可以使用签名和即时名称来触发全局屏障程序的执行.<br>实现自己的 MasterProcedureManager 后,只需将其放在 HBase 的类路径中,并在此处添加完全限定的类名即可.</p>
<p>hbase.coordinated.state.manager.class<br>org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager<br>实现协调状态管理器的类的完全限定名称.</p>
<p>hbase.regionserver.storefile.refresh.period<br>0<br>刷新次区域存储文件的周期(以毫秒为单位).<br>0 表示此功能已禁用.<br>一旦次要区域刷新区域中的文件列表(没有通知机制),次要区域就会看到来自主要区域的新文件(来自刷新和压缩).<br>但过于频繁的刷新可能会导致额外的 Namenode 压力.<br>如果文件刷新时间不能超过 HFile TTL (hbase.master.hfilecleaner.ttl),则请求将被拒绝.<br>还建议使用此设置将 HFile TTL 配置为更大的值.</p>
<p>hbase.region.replica.replication.enabled<br>false<br>是否启用到次要区域副本的异步 WAL 复制.<br>如果启用,将创建一个名为&quot;region_replica_replication&quot;的复制对等体,它将跟踪日志并将突变复制到区域复制&gt; 1 的表的区域副本.<br>如果启用一次,禁用此复制也需要禁用复制peer 使用 shell 或 ReplicationAdmin java 类.<br>对次要区域副本的复制通过标准的集群间复制进行.<br>因此,如果明确禁用复制,也必须通过将&quot;hbase.replication&quot;设置为 true 来启用此功能才能工作.</p>
<p>hbase.http.filter.initializers<br>org.apache.hadoop.hbase.http.lib.StaticUserWebFilter<br>以逗号分隔的类名列表.<br>列表中的每个类都必须扩展 org.apache.hadoop.hbase.http.FilterInitializer.<br>对应的Filter会被初始化.<br>然后,过滤器将应用于所有面向用户的 jsp 和 servlet 网页.<br>列表的顺序定义了过滤器的顺序.<br>默认的 StaticUserWebFilter 添加由 hbase.http.staticuser.user 属性定义的用户主体.</p>
<p>hbase.security.visibility.mutations.checkauths<br>false<br>如果启用此属性,将检查可见性表达式中的标签是否与发出突变的用户相关联</p>
<p>hbase.http.max.threads<br>10<br>HTTP 服务器将在其线程池中创建的最大线程数.</p>
<p>hbase.replication.rpc.codec<br>org.apache.hadoop.hbase.codec.KeyValueCodecWithTags<br>启用复制时要使用的编解码器,以便也复制标签.<br>这与支持其中标签的 HFileV3 一起使用.<br>如果不使用标签或者使用的 hfile 版本是 HFileV2,那么 KeyValueCodec 可以用作复制编解码器.<br>请注意,在没有标签时使用 KeyValueCodecWithTags 进行复制不会造成任何危害.</p>
<p>hbase.replication.source.maxthreads<br>10<br>任何复制源将用于将编辑并行传送到接收器的最大线程数.<br>这也限制了每个复制批次被分成的块数.<br>较大的值可以提高主从集群之间的复制吞吐量.<br>默认值 10 很少需要更改.</p>
<h3 id="web"><a href="#web" class="headerlink" title="web"></a>web</h3><p>hbase.http.staticuser.user<br>dr.stack<br>在呈现内容时在静态 Web 过滤器上过滤的用户名.<br>一个示例使用是 HDFS Web UI(用于浏览文件的用户).</p>
<p>hbase.master.normalizer.class<br>org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer<br>用于在周期发生时执行区域归一化的类.<br>有关其工作原理的更多信息,请参阅类评论<a target="_blank" rel="noopener" href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.html">http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.html</a></p>
<p>hbase.regionserver.handler.abort.on.error.percent<br>0.5<br>未能中止 RS 的区域服务器 RPC 线程的百分比.<br>-1 禁用中止.<br>0 中止,即使一个处理程序已经死亡.<br>0.x 仅当此百分比的处理程序死亡时才中止.<br>1 仅中止所有处理程序都已死亡.</p>
<p>hbase.snapshot.master.timeout.millis<br>300000<br>主快照过程执行超时</p>
<p>hbase.snapshot.region.timeout<br>300000<br>区域服务器超时以保持快照请求池中的线程等待</p>
<h3 id="wal"><a href="#wal" class="headerlink" title="wal"></a>wal</h3><p>hbase.wal.provider<br>multiwal<br>允许RegionServer通过在底层HDFS实例中使用多个管道并行写入多个WAL流,这增加了写入期间的总吞吐量.<br>这种并行化是通过按区域划分传入编辑来完成的.<br>因此当前的实现无助于增加单个区域的吞吐量.<br>禁用时,取消该配置</p>
<p>hbase.hlog.split.skip.errors<br>false<br>传播EOFException异常并将拆分记录为失败.<br>设置为true时,将记录拆分过程中遇到的任何错误,有问题的WAL日志将被移动到hbase下的.corruptrootdir目录中,WAL的处理将继续.</p>
<p>hbase.master.distributed.log.splitting<br>true<br>分布式日志拆分</p>
<p>hbase.master.distributed.log.replay<br>true<br>启用分布式日志重播,必须启用HFile版本3</p>
<h3 id="timeout"><a href="#timeout" class="headerlink" title="timeout"></a>timeout</h3><p><font color="red">hbase.rpc.timeout</font><br>60000<br>这是为了让 RPC 层定义 HBase 客户端应用程序需要多长时间(毫秒)进行远程调用超时.<br>它使用 ping 检查连接,但最终会抛出 TimeoutException.<br><font color="blue">限制单个 RPC 调用在超时前可以运行多长时间</font>.</p>
<p><font color="red">hbase.client.operation.timeout</font><br>1200000<br>操作超时是一个顶级限制(毫秒),确保 Table 中的阻塞操作不会被阻塞超过此时间.<br>在每次操作中,如果rpc请求因为超时(hbase.rpc.timeout)或其他原因失败,将重试直到成功或抛出RetriesExhaustedException(hbase.client.operation.timeout).<br>但是如果在重试耗尽之前阻塞的总时间达到操作超时,它会提前中断并抛出SocketTimeoutException.</p>
<p>hbase.client.meta.operation.timeout<br>系统表的客户端操作超时可以通过设置配置值进行微调.<br>如果未设置,则其值将使用hbase.client.operation.timeout.</p>
<p><font color="red">hbase.client.scanner.timeout.period</font><br>60000<br>客户端扫描仪租用期(以毫秒为单位).</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hbase/" rel="tag"># hbase</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/03/03/hive%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/" rel="prev" title="hive默认配置参数">
                  <i class="fa fa-chevron-left"></i> hive默认配置参数
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/03/03/hive%20mysql8%20row_number/" rel="next" title="hive mysql8 row_number">
                  hive mysql8 row_number <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
