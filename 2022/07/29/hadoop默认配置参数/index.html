<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="yarn-site.xmlhadoop.registry.jaas.contextClient定义 JAAS 上下文的键.在安全模式下使用">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop默认配置参数">
<meta property="og:url" content="https://maoeryu.github.io/2022/07/29/hadoop%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="yarn-site.xmlhadoop.registry.jaas.contextClient定义 JAAS 上下文的键.在安全模式下使用">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-07-28T16:00:00.000Z">
<meta property="article:modified_time" content="2022-09-06T07:53:16.559Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://maoeryu.github.io/2022/07/29/hadoop%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>hadoop默认配置参数 | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#yarn-site-xml"><span class="nav-number">1.</span> <span class="nav-text">yarn-site.xml</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapred-site-xml"><span class="nav-number">2.</span> <span class="nav-text">mapred-site.xml</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hdfs-site-xml"><span class="nav-number">3.</span> <span class="nav-text">hdfs-site.xml</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#core-site-xml"><span class="nav-number">4.</span> <span class="nav-text">core-site.xml</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8"><span class="nav-number">4.1.</span> <span class="nav-text">常用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#authentication"><span class="nav-number">4.2.</span> <span class="nav-text">authentication</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#security"><span class="nav-number">4.3.</span> <span class="nav-text">security</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ssl"><span class="nav-number">4.4.</span> <span class="nav-text">ssl</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#s3%E7%9B%B8%E5%85%B3"><span class="nav-number">4.5.</span> <span class="nav-text">s3相关</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tfile"><span class="nav-number">4.6.</span> <span class="nav-text">tfile</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">220</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2022/07/29/hadoop%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hadoop默认配置参数
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-29 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-29T00:00:00+08:00">2022-07-29</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-09-06 15:53:16" itemprop="dateModified" datetime="2022-09-06T15:53:16+08:00">2022-09-06</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%8F%E5%90%8C%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">协同框架</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h2><p>hadoop.registry.jaas.context<br>Client<br>定义 JAAS 上下文的键.在安全模式下使用</p>
<span id="more"></span>

<p>hadoop.registry.kerberos.realm<br>未配置<br>kerberos领域:用于设置系统主体不声明其领域的领域,以及任何其他需要该值的帐户.如果为空,则使用正在运行的进程的默认域.如果两者都不知道并且需要领域,那么注册服务/客户端将失败.</p>
<p>hadoop.registry.rm.enabled<br>FALSE<br>是否启用注册表:RM 是否启动它,创建用户和系统路径,并在容器/应用程序尝试和应用程序完成时清除服务记录</p>
<p>hadoop.registry.secure<br>FALSE<br>注册表是否安全时要设置的键.打开它会将权限策略从&quot;开放访问&quot;更改为对 kerberos 的限制,用户可以选择在自己的树中添加一个或多个身份验证密钥对.</p>
<p>hadoop.registry.system.acls<br>sasl:yarn@, sasl:mapred@, sasl:mapred@hdfs@<br>Zookeeper ACL 标识符的逗号分隔列表,具有对安全集群中注册表的系统访问权限.这些被授予对所有条目的完全访问权限.如果 SASL 条目的末尾有一个&quot;@&quot;,它会指示注册表客户端附加默认的 kerberos 域.</p>
<p>hadoop.registry.zk.connection.timeout.ms<br>15000<br>Zookeeper 会话超时(以毫秒为单位)</p>
<p>hadoop.registry.zk.quorum<br>localhost:2181<br>为注册表定义 Zookeeper 仲裁绑定的主机名:端口对列表</p>
<p>hadoop.registry.zk.retry.ceiling.ms<br>60000<br>Zookeeper 重试限制,以毫秒为单位,在指数退避期间:{@value} 即使重试次数和间隔限制与退避策略相结合,也会设置一个限制,导致重试周期较长</p>
<p>hadoop.registry.zk.retry.interval.ms<br>1000</p>
<p>hadoop.registry.zk.retry.times<br>5<br>失败前的 Zookeeper 连接重试次数</p>
<p>hadoop.registry.zk.root<br>/registry</p>
<p>hadoop.registry.zk.session.timeout.ms<br>60000<br>Zookeeper 会话超时(以毫秒为单位)</p>
<p>mapreduce.job.hdfs-servers<br>${fs.defaultFS}</p>
<p>mapreduce.job.jar<br>未配置</p>
<p>yarn.acl.enable<br>FALSE<br>是否启用了 acls.</p>
<p>yarn.admin.acl<br><code>*</code><br>谁可以成为 YARN 集群的管理员的 ACL.</p>
<p>yarn.am.liveness-monitor.expiry-interval-ms<br>600000<br>应用程序主报告的到期间隔.</p>
<p><font color="#dd0000">yarn.application.classpath</font><br>未配置<br>YARN 应用程序的 CLASSPATH.以逗号分隔的 CLASSPATH 条目列表.当此值为空时,将使用 YARN 应用程序的以下默认 CLASSPATH.对于 <code>Linux:$HADOOP_CONF_DIR/$HADOOP_COMMON_HOME/share/hadoop/common/*/$HADOOP_COMMON_HOME/share/hadoop/common/lib/*/$HADOOP_HDFS_HOME/share/hadoop/hdfs/*/$HADOOP_HDFS_HOME/share/hadoop/hdfs/ lib/*/$HADOOP_YARN_HOME/share/hadoop/yarn/*/$HADOOP_YARN_HOME/share/hadoop/yarn/lib/* 对于 Windows:%HADOOP_CONF_DIR%/%HADOOP_COMMON_HOME%/share/hadoop/common/*/%HADOOP_COMMON_HOME%/共享/hadoop/common/lib/*, %HADOOP_HDFS_HOME%/share/hadoop/hdfs/*, %HADOOP_HDFS_HOME%/share/hadoop/hdfs/lib/*, %HADOOP_YARN_HOME%/share/hadoop/yarn/*</code>,</p>
<p>yarn.client.application-client-protocol.poll-interval-ms<br>200<br>yarn 客户端库用于轮询应用程序客户端协议异步 API 完成状态的时间间隔.</p>
<p>yarn.client.failover-max-attempts<br>未配置<br>启用 HA 时,FailoverProxyProvider 应尝试故障转移的最大次数.设置后,它会覆盖 yarn.resourcemanager.connect.max-wait.ms.如果未设置,则从 yarn.resourcemanager.connect.max-wait.ms 推断.</p>
<p><font color="#dd0000">yarn.client.failover-proxy-provider</font><br>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider<br>启用 HA 时,客户端/AM 和 NM 用于故障转移到活动 RM 的类.它应该扩展 org.apache.hadoop.yarn.client.RMFailoverProxyProvider</p>
<p>yarn.client.failover-retries<br>0<br>启用 HA 时,每次尝试连接到 ResourceManager 的重试次数.换句话说,它是在故障转移尝试期间使用的 ipc.client.connect.max.retries</p>
<p>yarn.client.failover-retries-on-socket-timeouts<br>0<br>启用 HA 时,在套接字超时时每次尝试连接到 ResourceManager 的重试次数.换句话说,它是在故障转移尝试期间使用的 ipc.client.connect.max.retries.on.timeouts</p>
<p>yarn.client.failover-sleep-base-ms<br>未配置<br>启用 HA 时,用于计算故障转移之间的指数延迟的睡眠基准(以毫秒为单位).设置后,这会覆盖 yarn.resourcemanager.connect.* 设置.如果未设置,则使用 yarn.resourcemanager.connect.retry-interval.ms 代替.</p>
<p>yarn.client.failover-sleep-max-ms<br>未配置<br>启用 HA 时,故障转移之间的最大睡眠时间(以毫秒为单位).设置后,这会覆盖 yarn.resourcemanager.connect.* 设置.如果未设置,则使用 yarn.resourcemanager.connect.retry-interval.ms 代替.</p>
<p>yarn.client.max-cached-nodemanagers-proxies<br>0<br>为节点管理器缓存的最大代理连接数.如果设置为大于零的值,则启用缓存,NMClient 和 MRAppMaster 将缓存指定数量的节点管理器代理.每个节点管理器最多有一个代理.前任.将其配置为 5 将确保客户端最多有 5 个代理缓存与 5 个不同的节点管理器.如果空闲时间超过系统范围的空闲超时期限,这些代理的这些连接将超时.请注意,这可能会导致大型集群出现问题,因为许多连接可能同时存在并导致大量连接线程.用于身份验证的令牌将仅在连接创建时使用.如果收到新令牌,则应关闭较早的连接以使用新令牌.这和 (yarn.client.nodemanager-client-async.thread-pool-max-size) 是相关的并且应该是同步的(不需要它们相等).如果此属性的值为零,则禁用连接缓存,并且连接将使用零空闲超时来防止大型集群上的连接线程过多.</p>
<p>yarn.client.nodemanager-client-async.thread-pool-max-size<br>500<br>NMClientAsync 中处理容器管理事件的最大线程数</p>
<p>yarn.client.nodemanager-connect.max-wait-ms<br>180000<br>等待与 NM 建立连接的最长时间</p>
<p>yarn.client.nodemanager-connect.retry-interval-ms<br>10000<br>每次尝试连接到 NM 之间的时间间隔</p>
<p>yarn.dispatcher.drain-events.timeout<br>300000<br>YARN 调度程序尝试耗尽事件时的超时时间(以毫秒为单位).通常,这发生在服务停止时.例如,RM 在停止时会耗尽 ATS 事件调度程序.</p>
<p>yarn.fail-fast<br>FALSE<br>如果 YARN 遇到任何错误,它是否应该快速失败.这是所有其他组件的全局配置,包括 RM/NM 等.如果没有为组件特定的配置设置值(例如 yarn.resourcemanager.fail-fast),则该值将是默认值.</p>
<p>yarn.http.policy<br>HTTP_ONLY<br>这将为 Yarn Daemons 配置 HTTP 端点.支持以下值: - HTTP_ONLY :仅在 http 上提供服务 - HTTPS_ONLY :仅在 https 上提供服务</p>
<p>yarn.ipc.client.factory.class<br>未配置<br>工厂创建客户端 IPC 类.</p>
<p>yarn.ipc.record.factory.class<br>未配置<br>工厂创建可序列化的记录.</p>
<p>yarn.ipc.rpc.class<br>org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC<br>RPC 类实现</p>
<p>yarn.ipc.server.factory.class<br>未配置<br>工厂创建服务器 IPC 类.</p>
<p>yarn.log-aggregation.retain-check-interval-seconds<br>-1<br>汇总日志保留检查之间的等待时间.如果设置为 0 或负值,则该值被计算为聚合日志保留时间的十分之一.小心将其设置得太小,您将向名称节点发送垃圾邮件.</p>
<p><font color="#dd0000">yarn.log-aggregation.retain-seconds</font><br>-1<br>在删除聚合日志之前保留多长时间.-1 禁用.小心将其设置得太小,您将向名称节点发送垃圾邮件.</p>
<p><font color="#dd0000">yarn.log-aggregation-enable</font><br>FALSE<br>是否开启日志聚合.日志聚合收集每个容器的日志,并在应用程序完成后将这些日志移动到文件系统,例如 HDFS.用户可以配置&quot;yarn.nodemanager.remote-app-log-dir&quot;和&quot;yarn.nodemanager.remote-app-log-dir-suffix&quot;属性来确定这些日志的移动位置.用户可以通过 Application Timeline Server 访问日志.</p>
<p>yarn.nm.liveness-monitor.expiry-interval-ms<br>600000<br>等待节点管理器被认为死了多长时间.</p>
<p>yarn.nodemanager.address<br>${yarn.nodemanager.hostname}:0<br>NM中容器管理器的地址.</p>
<p>yarn.nodemanager.admin-env<br>MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX<br>应该从 NodeManager 的环境转发到容器的环境变量.</p>
<p><font color="#dd0000">yarn.nodemanager.aux-services</font><br>未配置<br>有效的服务名称只能包含 a-zA-Z0-9_ 并且不能以数字开头</p>
<p><font color="#dd0000">yarn.nodemanager.aux-services.mapreduce_shuffle.class</font><br>org.apache.hadoop.mapred.ShuffleHandler</p>
<p>yarn.nodemanager.bind-host<br>未配置<br>服务器将绑定到的实际地址.如果设置了这个可选地址,RPC 和 webapp 服务器将分别绑定到这个地址和 yarn.nodemanager.address 和 yarn.nodemanager.webapp.address 中指定的端口.这对于通过设置为 0.0.0.0 使 NM 侦听所有接口非常有用.</p>
<p>yarn.nodemanager.container-executor.class<br>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor<br>谁将执行(启动)容器.</p>
<p>yarn.nodemanager.container-manager.thread-count<br>20<br>容器管理器使用的线程数.</p>
<p>yarn.nodemanager.container-monitor.interval-ms<br>3000<br>多久监控一次容器.</p>
<p>yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled<br>FALSE<br>通过 /proc/pid/stat 计算的进程的 RSS 使用不是很准确,因为它包括进程的共享页面./proc/pid/smaps 提供有用的信息,如 Private_Dirty/Private_Clean/Shared_Dirty/Shared_Clean,可用于计算更准确的 RSS.启用此标志时,RSS 计算为 Min(Shared_Dirty, Pss) + Private_Clean + Private_Dirty.它不包括 RSS 计算中的只读共享映射.</p>
<p>yarn.nodemanager.container-monitor.resource-calculator.class<br>未配置<br>计算容器当前资源利用率的类.</p>
<p>yarn.nodemanager.delete.debug-delay-sec<br>0<br>应用程序完成后节点管理器的 DeletionService 将删除应用程序的本地化文件目录和日志目录之前的秒数.要诊断 Yarn 应用程序问题,请将此属性的值设置得足够大(例如,设置为 600 = 10 分钟)以允许检查这些目录.更改属性值后,您必须重新启动节点管理器才能使其生效.Yarn 应用程序工作目录的根可通过 yarn.nodemanager.local-dirs 属性(见下文)进行配置,Yarn 应用程序日志目录的根可通过 yarn.nodemanager.log-dirs 属性(另见以下).</p>
<p>yarn.nodemanager.delete.thread-count<br>4<br>清理中使用的线程数.</p>
<p>yarn.nodemanager.disk-health-checker.interval-ms<br>120000<br>运行磁盘健康检查器代码的频率.</p>
<p>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage<br>90<br>磁盘被标记为坏时允许的最大磁盘空间利用率百分比.值的范围可以从 0.0 到 100.0.如果该值大于或等于 100,则节点管理器将检查磁盘是否已满.这适用于 yarn.nodemanager.local-dirs 和 yarn.nodemanager.log-dirs.</p>
<p>yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb<br>0<br>磁盘上必须可用的最小空间才能使用它.这适用于 yarn.nodemanager.local-dirs 和 yarn.nodemanager.log-dirs.</p>
<p>yarn.nodemanager.disk-health-checker.min-healthy-disks<br>0.25<br>节点管理器启动新容器时健康的磁盘数量的最小比例.这对应于 yarn.nodemanager.local-dirs 和 yarn.nodemanager.log-dirs.即,如果可用的健康本地目录(或日志目录)数量较少,则不会在此节点上启动新容器.</p>
<p>yarn.nodemanager.docker-container-executor.exec-name<br>/usr/bin/docker<br>Docker 客户端的名称或路径.</p>
<p>yarn.nodemanager.env-whitelist<br>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME<br>容器可能会覆盖而不是使用 NodeManager 的默认值的环境变量.</p>
<p>yarn.nodemanager.health-checker.interval-ms<br>600000<br>运行节点健康脚本的频率.</p>
<p>yarn.nodemanager.health-checker.script.opts<br>未配置<br>要传递给运行状况检查脚本的参数.</p>
<p>yarn.nodemanager.health-checker.script.path<br>未配置<br>要运行的运行状况检查脚本.</p>
<p>yarn.nodemanager.health-checker.script.timeout-ms<br>1200000<br>脚本超时时间.</p>
<p>yarn.nodemanager.hostname<br>0.0.0.0<br>NM 的主机名.</p>
<p>yarn.nodemanager.keytab<br>/etc/krb5.keytab<br>NM 的密钥表.</p>
<p>yarn.nodemanager.linux-container-executor.cgroups.hierarchy<br>/hadoop-yarn<br>放置 YARN 进程的 cgroups 层次结构(不能包含逗号).如果 yarn.nodemanager.linux-container-executor.cgroups.mount 为 false(也就是说,如果 cgroups 已经预先配置),那么这个 cgroups 层次结构必须已经存在并且可以被 NodeManager 用户写入,否则 NodeManager 可能会失败.仅当 LCE 资源处理程序设置为 CgroupsLCEResourcesHandler 时使用.</p>
<p>yarn.nodemanager.linux-container-executor.cgroups.mount<br>FALSE<br>如果没有找到,LCE 是否应该尝试挂载 cgroup.仅当 LCE 资源处理程序设置为 CgroupsLCEResourcesHandler 时使用.</p>
<p>yarn.nodemanager.linux-container-executor.cgroups.mount-path<br>未配置<br>如果未找到 LCE 应尝试挂载 cgroups 的位置.常见位置包括 /sys/fs/cgroup 和 /cgroup；默认位置可能因使用的 Linux 发行版而异.在启动 NodeManager 之前,该路径必须存在.仅当 LCE 资源处理程序设置为 CgroupsLCEResourcesHandler 并且 yarn.nodemanager.linux-container-executor.cgroups.mount 为 true 时使用.</p>
<p>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage<br>FALSE<br>此标志确定应用程序是否应在严格的资源限制下运行,或者是否允许在需要时消耗备用资源.例如,打开标志将限制应用程序仅使用它们的 CPU 份额,即使节点有空闲 CPU 周期.默认值为假,即使用可用资源.请注意,打开此标志可能会降低集群上的作业吞吐量.</p>
<p>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users<br>TRUE<br>这决定了 LCE 应该在非安全集群上使用两种模式中的哪一种.如果此值设置为 true,则所有容器都将以 yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user 中指定的用户身份启动.如果此值设置为 false,则容器将以提交应用程序的用户身份运行.</p>
<p>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user<br>nobody<br>如果设置了 yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users,则容器将在非安全模式下使用 Linux-container-executor 时运行的 UNIX 用户(一个用例是使用 cgroups)为真.</p>
<p>yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern<br><code>^[_.A-Za-z0-9][-@_.A-Za-z0-9]&#123;0,255&#125;?[$]?$</code><br>在非安全模式下使用时由 Linux-container-executor 强制执行的 UNIX 用户名的允许模式(此用例是使用 cgroups).默认值取自 /usr/sbin/adduser</p>
<p>yarn.nodemanager.linux-container-executor.path<br>未配置<br>Linux 容器执行器的路径.</p>
<p>yarn.nodemanager.linux-container-executor.resources-handler.class<br>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler<br>应该帮助 LCE 处理资源的类.</p>
<p>yarn.nodemanager.local-cache.max-files-per-directory<br>8192<br>它限制了将在单个本地目录中本地化的文件的最大数量.如果达到限制,则将创建子目录并在其中本地化新文件.如果将其设置为小于或等于 36 [这是子目录(0-9 和 az)] 的值,则 NodeManager 将无法启动.例如;[用于公共缓存] 如果配置为 40(4 个文件 + 36 个子目录)并且本地目录是&quot;/tmp/local-dir1&quot;,那么它将允许直接在&quot;/&quot;中创建 4 个文件tmp/local-dir1/filecache&quot;.对于进一步本地化的文件,它将在&quot;/tmp/local-dir1/filecache&quot;内创建一个子目录&quot;0&quot;,并将本地化其中的文件直到它变满.</p>
<p><font color="#dd0000">yarn.nodemanager.local-dirs</font><br><code>$&#123;hadoop.tmp.dir&#125;</code>/nm-local-dir<br>存储本地化文件的目录列表.应用程序的本地化文件目录位于:<code>$&#123;yarn.nodemanager.local-dirs&#125;/usercache/$&#123;user&#125;/appcache/application_$&#123;appid&#125;</code>.各个容器的工作目录,称为 container_${contid},将是它的子目录.</p>
<p>yarn.nodemanager.localizer.address<br>${yarn.nodemanager.hostname}:8040<br>定位器 IPC 所在的地址.</p>
<p>yarn.nodemanager.localizer.cache.cleanup.interval-ms<br>600000<br>缓存清理之间的间隔.</p>
<p>yarn.nodemanager.localizer.cache.target-size-mb<br>10240<br>每个节点管理器的定位器缓存目标大小(以 MB 为单位).它是一个目标保留大小,仅包括具有 PUBLIC 和 PRIVATE 可见性的资源,不包括具有 APPLICATION 可见性的资源</p>
<p>yarn.nodemanager.localizer.client.thread-count<br>5<br>处理本地化请求的线程数.</p>
<p>yarn.nodemanager.localizer.fetch.thread-count<br>4<br>用于本地化获取的线程数.</p>
<p>yarn.nodemanager.log.retain-seconds<br>10800<br>保留用户日志的时间(以秒为单位).仅在禁用日志聚合时适用</p>
<p>yarn.nodemanager.log-aggregation.compression-type<br>none<br>用于压缩聚合日志的 T 文件压缩类型.</p>
<p>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds<br>-1<br>定义 NM 唤醒上传日志文件的频率.默认值为 -1.默认情况下,日志将在应用程序完成后上传.通过设置此配置,可以在应用程序运行时定期上传日志.可以设置的最小滚动间隔秒数为 3600.</p>
<p><font color="#dd0000">yarn.nodemanager.log-dirs</font><br>${yarn.log.dir}/userlogs<br>在哪里存储容器日志.应用程序的本地化日志目录将在 ${yarn.nodemanager.log-dirs}/application_${appid} 中找到.各个容器的日志目录将在此之下,在名为 container_{$contid} 的目录中.每个容器目录将包含该容器生成的文件 stderr/stdin 和 syslog.</p>
<p><font color="#dd0000">yarn.nodemanager.pmem-check-enabled</font><br>TRUE<br>是否将对容器实施物理内存限制.</p>
<p>yarn.nodemanager.principal<br>未配置<br>节点管理器的 kerberos 主体.</p>
<p>yarn.nodemanager.process-kill-wait.ms<br>2000<br>尝试清理容器时等待进程启动的最长时间</p>
<p>yarn.nodemanager.recovery.compaction-interval-secs<br>3600<br>NM 状态数据库完全压缩之间的时间(以秒为单位).将间隔设置为零会禁用完整的压缩周期.</p>
<p>yarn.nodemanager.recovery.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/yarn-nm-recovery<br>启用恢复时节点管理器将存储状态的本地文件系统目录.</p>
<p>yarn.nodemanager.recovery.enabled<br>FALSE<br>使节点管理器启动后恢复</p>
<p>yarn.nodemanager.remote-app-log-dir<br>/tmp/logs<br>将日志聚合到哪里.</p>
<p>yarn.nodemanager.remote-app-log-dir-suffix<br>logs<br>远程日志目录将在 {yarn.nodemanager.remote-app-log-dir}/${user}/{thisParam} 创建</p>
<p><font color="#dd0000">yarn.nodemanager.resource.cpu-vcores</font><br>8<br>可以为容器分配的 vcore 数量.这由 RM 调度程序在为容器分配资源时使用.这不是用来限制 YARN 容器使用的物理内核的数量.</p>
<p><font color="#dd0000">yarn.nodemanager.resource.memory-mb</font><br>8192<br>可以为容器分配的物理内存量(以 MB 为单位).</p>
<p>yarn.nodemanager.resource.percentage-physical-cpu-limit<br>100<br>可分配给容器的 CPU 百分比.此设置允许用户限制 YARN 容器使用的 CPU 量.目前仅在使用 cgroups 的 Linux 上起作用.默认是使用 100% 的 CPU.</p>
<p>yarn.nodemanager.resourcemanager.minimum.version<br>NONE<br>节点管理器将连接到的资源管理器的最低允许版本.有效值为 NONE(无版本检查)/EqualToNM(资源管理器的版本等于或大于 NM 版本)或版本字符串.</p>
<p>yarn.nodemanager.sleep-delay-before-sigkill.ms<br>250<br>在向容器发送 SIGTERM 和 SIGKILL 之间等待的毫秒数</p>
<p><font color="#dd0000">yarn.nodemanager.vmem-check-enabled</font><br>TRUE<br>是否将对容器实施虚拟内存限制.</p>
<p><font color="#dd0000">yarn.nodemanager.vmem-pmem-ratio</font><br>2.1<br>为容器设置内存限制时,虚拟内存与物理内存之间的比率.容器分配是用物理内存来表示的,虚拟内存的使用量是允许超过这个比例的.</p>
<p>yarn.nodemanager.webapp.address<br>${yarn.nodemanager.hostname}:8042<br>NM Webapp 地址.</p>
<p><font color="#dd0000">yarn.resourcemanager.address</font><br>${yarn.resourcemanager.hostname}:8032<br>RM 中应用程序管理器接口的地址.</p>
<p><font color="#dd0000">yarn.resourcemanager.admin.address</font><br>${yarn.resourcemanager.hostname}:8033<br>RM 管理界面的地址.</p>
<p>yarn.resourcemanager.admin.client.thread-count<br>1<br>用于处理 RM 管理界面的线程数.</p>
<p>yarn.resourcemanager.am.max-attempts<br>2<br>应用程序尝试的最大次数.这是所有应用程序主机的全局设置.每个应用程序主机可以通过 API 指定其单独的最大应用尝试次数,但单独的次数不能超过全局上限.如果是,资源管理器将覆盖它.默认数字设置为 2,以允许 AM 至少重试一次.</p>
<p>yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs<br>86400<br>用于生成应用程序令牌的主密钥的翻转间隔</p>
<p>yarn.resourcemanager.bind-host<br>未配置<br>服务器将绑定到的实际地址.如果设置了这个可选地址,RPC 和 webapp 服务器将分别绑定到这个地址和 yarn.resourcemanager.address 和 yarn.resourcemanager.webapp.address 中指定的端口.这对于通过设置为 0.0.0.0 使 RM 侦听所有接口非常有用.</p>
<p>yarn.resourcemanager.client.thread-count<br>50<br>用于处理应用程序管理器请求的线程数.</p>
<p><font color="#dd0000">yarn.resourcemanager.cluster-id</font><br>未配置<br>集群的名称.在 HA 设置中,这用于确保 RM 参与此集群的领导者选举,并确保它不会影响其他集群</p>
<p>yarn.resourcemanager.configuration.provider-class<br>org.apache.hadoop.yarn.LocalConfigurationProvider<br>用作配置提供程序的类.如果使用 org.apache.hadoop.yarn.LocalConfigurationProvider,则会加载本地配置.如果使用 org.apache.hadoop.yarn.FileSystemBasedConfigurationProvider,需要先将要加载的配置上传到远程文件系统.</p>
<p>yarn.resourcemanager.connect.max-wait.ms<br>900000<br>等待建立与 ResourceManager 的连接的最长时间.</p>
<p><font color="#dd0000">yarn.resourcemanager.connect.retry-interval.ms</font><br>30000<br>尝试连接到 ResourceManager 的频率.</p>
<p>yarn.resourcemanager.container.liveness-monitor.interval-ms<br>600000<br>多久检查一次容器是否还活着.</p>
<p>yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs<br>86400<br>用于生成容器令牌的主密钥的翻转间隔.预计会比 yarn.nm.liveness-monitor.expiry-interval-ms 和 yarn.rm.container-allocation.expiry-interval-ms 大得多.否则行为未定义.</p>
<p>yarn.resourcemanager.delayed.delegation-token.removal-interval-ms<br>30000<br>延迟令牌删除线程运行的时间间隔</p>
<p>yarn.resourcemanager.fail-fast<br>${yarn.fail-fast}<br>如果 RM 遇到任何错误,它是否应该快速失败.默认情况下,它指向 ${yarn.fail-fast}.错误包括:1)状态存储写/读操作失败时的异常.</p>
<p>yarn.resourcemanager.fs.state-store.retry-policy-spec<br>2000, 500<br>hdfs 客户端重试策略规范.hdfs 客户端重试始终处于启用状态.成对指定 sleep-time 和 number-of-retries 和 (t0, n0), (t1, n1), ...,前 n0 次重试平均睡眠 t0 毫秒,后面 n1 次重试平均睡眠 t1 毫秒,等等.</p>
<p>yarn.resourcemanager.fs.state-store.uri<br><code>$&#123;hadoop.tmp.dir&#125;</code>/yarn/system/rmstore<br>指向将存储 RM 状态的文件系统路径位置的 URI.当使用 org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore 作为 yarn.resourcemanager.store.class 的值时,必须提供此项</p>
<p>yarn.resourcemanager.ha.automatic-failover.embedded<br>TRUE<br>启用嵌入式自动故障转移.默认情况下,仅在启用 HA 时才启用.嵌入式选举器依赖 RM 状态存储来处理围栏,主要用于与 ZKRMStateStore 结合使用.</p>
<p><font color="#dd0000">yarn.resourcemanager.ha.automatic-failover.enabled</font><br>TRUE<br>启用自动故障转移.默认情况下,仅在启用 HA 时才启用</p>
<p><font color="#dd0000">yarn.resourcemanager.ha.automatic-failover.zk-base-path</font><br>/yarn-leader-election<br>使用基于 ZooKeeper 的领导者选举时,用于存储领导者信息的基本 znode 路径.</p>
<p><font color="#dd0000">yarn.resourcemanager.ha.enabled</font><br>FALSE<br>启用 RM 高可用性.启用后,(1) RM 默认在待机模式下启动,并在提示时转换到活动模式.(2) RM ensemble 中的节点在 yarn.resourcemanager.ha.rm-ids 中列出 (3) 如果明确指定了 yarn.resourcemanager.ha.id,每个 RM 的 id 要么来自 yarn.resourcemanager.ha.id或者可以通过匹配 yarn.resourcemanager.address.{id} 和本地地址来计算 (4) 实际的物理地址来自模式的配置 - {rpc-config}.{id}</p>
<p><font color="#">yarn.resourcemanager.ha.id</font><br>未配置<br>当前 RM 的 id(字符串).启用 HA 时,这是一个可选配置.当前 RM 的 id 可以通过显式指定 yarn.resourcemanager.ha.id 来设置,或者通过将 yarn.resourcemanager.address.{id} 与本地地址匹配来确定有关如何使用的完整详细信息,请参阅 yarn.resourcemanager.ha.enabled 的描述这是使用的.</p>
<p><font color="#dd0000">yarn.resourcemanager.ha.rm-ids</font><br>未配置<br>启用 HA 时集群中的 RM 节点列表.有关如何使用它的完整详细信息,请参阅 yarn.resourcemanager.ha .enabled 的描述.</p>
<p><font color="#dd0000">yarn.resourcemanager.hostname</font><br>0.0.0.0<br>RM 的主机名.</p>
<p>yarn.resourcemanager.keytab<br>/etc/krb5.keytab<br>资源管理器的密钥表.</p>
<p>yarn.resourcemanager.max-completed-applications<br>10000<br>RM 保留的已完成应用程序的最大数量.</p>
<p>yarn.resourcemanager.nodemanager.minimum.version<br>NONE<br>连接节点管理器的最低允许版本.有效值为 NONE(无版本检查)/EqualToRM(节点管理器的版本等于或大于 RM 版本)或版本字符串.</p>
<p>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms<br>1000<br>集群中每个 NodeManager 的心跳间隔(以毫秒为单位).</p>
<p><font color="#dd0000">yarn.resourcemanager.nodes.exclude-path</font><br>未配置<br>包含要排除的节点的文件路径.</p>
<p><font color="#dd0000">yarn.resourcemanager.nodes.include-path</font><br>未配置<br>包含要包含的节点的文件路径.</p>
<p>yarn.resourcemanager.principal<br>未配置<br>资源管理器的 Kerberos 主体.</p>
<p>yarn.resourcemanager.proxy-user-privileges.enabled<br>FALSE<br>如果为 true,ResourceManager 将拥有代理用户权限.用例:在安全集群中,YARN 要求用户 hdfs 委托令牌代表用户进行本地化和日志聚合.如果设置为 true,ResourceManager 能够代表用户请求新的 hdfs 委托令牌.长时间运行的服务需要这样做,因为 hdfs 令牌最终会过期,而 YARN 需要新的有效令牌来进行本地化和日志聚合.请注意,要启用此用例,相应的 HDFS NameNode 必须将 ResourceManager 配置为代理用户,以便 ResourceManager 可以在令牌超过其最大生命周期时代表用户请求新令牌.</p>
<p><font color="#dd0000">yarn.resourcemanager.recovery.enabled</font><br>FALSE<br>启用 RM 以在启动后恢复状态.如果为 true,则必须指定 yarn.resourcemanager.store.class.</p>
<p><font color="#dd0000">yarn.resourcemanager.resource-tracker.address</font><br>${yarn.resourcemanager.hostname}:8031</p>
<p>yarn.resourcemanager.resource-tracker.client.thread-count<br>50<br>处理资源跟踪器调用的线程数.</p>
<p><font color="#dd0000">yarn.resourcemanager.scheduler.address</font><br>${yarn.resourcemanager.hostname}:8030<br>调度程序接口的地址.</p>
<p>yarn.resourcemanager.scheduler.class<br>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br>用作资源调度程序的类.</p>
<p>yarn.resourcemanager.scheduler.client.thread-count<br>50<br>处理调度程序接口的线程数.</p>
<p>yarn.resourcemanager.scheduler.monitor.enable<br>FALSE<br>启用一组影响调度程序的定期监视器(在 yarn.resourcemanager.scheduler.monitor.policies 中指定).</p>
<p>yarn.resourcemanager.scheduler.monitor.policies<br>org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy<br>与调度程序交互的 SchedulingEditPolicy 类的列表.特定模块可能与调度程序/其他策略或两者的配置不兼容.</p>
<p>yarn.resourcemanager.state-store.max-completed-applications<br>${yarn.resourcemanager.max-completed-applications}<br>RM state store 保留的已完成应用程序的最大数量,小于或等于 ${yarn.resourcemanager.max-completed-applications}.默认情况下,它等于 ${yarn.resourcemanager.max-completed-applications}.这确保了保存在状态存储中的应用程序与记忆在 RM 内存中的应用程序是一致的.任何大于 ${yarn.resourcemanager.max-completed-applications} 的值都将重置为 ${yarn.resourcemanager.max-completed-applications}.请注意,此值会影响 RM 恢复性能.通常,较小的值表示 RM 恢复的性能更好.</p>
<p><font color="#dd0000">yarn.resourcemanager.store.class</font><br>org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore<br>用作持久存储的类.如果使用了 org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore,则存储是隐式隔离的；这意味着单个 ResourceManager 可以在任何时间点使用存储.有关此隐式防护以及设置适当 ACL 的更多详细信息,请参阅 yarn.resourcemanager.zk-state-store.root-node.acl.</p>
<p>yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size<br>10<br>发送纱线系统指标数据的工作线程数.</p>
<p><font color="#dd0000">yarn.resourcemanager.system-metrics-publisher.enabled</font><br>FALSE<br>控制纱线系统指标是否由 RM 发布在时间线服务器上的设置.</p>
<p><font color="#dd0000">yarn.resourcemanager.webapp.address</font><br>${yarn.resourcemanager.hostname}:8088<br>RM Web 应用程序的 http 地址.</p>
<p>yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled<br>TRUE<br>标记以启用使用 RM 身份验证过滤器覆盖默认 kerberos 身份验证过滤器,以允许使用委托令牌进行身份验证(如果缺少令牌,则回退到 kerberos).仅在 http 身份验证类型为 kerberos 时适用.</p>
<p>yarn.resourcemanager.webapp.https.address<br>${yarn.resourcemanager.hostname}:8090<br>RM Web 应用程序的 https 地址.</p>
<p>yarn.resourcemanager.work-preserving-recovery.enabled<br>FALSE<br>启用 RM 工作保留恢复.此配置是 YARN 专用的,用于试验该功能.</p>
<p>yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms<br>10000<br>设置 RM 在分配新容器之前等待的时间量.这样的等待期使 RM 有机会在恢复时与集群中的 NM 重新同步,然后再将新容器分配给应用程序.</p>
<p>yarn.resourcemanager.zk-acl<br>world:anyone:rwcda<br>用于 ZooKeeper znode 的 ACL.</p>
<p><font color="#dd0000">yarn.resourcemanager.zk-address</font><br>未配置<br>Host:RM 使用的 ZooKeeper 服务器的端口.当使用基于 ZooKeeper 的 RM 状态存储实现和/或 HA 设置中的嵌入式自动故障转移时,必须提供此信息.</p>
<p>yarn.resourcemanager.zk-auth<br>未配置<br>指定要用于在 yarn.resourcemanager.zk-acl 和 yarn.resourcemanager.zk-state-store.root-node.acl 属性中指定的 ACL 的身份验证.这需要一个以逗号分隔的身份验证机制列表,每个形式为&quot;scheme:auth&quot;(与 ZK CLI 中的&quot;addAuth&quot;命令使用的语法相同).</p>
<p>yarn.resourcemanager.zk-num-retries<br>1000<br>RM 尝试连接到 ZooKeeper 的次数.</p>
<p>yarn.resourcemanager.zk-retry-interval-ms<br>1000<br>连接到 ZooKeeper 时的重试间隔(以毫秒为单位).启用 HA 时,不使用此处的值.它是从 yarn.resourcemanager.zk-timeout-ms 和 yarn.resourcemanager.zk-num-retries 自动生成的.</p>
<p>yarn.resourcemanager.zk-state-store.parent-path<br>/rmstore<br>将存储 RM 状态的 ZooKeeper znode 的完整路径.当使用 org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore 作为 yarn.resourcemanager.store.class 的值时,必须提供此项</p>
<p>yarn.resourcemanager.zk-state-store.root-node.acl<br>未配置<br>在 HA 场景中使用 ZKRMStateStore 进行防护时用于根 znode 的 ACL.ZKRMStateStore 支持隐式防护以允许单个 ResourceManager 对存储进行写访问.对于 fencing,集群中的 ResourceManager 共享根节点上的读写管理员权限,但 Active ResourceManager 声称拥有独占的创建删除权限.默认情况下,如果未设置此属性,我们使用来自 yarn.resourcemanager.zk-acl 的 ACL 进行共享管理员访问,使用 rm-address:random-number 进行基于用户名的独占创建-删除访问.此属性允许用户设置他们选择的 ACL,而不是使用默认机制.为了击剑工作,</p>
<p>yarn.resourcemanager.zk-timeout-ms<br>10000<br>ZooKeeper 会话超时(以毫秒为单位).会话过期由 ZooKeeper 集群本身管理,而不是由客户端管理.集群使用此值来确定客户端会话何时到期.当集群在指定的会话超时期限(即没有心跳)内没有收到客户端的消息时,就会发生过期.</p>
<p><font color="#dd0000">yarn.scheduler.maximum-allocation-mb</font><br>8192<br>RM 上每个容器请求的最大分配,以 MB 为单位.高于此值的内存请求将不会生效,并将被限制为该值.</p>
<p><font color="#dd0000">yarn.scheduler.maximum-allocation-vcores</font><br>32<br>RM 上每个容器请求的最大分配,以虚拟 CPU 内核计.高于此值的请求将不会生效,并将被限制为该值.</p>
<p><font color="#dd0000">yarn.scheduler.minimum-allocation-mb</font><br>1024<br>RM 上每个容器请求的最小分配,以 MB 为单位.低于此值的内存请求将不会生效,并且将至少分配指定的值.</p>
<p>yarn.scheduler.minimum-allocation-vcores<br>1<br>RM 中每个容器请求的最小分配,以虚拟 CPU 内核计.低于此值的请求将不会生效,并且指定的值将被分配到最小值.</p>
<p><font color="#dd0000">yarn.timeline-service.address</font><br>${yarn.timeline-service.hostname}:10200<br>这是时间线服务器启动 RPC 服务器的默认地址.</p>
<p>yarn.timeline-service.bind-host<br>未配置<br>服务器将绑定到的实际地址.如果设置了这个可选地址,RPC 和 webapp 服务器将分别绑定到这个地址和 yarn.timeline-service.address 和 yarn.timeline-service.webapp.address 中指定的端口.这对于通过设置为 0.0.0.0 使服务侦听所有接口非常有用.</p>
<p>yarn.timeline-service.client.max-retries<br>30<br>时间线服务客户端的默认最大退休次数.</p>
<p>yarn.timeline-service.client.retry-interval-ms<br>1000<br>时间线服务客户端的默认重试时间间隔.</p>
<p><font color="#dd0000">yarn.timeline-service.enabled</font><br>FALSE<br>向客户端指示是否启用了时间线服务.如果启用,客户端会将实体和事件放入时间线服务器.</p>
<p>yarn.timeline-service.generic-application-history.max-applications<br>10000<br>定义可以使用 REST API 或应用程序历史协议获取并显示在时间线服务器 Web ui 中的最大应用程序数量.</p>
<p><font color="#dd0000">yarn.timeline-service.handler-thread-count</font><br>10<br>处理客户端 RPC 请求的处理程序线程计数.</p>
<p><font color="#dd0000">yarn.timeline-service.hostname</font><br>0.0.0.0<br>时间线服务 Web 应用程序的主机名.</p>
<p>yarn.timeline-service.http-authentication.simple.anonymous.allowed<br>TRUE<br>指示在使用&quot;简单&quot;身份验证时时间线服务器是否允许匿名请求.</p>
<p>yarn.timeline-service.http-authentication.type<br>simple<br>定义用于时间线服务器 HTTP 端点的身份验证.支持的值是:simple |kerberos |#AUTHENTICATION_HANDLER_CLASSNAME#</p>
<p>yarn.timeline-service.keytab<br>/etc/krb5.keytab<br>时间线服务器的 Kerberos 密钥表.</p>
<p><font color="#dd0000">yarn.timeline-service.leveldb-timeline-store.path</font><br><code>$&#123;hadoop.tmp.dir&#125;</code>/yarn/timeline<br>leveldb 时间线存储的存储文件名.</p>
<p>yarn.timeline-service.leveldb-timeline-store.read-cache-size<br>104857600<br>leveldb 时间线存储的未压缩块的读取缓存大小(以字节为单位).</p>
<p>yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size<br>10000<br>leveldb 时间线存储的最近读取实体开始时间的缓存大小,以实体数表示.</p>
<p>yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size<br>10000<br>leveldb 时间线存储的最近写入实体开始时间的缓存大小,以实体数量表示.</p>
<p>yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms<br>300000<br>在 leveldb 时间线存储的删除周期之间等待的时间长度(以毫秒为单位).</p>
<p>yarn.timeline-service.principal<br>未配置<br>时间线服务器的 Kerberos 主体.</p>
<p>yarn.timeline-service.store-class<br>org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore<br>时间线存储的存储类名称.</p>
<p>yarn.timeline-service.ttl-enable<br>TRUE<br>启用时间线存储数据的年龄.</p>
<p><font color="#dd0000">yarn.timeline-service.ttl-ms</font><br>604800000<br>时间线存储数据的生存时间(以毫秒为单位).</p>
<p><font color="#dd0000">yarn.timeline-service.webapp.address</font><br>${yarn.timeline-service.hostname}:8188<br>时间线服务 Web 应用程序的 http 地址.</p>
<p><font color="#dd0000">yarn.timeline-service.webapp.https.address</font><br>${yarn.timeline-service.hostname}:8190<br>时间线服务 Web 应用程序的 https 地址.</p>
<p>yarn.web-proxy.address<br>未配置<br>Web 代理的地址为 HOST:PORT,如果未给出,则代理将作为 RM 的一部分运行</p>
<p>yarn.web-proxy.keytab<br>未配置<br>WebAppProxy 的 Keytab(如果代理未作为 RM 的一部分运行).</p>
<p>yarn.web-proxy.principal<br>未配置<br>代理的 kerberos 主体(如果代理未作为 RM 的一部分运行).</p>
<h2 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h2><p>map.sort.class<br>org.apache.hadoop.util.QuickSort<br>排序键的默认排序类.</p>
<!-- more -->

<p>mapred.child.env<br>未配置<br>用户为任务进程添加了环境变量.示例:<br>1)A=foo 这会将环境变量 A 设置为 foo.<br>2)B=$B:c 这是在 Unix 上继承 nodemanager 的 B 环境变量.<br>3)B=%B%;c 这是在 Windows 上继承 nodemanager 的 B 环境变量.</p>
<p><font color="#dd0000">mapred.child.java.opts</font><br>-Xmx200m<br>Java 选择任务进程.以下符号(如果存在)将被插入:@taskid@ 被当前 TaskID 替换.任何其他出现的&quot;@&quot;都将保持不变.例如,要启用详细 gc 日志记录到以 /tmp 中的 taskid 命名的文件并将堆最大值设置为千兆字节,请传递以下&quot;值&quot;:-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid @.gc 使用 -Djava.library.path 可能会导致程序在使用 hadoop 本机库时不再运行.应该使用 mapreduce.map.env 和 mapreduce.reduce.env 配置设置将这些值设置为 map/reduce JVM env 中 LD_LIBRARY_PATH 的一部分.</p>
<p>mapreduce.admin.user.env<br>未配置<br>专家:map 和 reduce 任务流程的附加执行环境条目.这不是附加属性.如果您希望 map 和 reduce 任务能够访问本机库(压缩等),则必须保留原始值.当此值为空时,设置执行环境的命令将取决于操作系统:对于 linux,使用 LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native.对于 Windows,使用 PATH = <code>%PATH%;%HADOOP_COMMON_HOME%\\bin</code>.</p>
<p>mapreduce.am.max-attempts<br>2<br>应用程序尝试的最大次数.这是特定于应用程序的设置.它不应大于资源管理器设置的全局数.否则,它将被覆盖.默认数字设置为 2,以允许 AM 至少重试一次.</p>
<p>mapreduce.application.classpath<br>未配置<br>MR 应用程序的 CLASSPATH.以逗号分隔的 CLASSPATH 条目列表.如果设置了 mapreduce.application.framework,那么它必须为该归档指定适当的类路径,并且归档的名称必须存在于类路径中.如果 mapreduce.app-submission.cross-platform 为 false,将使用特定于平台的环境变量扩展语法来构造默认的 CLASSPATH 条目.对于 <code>Linux:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*/$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*.对于 Windows:%HADOOP_MAPRED_HOME%/share/hadoop/mapreduce/*/%HADOOP_MAPRED_HOME%/share/hadoop/mapreduce/lib/*</code>.如果 mapreduce.app-submission.cross-platform 为 true,则将使用 MR 应用程序的与平台无关的默认 CLASSPATH:/share/hadoop/mapreduce/<code>*</code>,</p>
<p>mapreduce.application.framework.path<br>未配置<br>MapReduce 框架存档的路径.如果设置,框架存档将与作业一起自动分发,并且此路径通常位于 HDFS 文件系统中的公共位置.与分布式缓存文件一样,这可以是带有片段的 URL,该片段指定用于存档名称的别名.例如,hdfs:/mapred/framework/hadoop-mapreduce-2.1.1.tar.gz#mrframework 会将本地化存档别名为&quot;mrframework&quot;.请注意,mapreduce.application.classpath 必须包含指定框架的适当类路径.存档的基本名称或存档的别名(如果使用别名)必须出现在指定的类路径中.</p>
<p>mapreduce.app-submission.cross-platform<br>FALSE<br>如果启用,用户可以跨平台提交应用程序,即将应用程序从 Windows 客户端提交到 Linux/Unix 服务器,反之亦然.</p>
<p>mapreduce.client.completion.pollinterval<br>5000<br>JobClient 轮询 JobTracker 以获取有关作业状态的更新的间隔(以毫秒为单位).您可能希望将其设置为较低的值,以使测试在单节点系统上运行得更快.在生产中调整此值可能会导致不需要的客户端-服务器流量.</p>
<p>mapreduce.client.output.filter<br>FAILED<br>用于控制发送到 JobClient 控制台的任务用户日志输出的过滤器.允许的选项是:NONE/KILLED/FAILED/SUCCEEDED 和 ALL.</p>
<p>mapreduce.client.progressmonitor.pollinterval<br>1000<br>JobClient 向控制台报告状态并检查作业完成的时间间隔(以毫秒为单位).您可能希望将其设置为较低的值,以使测试在单节点系统上运行得更快.在生产中调整此值可能会导致不需要的客户端-服务器流量.</p>
<p>mapreduce.client.submit.file.replication<br>10<br>提交的作业文件的复制级别.这应该在节点数的平方根附近.</p>
<p>mapreduce.cluster.acls.enabled<br>FALSE<br>指定是否应检查 ACL 以获取用户执行各种队列和作业级别操作的授权.默认情况下禁用 ACL.如果启用,当用户请求队列操作(例如将作业提交到队列并终止队列中的作业)和作业操作(例如查看作业详细信息)时,JobTracker 和 TaskTracker 会进行访问控制检查(请参阅 mapreduce.job.acl -view-job)或用于使用 Map/Reduce API/RPC 或通过控制台和 Web 用户界面修改作业(参见 mapreduce.job.acl-modify-job).为了启用这个标志(mapreduce.cluster.acls.enabled),这将在 JobTracker 节点和所有 TaskTracker 节点上的 mapred-site.xml 中设置为 true.</p>
<p>mapreduce.cluster.local.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/mapred/local<br>MapReduce 存储中间数据文件的本地目录.可能是不同设备上以逗号分隔的目录列表,以便分散磁盘 i/o.不存在的目录将被忽略.</p>
<p>mapreduce.cluster.temp.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/mapred/temp<br>临时文件的共享目录.</p>
<p><font color="#dd0000">mapreduce.framework.name</font><br>local<br>用于执行 MapReduce 作业的运行时框架.可以是本地/经典或纱线之一.</p>
<p>mapreduce.ifile.readahead<br>TRUE<br>用于启用/禁用 IFile 预读的配置键.</p>
<p>mapreduce.ifile.readahead.bytes<br>4194304<br>用于设置 IFile 预读长度(以字节为单位)的配置键.</p>
<p>mapreduce.input.fileinputformat.list-status.num-threads<br>1<br>用于列出和获取指定输入路径的块位置的线程数.注意:如果使用自定义的非线程安全路径过滤器,则不应使用多线程.</p>
<p>mapreduce.input.fileinputformat.split.minsize<br>0<br>映射输入应该被分成的最小大小的块.请注意,某些文件格式可能具有优先于此设置的最小拆分大小.</p>
<p>mapreduce.input.lineinputformat.linespermap<br>1<br>使用 NLineInputFormat 时,要包含在每个拆分中的输入数据的行数.</p>
<p>mapreduce.job.acl-modify-job<br>未配置<br>用于&quot;修改&quot;作业的作业特定访问控制列表.它仅在通过将配置属性 mapreduce.cluster.acls.enabled 设置为 true 在 Map/Reduce 中启用授权时使用.这指定了可以对作业进行修改操作的用户和/或组的列表.要指定用户和组的列表,使用的格式是&quot;user1,user2 group1,group&quot;.如果设置为&quot;<code>*</code>&quot;,则允许所有用户/组修改此作业.如果设置为&#39; &#39;(即空格),则不允许.此配置用于保护与此作业有关的所有修改并处理以下所有操作: o 终止此作业 o 终止此作业的任务,此作业的任务失败 o 设置此作业的优先级 这些操作中的每一个也受通过 mapred-queues.xml 配置的每个队列级别 ACL&quot;acl-administer-jobs&quot;的保护.因此,调用者应该有权满足队列级 ACL 或作业级 ACL.无论此 ACL 配置如何,(a) 作业所有者,(b) 启动集群的用户,(c) 通过 mapreduce.cluster.permissions.supergroup 配置的管理员配置的超级组的成员和 (d) 队列的队列管理员通过 acl-administer-jobs 为 mapred-queues.xml 中的特定队列配置的此作业可以对作业执行所有修改操作.默认情况下,除了启动集群的用户 job-owner 之外,没有其他人,</p>
<p>mapreduce.job.acl-view-job<br>未配置<br>用于&quot;查看&quot;作业的作业特定访问控制列表.它仅在通过将配置属性 mapreduce.cluster.acls.enabled 设置为 true 在 Map/Reduce 中启用授权时使用.这指定了可以查看有关作业的私人详细信息的用户和/或组的列表.要指定用户和组的列表,使用的格式是&quot;user1,user2 group1,group&quot;.如果设置为&quot;<code>*</code>&quot;,则允许所有用户/组修改此作业.如果设置为&#39; &#39;(即空格),则不允许.此配置用于保护一些作业视图,目前仅保护可能返回作业所有者的敏感信息的 API,例如 o 作业级计数器 o 任务级计数器 o 任务&#39;诊断信息 o Task-logs 显示在 TaskTracker web-UI 和 o JobTracker 的 web-UI 显示的 job.xml 任何其他用户仍然可以访问其他作业信息,例如 JobStatus/JobProfile/作业列表在队列中等.无论此 ACL 配置如何,(a) 作业所有者,(b) 启动集群的用户,(c) 通过 mapreduce.cluster.permissions.supergroup 配置的管理员配置的超级组的成员和 (d ) 提交此作业的队列的队列管理员通过 acl-administer-jobs 为 mapred-queues.xml 中的特定队列配置,可以对作业执行所有查看操作.默认情况下,除了启动集群的用户 job-owner 之外,没有其他人,</p>
<p>mapreduce.job.classloader<br>FALSE<br>是否为任务 JVM 中的用户类使用单独的(隔离的)类加载器.</p>
<p>mapreduce.job.classloader.system.classes<br>未配置<br>用于覆盖作业类加载器的系统类的默认定义.当启用 mapreduce.job.classloader 时,系统类是应从系统类路径加载的类的逗号分隔列表,而不是用户提供的 JAR.以&quot;.&quot;结尾的名字(句点)被视为包名称,以&quot;-&quot;开头的名称被视为否定匹配.</p>
<p>mapreduce.job.committer.setup.cleanup.needed<br>TRUE<br>如果作业需要作业设置和作业清理,则为 true.假的,否则</p>
<p>mapreduce.job.complete.cancel.delegation.tokens<br>TRUE<br>如果为 false - 不要从续订中取消注册/取消委托令牌,因为生成的作业可能会使用相同的令牌</p>
<p>mapreduce.job.counters.limit<br>120<br>限制每个作业允许的用户计数器数量.</p>
<p>mapreduce.job.emit-timeline-data<br>FALSE<br>指定 Application Master 是否应将时间线数据发送到时间线服务器.单个作业可以覆盖此值.</p>
<p>mapreduce.job.end-notification.max.attempts<br>5<br>为提供作业结束通知而读取 URL 的最大次数.集群管理员可以设置它来限制作业结束后的多长时间,Application Master 在退出之前等待.必须标记为 final 以防止用户覆盖它.</p>
<p>mapreduce.job.end-notification.max.retry.interval<br>5000<br>在重试作业结束通知之前等待的最长时间(以毫秒为单位).集群管理员可以设置它来限制 Application Master 在退出之前等待的时间.必须标记为 final 以防止用户覆盖它.</p>
<p>mapreduce.job.end-notification.retry.attempts<br>0<br>如果作业失败,作业的提交者想要重试作业结束通知的次数.这由 mapreduce.job.end-notification.max.attempts 限制</p>
<p>mapreduce.job.end-notification.retry.interval<br>1000<br>如果作业结束通知失败,作业提交者希望在重试作业结束通知之前等待的毫秒数.这由 mapreduce.job.end-notification.max.retry.interval 限制</p>
<p>mapreduce.job.end-notification.url<br>未配置<br>指示将在作业完成时调用以通知作业结束状态的 url.用户最多可以使用 URI 提供 2 个变量:$jobId 和 $jobStatus.如果它们存在于 URI 中,那么它们将被它们各自的值替换.</p>
<p>mapreduce.job.jvm.numtasks<br>1<br>每个 jvm 运行多少个任务.如果设置为 -1,则没有限制.</p>
<p>mapreduce.job.map.output.collector.class<br>org.apache.hadoop.mapred.MapTask$MapOutputBuffer<br>要使用的 MapOutputCollector 实现.这可能是一个以逗号分隔的类名列表,在这种情况下,map 任务将尝试依次初始化每个收集器.将使用第一个成功初始化的.</p>
<p>mapreduce.job.maps<br>2<br>每个作业的默认地图任务数.当 mapreduce.jobtracker.address 为&quot;本地&quot;时忽略.</p>
<p>mapreduce.job.max.split.locations<br>10<br>用于位置计算的每个分割存储的最大块位置数.</p>
<p>mapreduce.job.maxtaskfailures.per.tracker<br>3<br>给定作业的 tasktracker 上的任务失败次数,之后该作业的新任务未分配给它.它必须小于 mapreduce.map.maxattempts 和 mapreduce.reduce.maxattempts 否则失败的任务将永远不会在不同的节点上尝试.</p>
<p>mapreduce.job.queuename<br>default<br>作业提交到的队列.这必须与系统的 mapred-queues.xml 中定义的队列之一匹配.此外,队列的 ACL 设置必须允许当前用户向队列提交作业.在指定队列之前,请确保系统已配置队列,并且允许访问以将作业提交到队列.</p>
<p>mapreduce.job.reduce.shuffle.consumer.plugin.class<br>org.apache.hadoop.mapreduce.task.reduce.Shuffle<br>该作业的reducetasks将使用其实例发送shuffle请求的类的名称.该类必须是 org.apache.hadoop.mapred.ShuffleConsumerPlugin 的实例.</p>
<p>mapreduce.job.reduce.slowstart.completedmaps<br>0.05<br>在为作业安排 reduce 之前,作业中应完成的地图数量的一部分.</p>
<p>mapreduce.job.reducer.preempt.delay.sec<br>0<br>当没有预期的净空时,未满足的映射器请求触发reducer抢占的阈值(以秒为单位).如果设置为 0 或负值,则一旦检测到余量不足,reducer 就会被抢占.默认值为 0.</p>
<p>mapreduce.job.reducer.unconditional-preempt.delay.sec<br>300<br>不满足的映射器请求触发强制减速器抢占的阈值(以秒为单位),而与预期的净空无关.默认情况下,它设置为 5 分钟.将其设置为 0 会导致 reducer 立即抢占.设置为 -1 将完全禁用此抢占.</p>
<p>mapreduce.job.reduces<br>1<br>每个作业的默认减少任务数.通常设置为集群的 reduce 容量的 99%,这样如果一个节点发生故障,reduce 仍然可以在单个 wave 中执行.当 mapreduce.jobtracker.address 为&quot;本地&quot;时忽略.</p>
<p>mapreduce.job.skip.outdir<br>未配置<br>如果此处未指定任何值,则跳过的记录将写入位于<code> _logs</code>/skip 的输出目录.用户可以通过给出值&quot;none&quot;来停止写入跳过的记录.</p>
<p>mapreduce.job.speculative.slownodethreshold<br>1<br>Task Tracker 的 ave map 和 reduce 进度率 (finishTime-dispatchTime) 的标准偏差数必须低于所有成功的 map/reduce 任务的平均值,因为 TT 被认为太慢而无法提供推测性任务.</p>
<p>mapreduce.job.speculative.slowtaskthreshold<br>1<br>一个任务的平均进度率必须低于所有正在运行的任务的平均值的标准偏差数,该任务被认为太慢.</p>
<p>mapreduce.job.speculative.speculativecap<br>0.1<br>可以在任何时候以推测方式重新执行的正在运行任务的最大百分比 (0-1).</p>
<p>mapreduce.job.split.metainfo.maxsize<br>10000000<br>拆分元信息文件的最大允许大小.JobTracker 不会尝试读取大于配置值的拆分元信息文件.如果设置为 -1,则没有限制.</p>
<p>mapreduce.job.tags<br>未配置<br>在提交时将传递给 YARN 的作业标签.对应用程序的 YARN 查询可以过滤这些标签.</p>
<p>mapreduce.job.token.tracking.ids<br>未配置<br>当 mapreduce.job.token.tracking.ids.enabled 设置为 true 时,框架将其设置为作业使用的 token-tracking-ids.</p>
<p>mapreduce.job.token.tracking.ids.enabled<br>FALSE<br>是否将令牌的跟踪 ID 写入作业配置.当为 true 时,配置属性&quot;mapreduce.job.token.tracking.ids&quot;设置为作业的 token-tracking-ids</p>
<p>mapreduce.job.ubertask.enable<br>FALSE<br>是否启用小型作业&quot;ubertask&quot;优化,它在单个 JVM 中按顺序运行&quot;足够小的&quot;作业.&quot;Small&quot;由以下 maxmaps/maxreduces 和 maxbytes 设置定义.请注意,应用程序主控的配置也会影响&quot;小&quot;定义 - yarn.app.mapreduce.am.resource.mb 必须大于 mapreduce.map.memory.mb 和 mapreduce.reduce.memory.mb,以及 yarn.app .mapreduce.am.resource.cpu-vcores 必须大于 mapreduce.map.cpu.vcores 和 mapreduce.reduce.cpu.vcores 才能启用 ubertask.用户可以覆盖此值.</p>
<p>mapreduce.job.ubertask.maxbytes<br>未配置<br>输入字节数的阈值,超过该阈值的作业被认为对于 ubertasking 优化来说太大了.如果未指定任何值,则使用 dfs.block.size 作为默认值.如果底层文件系统不是 HDFS,请务必在 mapred-site.xml 中指定默认值.用户可以覆盖这个值,但只能向下.</p>
<p>mapreduce.job.ubertask.maxmaps<br>9<br>地图数量的阈值,超过该阈值的作业被认为对于 ubertasking 优化来说太大了.用户可以覆盖这个值,但只能向下.</p>
<p>mapreduce.job.ubertask.maxreduces<br>1<br>减少数量的阈值,超过该阈值的作业被认为对于 ubertasking 优化来说太大了.目前该代码不能支持多个 REDUCE 并将忽略更大的值.(然而,零是一个有效的最大值.)用户可以覆盖这个值,但只能向下.</p>
<p>mapreduce.job.userhistorylocation<br>未配置<br>用户可以指定一个位置来存储特定作业的历史文件.如果未指定任何内容,则日志存储在输出目录中.这些文件存储在目录中的&quot;<code>_logs</code>/history/&quot;中.用户可以通过提供值&quot;none&quot;来停止记录.</p>
<p>mapreduce.job.userlog.retain.hours<br>24<br>作业完成后保留用户日志的最长时间(以小时为单位).</p>
<p><font color="#dd0000">mapreduce.jobhistory.address</font><br>0.0.0.0:10020<br>MapReduce JobHistory Server IPC 主机:端口</p>
<p>mapreduce.jobhistory.admin.acl<br>*<br>可以成为历史服务器管理员的 ACL.</p>
<p>mapreduce.jobhistory.admin.address<br>0.0.0.0:10033<br>历史服务器管理界面的地址.</p>
<p>mapreduce.jobhistory.cleaner.enable<br>TRUE</p>
<p>mapreduce.jobhistory.cleaner.interval-ms<br>86400000<br>作业历史记录清理器检查要删除的文件的频率(以毫秒为单位).默认为 86400000(一天).仅当文件早于 mapreduce.jobhistory.max-age-ms 时才会删除文件.</p>
<p>mapreduce.jobhistory.client.thread-count<br>10<br>处理客户端 API 请求的线程数</p>
<p>mapreduce.jobhistory.datestring.cache.size<br>200000<br>日期字符串缓存的大小.影响将被扫描以查找作业的目录数量.</p>
<p>mapreduce.jobhistory.done-dir<br>${yarn.app.mapreduce.am.staging-dir}/history/done</p>
<p>mapreduce.jobhistory.http.policy<br>HTTP_ONLY<br>这将为 JobHistoryServer Web UI 配置 HTTP 端点.支持以下值: - HTTP_ONLY :仅在 http 上提供服务 - HTTPS_ONLY :仅在 https 上提供服务</p>
<p>mapreduce.jobhistory.intermediate-done-dir<br>${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate</p>
<p>mapreduce.jobhistory.joblist.cache.size<br>20000<br>作业列表缓存的大小</p>
<p>mapreduce.jobhistory.keytab<br>/etc/security/keytab/jhs.service.keytab<br>MapReduce JobHistory Server 的 kerberos 密钥表文件的位置.</p>
<p>mapreduce.jobhistory.loadedjobs.cache.size<br>5<br>加载的作业缓存的大小.如果属性 mapreduce.jobhistory.loadedtasks.cache.size 设置为正值,则忽略此属性.</p>
<p>mapreduce.jobhistory.loadedtasks.cache.size<br>未配置<br>更改要根据总任务计数设置的作业历史缓存限制.如果加载的任务总数超过此值,则作业缓存将缩小,直到低于此限制(缓存中至少 1 个作业).如果此值为空或非正数,则缓存将恢复为使用属性 mapreduce.jobhistory.loadedjobs.cache.size 作为作业缓存大小.对于 mapreduce.jobhistory.loadedtasks.cache.size 属性的两个建议: 1) 对于每 100k 的缓存大小,将 Job History Server 的堆大小设置为 1.2GB.例如,mapreduce.jobhistory.loadedtasks.cache.size=500000,堆大小=6GB.2) 确保缓存大小大于集群上运行的最大作业所需的任务数.将值设置得稍高可能是个好主意(例如,</p>
<p>mapreduce.jobhistory.max-age-ms<br>604800000<br>历史清理器运行时,将删除超过此毫秒数的作业历史文件.默认为 604800000(1 周).</p>
<p>mapreduce.jobhistory.minicluster.fixed.ports<br>FALSE<br>是否对 minicluster 使用固定端口</p>
<p>mapreduce.jobhistory.move.interval-ms<br>180000<br>以这个频率从中间完成目录扫描历史文件到完成目录.</p>
<p>mapreduce.jobhistory.move.thread-count<br>3<br>用于移动文件的线程数.</p>
<p>mapreduce.jobhistory.principal<br><code>jhs/_HOST@REALM.TLD</code><br>MapReduce JobHistory Server 的 Kerberos 主体名称.</p>
<p>mapreduce.jobhistory.recovery.enable<br>FALSE<br>启用历史服务器来存储服务器状态并在启动时恢复服务器状态.如果启用,则必须指定 mapreduce.jobhistory.recovery.store.class.</p>
<p>mapreduce.jobhistory.recovery.store.class<br>org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService<br>HistoryServerStateStoreService 类用于存储历史服务器状态以供恢复.</p>
<p>mapreduce.jobhistory.recovery.store.fs.uri<br><code>$&#123;hadoop.tmp.dir&#125;</code>/mapred/history/recoverystore<br>如果将 HistoryServerFileSystemStateStoreService 配置为恢复存储类,则将存储历史服务器状态的 URI.</p>
<p>mapreduce.jobhistory.store.class<br>未配置<br>用于缓存历史数据的 HistoryStorage 类.</p>
<p><font color="#dd0000">mapreduce.jobhistory.webapp.address</font><br>0.0.0.0:19888<br>MapReduce JobHistory Server Web UI 主机:端口</p>
<p>mapreduce.jobtracker.address<br>local<br>MapReduce 作业跟踪器运行的主机和端口.如果是&quot;本地&quot;,则作业将作为单个 map 和 reduce 任务在进程内运行.</p>
<p>mapreduce.jobtracker.expire.trackers.interval<br>600000<br>专家:时间间隔,以毫秒为单位,如果任务跟踪器不发送心跳,则在该时间间隔之后它被宣布为&quot;丢失&quot;.</p>
<p>mapreduce.jobtracker.handler.count<br>10<br>JobTracker 的服务器线程数.这应该是 tasktracker 节点数量的大约 4%.</p>
<p>mapreduce.jobtracker.heartbeats.in.second<br>100<br>专家:一秒钟内可以到达 JobTracker 的近似心跳数.假设每个 RPC 可以在 10 毫秒内处理,默认值是每秒 100 个 RPC.</p>
<p>mapreduce.jobtracker.hosts.exclude.filename<br>未配置<br>命名一个文件,其中包含应被作业跟踪器排除的主机列表.如果该值为空,则不排除任何主机.</p>
<p>mapreduce.jobtracker.hosts.filename<br>未配置<br>命名一个文件,该文件包含可能连接到 jobtracker 的节点列表.如果该值为空,则允许所有主机.</p>
<p>mapreduce.jobtracker.http.address<br>0.0.0.0:50030<br>作业跟踪器 http 服务器地址和服务器将侦听的端口.如果端口为 0,则服务器将在空闲端口上启动.</p>
<p>mapreduce.jobtracker.instrumentation<br>org.apache.hadoop.mapred.JobTrackerMetricsInst<br>专家:与每个 JobTracker 关联的检测类.</p>
<p>mapreduce.jobtracker.jobhistory.block.size<br>3145728<br>作业历史文件的块大小.由于作业恢复使用作业历史记录,因此尽快将作业历史记录转储到磁盘非常重要.请注意,这是专家级参数.默认值设置为 3 MB.</p>
<p>mapreduce.jobtracker.jobhistory.completed.location<br>未配置<br>完成的作业历史文件存储在这个众所周知的位置.如果未指定任何内容,则文件存储在 ${mapreduce.jobtracker.jobhistory.location}/done.</p>
<p>mapreduce.jobtracker.jobhistory.location<br>未配置<br>如果作业跟踪器是静态的,则历史文件存储在这个众所周知的地方.如果这里没有设置值,默认在本地文件系统${hadoop.log.dir}/history.</p>
<p>mapreduce.jobtracker.jobhistory.lru.cache.size<br>5<br>内存中加载的作业历史文件的数量.作业在首次访问时被加载.基于 LRU 清除缓存.</p>
<p>mapreduce.jobtracker.jobhistory.task.numberprogresssplits<br>12<br>每个任务尝试从 0.0 进展到 1.0 [除非它失败或被杀死].对于每次任务尝试,我们都会记录每十二分之一进度范围内的某些统计数据.您可以通过设置此属性来更改我们将整个进度范围划分为的间隔数.值越高,记录的数据就越精确,但在运行时会占用作业跟踪器中的更多内存.此属性中的每个增量每个正在运行的任务花费 16 个字节.</p>
<p>mapreduce.jobtracker.maxtasks.perjob<br>-1<br>单个作业的最大任务数.值 -1 表示没有最大值.</p>
<p>mapreduce.jobtracker.persist.jobstatus.active<br>TRUE<br>指示作业状态信息的持久性是否处于活动状态.</p>
<p>mapreduce.jobtracker.persist.jobstatus.dir<br>/jobtracker/jobsInfo<br>作业状态信息保存在文件系统中的目录,以便在它删除内存队列后以及在 jobtracker 重新启动之间可用.</p>
<p>mapreduce.jobtracker.persist.jobstatus.hours<br>1<br>工作状态信息在 DFS 中保留的小时数.作业状态信息将在它丢弃内存队列后以及在 jobtracker 重新启动之间可用.对于零值,作业状态信息根本不会保存在 DFS 中.</p>
<p>mapreduce.jobtracker.restart.recover<br>FALSE<br>&quot;true&quot; 重新启动时启用(作业)恢复,&quot;false&quot; 重新开始</p>
<p>mapreduce.jobtracker.retiredjobs.cache.size<br>1000<br>要保留在缓存中的退休作业状态的数量.</p>
<p>mapreduce.jobtracker.staging.root.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/mapred/staging<br>用户作业文件暂存区的根目录 实际上,这应该是用户主目录所在的目录(通常是 /user)</p>
<p>mapreduce.jobtracker.system.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/mapred/system<br>MapReduce 存储控制文件的目录.</p>
<p>mapreduce.jobtracker.taskcache.levels<br>2<br>这是任务缓存的最高级别.例如,如果级别为 2,则缓存的任务在主机级别和机架级别.</p>
<p>mapreduce.jobtracker.taskscheduler<br>org.apache.hadoop.mapred.JobQueueTaskScheduler<br>负责调度任务的类.</p>
<p>mapreduce.jobtracker.taskscheduler.maxrunningtasks.perjob<br>未配置<br>作业被抢占之前的最大运行任务数.如果未定义,则没有限制.</p>
<p>mapreduce.jobtracker.tasktracker.maxblacklists<br>4<br>任务跟踪器按各种作业列入黑名单的数量,之后任务跟踪器可以在所有作业中列入黑名单.跟踪器将在稍后(一天后)获得任务.重新启动后,跟踪器将成为健康的跟踪器.</p>
<p>mapreduce.local.clientfactory.class.name<br>org.apache.hadoop.mapred.LocalClientFactory<br>这是负责创建本地作业运行器客户端的客户端工厂</p>
<p>mapreduce.map.cpu.vcores<br>1<br>为每个映射任务从调度程序请求的虚拟核心数.</p>
<p>mapreduce.map.cpu.vcores<br>1<br>每个映射任务所需的虚拟核心数.</p>
<p>mapreduce.map.log.level<br>INFO<br>地图任务的日志记录级别.允许的级别为:OFF/FATAL/ERROR/WARN/INFO/DEBUG/TRACE 和 ALL.</p>
<p>mapreduce.map.maxattempts<br>4<br>专家:每个地图任务的最大尝试次数.换句话说,框架会在放弃之前尝试多次执行地图任务.</p>
<p>mapreduce.map.memory.mb<br>1024<br>为每个映射任务从调度程序请求的内存量.</p>
<p>mapreduce.map.output.compress<br>FALSE<br>映射的输出是否应该在通过网络发送之前进行压缩.使用 SequenceFile 压缩.</p>
<p>mapreduce.map.output.compress.codec<br>org.apache.hadoop.io.compress.DefaultCodec<br>如果地图输出被压缩,它们应该如何压缩?</p>
<p>mapreduce.map.skip.maxrecords<br>0<br>mapper 中每个坏记录周围的可接受跳过记录的数量.该数字还包括不良记录.要关闭检测/跳过不良记录的功能,请将值设置为 0.框架尝试通过重试来缩小跳过的范围,直到达到此阈值或所有尝试都用尽此任务.将值设置为 Long.MAX_VALUE 以指示框架不需要尝试缩小范围.跳过任何记录(取决于应用程序)都是可以接受的.</p>
<p>mapreduce.map.skip.proc.count.autoincr<br>TRUE<br>如果设置为 true,则 SkipBadRecords.COUNTER_MAP_PROCESSED_RECORDS 的标志在调用 map 函数后由 MapRunner 递增.对于异步处理记录或缓冲输入记录的应用程序,此值必须设置为 false.例如流媒体.在这种情况下,应用程序应自行增加此计数器.</p>
<p>mapreduce.map.sort.spill.percent<br>0.8<br>序列化缓冲区中的软限制.一旦达到,一个线程将开始在后台将内容溢出到磁盘.请注意,如果在溢出过程中超过此阈值,则收集不会阻塞,因此当设置为小于 0.5 时,溢出可能大于此阈值</p>
<p>mapreduce.map.speculative<br>TRUE<br>如果为真,则某些地图任务的多个实例可能会并行执行.</p>
<p>mapreduce.output.fileoutputformat.compress<br>FALSE<br>是否应该压缩作业输出?</p>
<p>mapreduce.output.fileoutputformat.compress.codec<br>org.apache.hadoop.io.compress.DefaultCodec<br>如果作业输出被压缩,它们应该如何被压缩?</p>
<p>mapreduce.output.fileoutputformat.compress.type<br>RECORD<br>如果将作业输出压缩为 SequenceFiles,应该如何压缩它们?应该是 NONE/RECORD 或 BLOCK 之一.</p>
<p>mapreduce.reduce.cpu.vcores<br>1<br>每个reduce任务从调度器请求的虚拟核心数.</p>
<p>mapreduce.reduce.cpu.vcores<br>1<br>每个reduce任务所需的虚拟核心数.</p>
<p>mapreduce.reduce.input.buffer.percent<br>0<br>在减少期间保留映射输出的内存百分比(相对于最大堆大小).当 shuffle 结束时,内存中任何剩余的 map 输出必须消耗少于这个阈值,然后才能开始 reduce.</p>
<p>mapreduce.reduce.log.level<br>INFO<br>reduce 任务的日志记录级别.允许的级别为:OFF/FATAL/ERROR/WARN/INFO/DEBUG/TRACE 和 ALL.</p>
<p>mapreduce.reduce.markreset.buffer.percent<br>0<br>使用标记重置功能时用于缓存值的内存百分比(相对于最大堆大小).</p>
<p>mapreduce.reduce.maxattempts<br>4<br>Expert:每个reduce任务的最大尝试次数.换句话说,框架会在放弃之前尝试多次执行reduce任务.</p>
<p>mapreduce.reduce.memory.mb<br>1024<br>每个reduce任务从调度器请求的内存量.</p>
<p>mapreduce.reduce.merge.inmem.threshold<br>1000<br>阈值,以内存中合并过程的文件数表示.当我们累积阈值文件数时,我们会启动内存合并并溢出到磁盘.值 0 或小于 0 表示我们不希望有任何阈值,而是仅依赖 ramfs 的内存消耗来触发合并.</p>
<p>mapreduce.reduce.shuffle.connect.timeout<br>180000<br>专家:reduce 任务尝试连接到 tasktracker 以获取地图输出所花费的最大时间量(以毫秒为单位).</p>
<p>mapreduce.reduce.shuffle.fetch.retry.enabled<br>${yarn.nodemanager.recovery.enabled}<br>设置为在主机重新启动期间启用提取重试.</p>
<p>mapreduce.reduce.shuffle.fetch.retry.interval-ms<br>1000<br>由于某些事件(例如 NM 重启)而发生某些非致命故障时,fetcher 重试再次获取的间隔时间.</p>
<p>mapreduce.reduce.shuffle.fetch.retry.timeout-ms<br>30000<br>由于某些事件(例如 NM 重启)而发生某些非致命故障时,fetcher 重试再次获取的超时值.</p>
<p>mapreduce.reduce.shuffle.input.buffer.percent<br>0.7<br>在 shuffle 期间从最大堆大小分配到存储映射输出的内存百分比.</p>
<p><font color="#dd0000">mapreduce.reduce.shuffle.memory.limit.percent</font><br>0.25<br>专家:单个 shuffle 可以消耗的内存限制的最大百分比</p>
<p>mapreduce.reduce.shuffle.merge.percent<br>0.66<br>将启动内存合并的使用阈值,表示为分配给存储内存映射输出的总内存的百分比,由 mapreduce.reduce.shuffle.input.buffer.percent 定义.</p>
<p>mapreduce.reduce.shuffle.parallelcopies<br>5<br>在复制(洗牌)阶段,reduce 运行的默认并行传输数.</p>
<p>mapreduce.reduce.shuffle.read.timeout<br>180000<br>专家:reduce 任务在获得连接后等待 map 输出数据可供读取的最长时间(以毫秒为单位).</p>
<p>mapreduce.reduce.shuffle.retry-delay.max.ms<br>60000<br>在重试下载地图数据之前,reducer 将延迟的最大毫秒数.</p>
<p>mapreduce.reduce.skip.maxgroups<br>0<br>reducer 中每个坏组周围的可接受跳过组的数量.该数字也包括不良组.要关闭检测/跳过坏组的功能,请将值设置为 0.框架尝试通过重试来缩小跳过的范围,直到达到此阈值或所有尝试都用尽此任务.将值设置为 Long.MAX_VALUE 以指示框架不需要尝试缩小范围.跳过任何组(取决于应用程序)都是可以接受的.</p>
<p>mapreduce.reduce.skip.proc.count.autoincr<br>TRUE<br>如果设置为 true,则 SkipBadRecords.COUNTER_REDUCE_PROCESSED_GROUPS 的标志在调用 reduce 函数后由框架递增.对于异步处理记录或缓冲输入记录的应用程序,此值必须设置为 false.例如流媒体.在这种情况下,应用程序应自行增加此计数器.</p>
<p>mapreduce.reduce.speculative<br>TRUE<br>如果为 true,则某些 reduce 任务的多个实例可能会并行执行.</p>
<p>mapreduce.shuffle.connection-keep-alive.enable<br>FALSE<br>设置为 true 以支持保持连接.</p>
<p>mapreduce.shuffle.connection-keep-alive.timeout<br>5<br>shuffle 客户端尝试保留 http 连接的秒数.请参阅 Http 规范中的&quot;Keep-Alive: timeout=&quot;标头</p>
<p>mapreduce.shuffle.max.connections<br>0<br>洗牌的最大允许连接数.设置为 0(零)表示对连接数没有限制.</p>
<p>mapreduce.shuffle.max.threads<br>0<br>用于服务随机连接的最大允许线程数.设置为零表示默认为可用处理器数量的 2 倍(由 Runtime.availableProcessors() 报告).Netty 用于服务请求,因此每个连接都不需要一个线程.</p>
<p><font color="#dd0000">mapreduce.shuffle.port</font><br>13562<br>ShuffleHandler 将在其上运行的默认端口.ShuffleHandler 是在 NodeManager 上运行的服务,用于促进将中间 Map 输出传输到请求的 Reducer.</p>
<p>mapreduce.shuffle.ssl.enabled<br>FALSE<br>是否对 Shuffle HTTP 端点使用 SSL.</p>
<p>mapreduce.shuffle.ssl.file.buffer.size<br>65536<br>使用 SSL 时从文件中读取溢出的缓冲区大小.</p>
<p>mapreduce.shuffle.transfer.buffer.size<br>131072<br>仅当 mapreduce.shuffle.transferTo.allowed 设置为 false 时才使用此属性.在这种情况下,此属性定义了在 shuffle 阶段的缓冲区复制代码中使用的缓冲区大小.这个缓冲区的大小决定了 IO 请求的大小.</p>
<p>mapreduce.shuffle.transferTo.allowed<br>未配置<br>此选项可以在 shuffle 阶段使用 nio transferTo 方法启用/禁用.NIO transferTo 在 shuffle 阶段的 windows 上表现不佳.因此,使用此配置属性可以禁用它,在这种情况下将使用自定义传输方法.在 Windows 上运行 Hadoop 时,推荐值为 false.对于 Linux,建议将其设置为 true.如果未设置任何内容,则 Windows 的默认值为 false,Linux 的默认值为 true.</p>
<p>mapreduce.task.combine.progress.records<br>10000<br>在发送进度通知之前在组合输出收集期间要处理的记录数.</p>
<p>mapreduce.task.files.preserve.failedtasks<br>FALSE<br>是否应保留失败任务的文件.这应该只用于失败的作业,因为存储永远不会被回收.它还可以防止 map 输出在使用时从 reduce 目录中删除.</p>
<p>mapreduce.task.io.sort.factor<br>10<br>排序文件时一次合并的流数.这决定了打开文件句柄的数量.</p>
<p><font color="#dd0000">mapreduce.task.io.sort.mb</font><br>100<br>排序文件时使用的缓冲内存总量,以兆字节为单位.默认情况下,给每个合并流 1MB,这应该最大限度地减少搜索.</p>
<p>mapreduce.task.merge.progress.records<br>10000<br>在向 TaskTracker 发送进度通知之前要在合并期间处理的记录数.</p>
<p>mapreduce.task.profile<br>FALSE<br>设置系统是否应该为该作业中的某些任务收集探查器信息?信息存储在用户日志目录中.如果启用了任务分析,则值为&quot;true&quot;.</p>
<p>mapreduce.task.profile.map.params<br>${mapreduce.task.profile.params}<br>映射任务特定的 JVM 分析器参数.见 mapreduce.task.profile.params</p>
<p>mapreduce.task.profile.maps<br>0-2<br>将地图任务的范围设置为配置文件.mapreduce.task.profile 必须设置为 true 才能计算该值.</p>
<p>mapreduce.task.profile.params<br>-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s<br>用于分析映射和减少任务尝试的 JVM 分析器参数.此字符串可能包含单个格式说明符 %s,它将被任务尝试日志目录中 profile.out 的路径替换.要为 map 任务和 reduce 任务指定不同的分析选项,应该使用更具体的参数 mapreduce.task.profile.map.params 和 mapreduce.task.profile.reduce.params.</p>
<p>mapreduce.task.profile.reduce.params<br>${mapreduce.task.profile.params}<br>减少任务特定的 JVM 分析器参数.见 mapreduce.task.profile.params</p>
<p>mapreduce.task.profile.reduces<br>0-2<br>将reduce任务的范围设置为profile.mapreduce.task.profile 必须设置为 true 才能计算该值.</p>
<p>mapreduce.task.skip.start.attempts<br>2<br>将启动哪个跳过模式后的任务尝试次数.当跳过模式启动时,任务将接下来将处理的记录范围报告给 TaskTracker.因此,在失败时,TT 知道哪些可能是不良记录.在进一步的执行中,这些被跳过.</p>
<p>mapreduce.task.timeout<br>600000<br>如果任务既不读取输入,也不写入输出,也不更新其状态字符串,则任务终止前的毫秒数.值 0 禁用超时.</p>
<p>mapreduce.task.tmp.dir<br>./tmp<br>为 map 和 reduce 任务设置 tmp 目录的值.如果值为绝对路径,则直接赋值.否则,它会附加任务的工作目录.使用选项 -Djava.io.tmpdir=&#39;tmp dir 的绝对路径&#39;执行 java 任务.使用环境变量设置管道和流式传输,TMPDIR=&#39;tmp dir 的绝对路径&#39;</p>
<p>mapreduce.task.userlog.limit.kb<br>0<br>每个任务的用户日志的最大大小,以 KB 为单位.0 禁用上限.</p>
<p>mapreduce.tasktracker.dns.interface<br>default<br>任务跟踪器应报告其 IP 地址的网络接口的名称.</p>
<p>mapreduce.tasktracker.dns.nameserver<br>default<br>TaskTracker 应使用名称服务器 (DNS) 的主机名或 IP 地址来确定 JobTracker 用于通信和显示目的的主机名.</p>
<p>mapreduce.tasktracker.group<br>未配置<br>专家:TaskTracker 所属的组.如果 LinuxTaskController 是通过 mapreduce.tasktracker.taskcontroller 配置的,则任务控制器二进制文件的组所有者应该与该组相同.</p>
<p>mapreduce.tasktracker.healthchecker.interval<br>60000<br>要运行的节点健康脚本的频率,以毫秒为单位</p>
<p>mapreduce.tasktracker.healthchecker.script.args<br>未配置<br>启动时要传递给节点健康脚本的参数列表,以逗号分隔.</p>
<p>mapreduce.tasktracker.healthchecker.script.path<br>未配置<br>脚本的绝对路径,由节点健康监控服务定期运行以确定节点是否健康.如果该key的值为空或者此处配置的位置不存在该文件,则不启动节点健康监控服务.</p>
<p>mapreduce.tasktracker.healthchecker.script.timeout<br>600000<br>如果无响应并认为脚本失败,则应终止节点运行状况脚本之后的时间.</p>
<p>mapreduce.tasktracker.http.address<br>0.0.0.0:50060<br>任务跟踪器 http 服务器地址和端口.如果端口为 0,则服务器将在空闲端口上启动.</p>
<p>mapreduce.tasktracker.http.threads<br>40<br>http 服务器的工作线程数.这用于地图输出获取</p>
<p>mapreduce.tasktracker.indexcache.mb<br>10<br>任务跟踪器允许的最大内存,用于将映射输出提供给减速器时使用的索引缓存.</p>
<p>mapreduce.tasktracker.instrumentation<br>org.apache.hadoop.mapred.TaskTrackerMetricsInst<br>Expert:与每个 TaskTracker 关联的检测类.</p>
<p>mapreduce.tasktracker.local.dir.minspacekill<br>0<br>如果 mapreduce.cluster.local.dir 中的空间低于此值,则在所有当前任务完成并清理之前不要询问更多任务.另外,为了保存我们正在运行的其余任务,杀死其中一个,清理一些空间.从 reduce 任务开始,然后继续完成最少的任务.以字节为单位的值.</p>
<p>mapreduce.tasktracker.local.dir.minspacestart<br>0<br>如果 mapreduce.cluster.local.dir 中的空间低于此值,请不要要求更多任务.以字节为单位的值.</p>
<p>mapreduce.tasktracker.map.tasks.maximum<br>2<br>任务跟踪器将同时运行的最大地图任务数.</p>
<p>mapreduce.tasktracker.outofband.heartbeat<br>FALSE<br>专家:将此设置为 true 以让 tasktracker 在任务完成时发送带外心跳以获得更好的延迟.</p>
<p>mapreduce.tasktracker.reduce.tasks.maximum<br>2<br>任务跟踪器将同时运行的最大减少任务数.</p>
<p>mapreduce.tasktracker.report.address<br>127.0.0.1:0<br>任务跟踪服务器侦听的接口和端口.由于它仅由任务连接,因此它使用本地接口.仅限专家.仅当您的主机没有环回接口时才应更改.</p>
<p>mapreduce.tasktracker.resourcecalculatorplugin<br>未配置<br>类的名称,其实例将用于查询 tasktracker 上的资源信息.该类必须是 org.apache.hadoop.util.ResourceCalculatorPlugin 的实例.如果值为 null,则 tasktracker 会尝试使用适合平台的类.目前,唯一支持的平台是 Linux.</p>
<p>mapreduce.tasktracker.taskcontroller<br>org.apache.hadoop.mapred.DefaultTaskController<br>TaskController 用于启动和管理任务执行</p>
<p>mapreduce.tasktracker.taskmemorymanager.monitoringinterval<br>5000<br>tasktracker 在监视其任务的内存使用的两个周期之间等待的时间间隔,以毫秒为单位.仅在通过 mapred.tasktracker.tasks.maxmemory 启用任务的内存管理时使用.</p>
<p>mapreduce.tasktracker.tasks.sleeptimebeforesigkill<br>5000<br>在发送 SIGTERM 后,tasktracker 等待向任务发送 SIGKILL 的时间(以毫秒为单位).这目前不用于仅向任务发送 SIGTERM 的 WINDOWS.</p>
<p>yarn.app.mapreduce.am.admin.user.env<br>未配置<br>用于管理目的的 MR App Master 进程的环境变量.这些值首先设置并且可以被用户 env (yarn.app.mapreduce.am.env) 覆盖 示例:1) A=foo 这会将 env 变量 A 设置为 foo 2) B=$B:c 这是继承 app master 的 B 环境变量.</p>
<p>yarn.app.mapreduce.am.admin-command-opts<br>未配置<br>Java 出于管理目的选择了 MR App Master 进程.它会出现在由 yarn.app.mapreduce.am.command-opts 设置的选项之前,因此它的选项可以被用户覆盖.如果使用 hadoop 本机库,使用 -Djava.library.path 可能会导致程序不再运行.应该使用 mapreduce.map.env 和 mapreduce.reduce.env 配置设置将这些值设置为 map/reduce JVM env 中 LD_LIBRARY_PATH 的一部分.</p>
<p>yarn.app.mapreduce.am.command-opts<br>-Xmx1024m<br>Java 选择 MR App Master 进程.以下符号(如果存在)将被插入:@taskid@ 被当前 TaskID 替换.任何其他出现的&quot;@&quot;都将保持不变.例如,要启用详细 gc 日志记录到以 /tmp 中的 taskid 命名的文件并将堆最大值设置为千兆字节,请传递以下&quot;值&quot;:-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid @.gc 使用 -Djava.library.path 可能会导致程序在使用 hadoop 本机库时不再运行.应该使用 mapreduce.map.env 和 mapreduce.reduce.env 配置设置将这些值设置为 map/reduce JVM env 中 LD_LIBRARY_PATH 的一部分.</p>
<p>yarn.app.mapreduce.am.container.log.backups<br>0<br>使用 ContainerRollingLogAppender (CRLA) 时 ApplicationMaster 日志的备份文件数.请参阅 org.apache.log4j.RollingFileAppender.maxBackupIndex.默认使用 ContainerLogAppender (CLA),不滚动容器日志.当 mapreduce.task.userlog.limit.kb 和 yarn.app.mapreduce.am.container.log.backups 都大于零时,为 ApplicationMaster 启用 CRLA.</p>
<p>yarn.app.mapreduce.am.container.log.limit.kb<br>0<br>MRAppMaster 尝试容器日志的最大大小以 KB 为单位.0 禁用上限.</p>
<p>yarn.app.mapreduce.am.env<br>未配置<br>用户为 MR App Master 进程添加了环境变量.示例: 1) A=foo 这会将环境变量 A 设置为 foo 2) B=$B:c 这是继承 tasktracker 的 B 环境变量.</p>
<p>yarn.app.mapreduce.am.job.client.port-range<br>未配置<br>MapReduce AM 绑定时可以使用的端口范围.如果您想要所有可能的端口,请留空.例如 50000-50050,50100-50200</p>
<p>yarn.app.mapreduce.am.job.committer.cancel-timeout<br>60000<br>如果作业被杀死,等待输出提交者取消操作的时间(以毫秒为单位)</p>
<p>yarn.app.mapreduce.am.job.committer.commit-window<br>10000<br>定义输出提交操作的时间窗口(以毫秒为单位).如果在此窗口内发生了与 RM 的联系,则允许提交,否则 AM 将不允许输出提交,直到重新建立与 RM 的联系.</p>
<p>yarn.app.mapreduce.am.job.task.listener.thread-count<br>30<br>用于处理 MR AppMaster 中来自远程任务的 RPC 调用的线程数</p>
<p>yarn.app.mapreduce.am.resource.cpu-vcores<br>1<br>MR AppMaster 需要的虚拟 CPU 内核数.</p>
<p>yarn.app.mapreduce.am.resource.mb<br>1536<br>MR AppMaster 需要的内存量.</p>
<p>yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms<br>1000<br>MR AppMaster 向 ResourceManager 发送心跳的时间间隔(毫秒)</p>
<p>yarn.app.mapreduce.am.staging-dir<br>/tmp/hadoop-yarn/staging<br>提交作业时使用的暂存目录.</p>
<p>yarn.app.mapreduce.client.max-retries<br>3<br>在抛出异常之前客户端重试 RM/HS 的次数.这是ipc之上的一层.</p>
<p>yarn.app.mapreduce.client-am.ipc.max-retries<br>3<br>客户端重试到 AM 的次数 - 在重新连接到 RM 以获取应用程序状态之前.</p>
<p>yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts<br>3<br>在重新连接到 RM 以获取应用程序状态之前,客户端对 AM 的套接字超时重试次数.</p>
<p>yarn.app.mapreduce.task.container.log.backups<br>0<br>使用 ContainerRollingLogAppender (CRLA) 时任务日志的备份文件数.请参阅 org.apache.log4j.RollingFileAppender.maxBackupIndex.默认使用 ContainerLogAppender (CLA),不滚动容器日志.当 mapreduce.task.userlog.limit.kb 和 yarn.app.mapreduce.task.container.log.backups 都大于零时,为任务启用 CRLA.</p>
<h2 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h2><p>dfs.block.access.key.update.interval<br>600<br>namenode 更新其访问密钥的时间间隔(以分钟为单位).</p>
<!-- more -->
<p>dfs.block.access.token.enable<br>FALSE<br>如果为&quot;true&quot;,则访问令牌用作访问数据节点的能力.如果为&quot;false&quot;,则在访问数据节点时不检查访问令牌.</p>
<p>dfs.block.access.token.lifetime<br>600<br>访问令牌的生命周期(以分钟为单位).</p>
<p>dfs.block.local-path-access.user<br>未配置<br>允许在遗留短路本地读取上打开块文件的用户的逗号分隔列表.</p>
<p>dfs.blockreport.initialDelay<br>0<br>第一个块报告的延迟(以秒为单位).</p>
<p>dfs.blockreport.intervalMsec<br>21600000<br>以毫秒为单位确定块报告间隔.</p>
<p>dfs.blockreport.split.threshold<br>1000000<br>如果 DataNode 上的块数低于此阈值,则它将在单个消息中发送所有存储目录的块报告.如果块数超过此阈值,则 DataNode 将在单独的消息中发送每个存储目录的块报告.设置为零以始终拆分.</p>
<p><font color="#dd0000">dfs.blocksize</font><br>134217728<br>新文件的默认块大小,以字节为单位.您可以使用以下后缀(不区分大小写):k(kilo)/m(mega)/g(giga)/t(tera)/p(peta)/e(exa) 来指定大小(如 128k/512m , 1g 等),或者以字节为单位提供完整大小(例如 134217728 表示 128 MB).</p>
<p>dfs.bytes-per-checksum<br>512<br>每个校验和的字节数.不得大于 dfs.stream-buffer-size</p>
<p>dfs.cachereport.intervalMsec<br>10000<br>以毫秒为单位确定缓存报告间隔.在这段时间之后,DataNode 将其缓存状态的完整报告发送到 NameNode.NameNode 使用缓存报告将其缓存块映射更新到 DataNode 位置.如果通过将 dfs.datanode.max.locked.memory 设置为 0(这是默认值)禁用了内存缓存,则此配置无效.如果本机库对 DataNode 不可用,则此配置无效.</p>
<p>dfs.client.block.write.replace-datanode-on-failure.best-effort<br>FALSE<br>仅当 dfs.client.block.write.replace-datanode-on-failure.enable 的值为 true 时才使用此属性.尽力而为意味着客户端将尝试在写入管道中替换失败的数据节点(前提是满足策略),但是,如果数据节点替换也失败,它会继续写入操作.假设数据节点替换失败.false:应该抛出异常,以便写入失败.true :应该使用剩余的数据恢复写入.请注意,将此属性设置为 true 允许写入具有较少数据节点的管道.结果,它增加了数据丢失的可能性.</p>
<p>dfs.client.block.write.replace-datanode-on-failure.enable<br>TRUE<br>如果写入管道中出现数据节点/网络故障,DFSClient 将尝试从管道中删除失败的数据节点,然后继续使用剩余的数据节点进行写入.结果,管道中的数据节点数量减少了.功能是将新的数据节点添加到管道中.这是启用/禁用该功能的站点范围的属性.当集群规模非常小时,例如 3 个节点或更少时,集群管理员可能希望在默认配置文件中将策略设置为 NEVER 或禁用此功能.否则,用户可能会遇到异常高的管道故障率,因为无法找到新的数据节点进行替换.另请参阅 dfs.client.block.write.replace-datanode-on-failure.policy</p>
<p>dfs.client.block.write.replace-datanode-on-failure.policy<br>DEFAULT<br>仅当 dfs.client.block.write.replace-datanode-on-failure.enable 的值为 true 时才使用此属性.始终:删除现有数据节点时始终添加新数据节点.从不:从不添加新的数据节点.默认值:设 r 为复制编号.设 n 为现有数据节点的数量.仅当 r 大于或等于 3 并且 (1) floor(r/2) 大于或等于 n 时,才添加新的数据节点；或 (2) r 大于 n 并且块被刷新/附加.</p>
<p>dfs.client.block.write.retries<br>3<br>在我们向应用程序发出失败信号之前,向数据节点写入块的重试次数.</p>
<p>dfs.client.cache.drop.behind.reads<br>未配置<br>就像 dfs.datanode.drop.cache.behind.reads 一样,此设置会导致页面缓存在 HDFS 读取之后被丢弃,从而可能释放更多内存用于其他用途.与 dfs.datanode.drop.cache.behind.reads 不同,这是客户端设置,而不是整个数据节点的设置.如果存在,此设置将覆盖 DataNode 默认值.如果本机库对 DataNode 不可用,则此配置无效.</p>
<p>dfs.client.cache.drop.behind.writes<br>未配置<br>就像 dfs.datanode.drop.cache.behind.writes 一样,此设置会导致页面缓存在 HDFS 写入之后被丢弃,从而可能释放更多内存用于其他用途.与 dfs.datanode.drop.cache.behind.writes 不同,这是一个客户端设置,而不是整个数据节点的设置.如果存在,此设置将覆盖 DataNode 默认值.如果本机库对 DataNode 不可用,则此配置无效.</p>
<p>dfs.client.cache.readahead<br>未配置<br>使用远程读取时,此设置会导致数据节点使用 posix_fadvise 提前读取块文件,从而可能减少 I/O 等待时间.与 dfs.datanode.readahead.bytes 不同,这是客户端设置,而不是整个数据节点的设置.如果存在,此设置将覆盖 DataNode 默认值.使用本地读取时,此设置决定了我们在 BlockReaderLocal 中执行多少预读.如果本机库对 DataNode 不可用,则此配置无效.</p>
<p>dfs.client.cached.conn.retry<br>3<br>HDFS 客户端从缓存中拉取套接字的次数.一旦超过这个数字,客户端将尝试创建一个新的套接字.</p>
<p>dfs.client.context<br>default<br>我们应该使用的 DFSClient 上下文的名称.共享上下文的客户端共享套接字缓存和短路缓存等.如果您不想与另一组线程共享,您应该只更改此设置.</p>
<p>dfs.client.datanode-restart.timeout<br>30<br>仅限专家.从收到快速重启的数据节点关闭通知到宣布数据节点死亡并调用正常恢复机制的等待时间(以秒为单位).通知由数据节点在关闭时使用带有升级选项的 shutdownDatanode 管理命令发送.</p>
<p>dfs.client.domain.socket.data.traffic<br>FALSE<br>这控制我们是否将尝试通过 UNIX 域套接字而不是通过节点本地数据传输的 TCP 套接字传递正常数据流量.这目前是实验性的,默认情况下是关闭的.</p>
<p>dfs.client.failover.connection.retries<br>0<br>仅限专家.指示故障转移 IPC 客户端为建立服务器连接而重试的次数.</p>
<p>dfs.client.failover.connection.retries.on.timeouts<br>0<br>仅限专家.建立服务器连接时,故障转移 IPC 客户端将在套接字超时时重试的次数.</p>
<p>dfs.client.failover.max.attempts<br>15<br>仅限专家.在故障转移被视为失败之前应进行的客户端故障转移尝试次数.</p>
<p>dfs.client.failover.sleep.base.millis<br>500<br>仅限专家.故障转移尝试之间的等待时间(以毫秒为单位)作为迄今为止尝试次数的函数呈指数增长,随机系数为 +/- 50%.此选项指定故障转移计算中使用的基值.第一次故障转移将立即重试.第二次故障转移尝试将至少延迟 dfs.client.failover.sleep.base.millis 毫秒.等等.</p>
<p>dfs.client.failover.sleep.max.millis<br>15000<br>仅限专家.故障转移尝试之间的等待时间(以毫秒为单位)作为迄今为止尝试次数的函数呈指数增长,随机系数为 +/- 50%.此选项指定故障转移之间等待的最大值.具体来说,两次故障转移尝试之间的时间不会超过 dfs.client.failover.sleep.max.millis 毫秒的 +/- 50%.</p>
<p>dfs.client.file-block-storage-locations.num-threads<br>10<br>在 DistributedFileSystem#getFileBlockStorageLocations() 中用于创建并行 RPC 的线程数.</p>
<p>dfs.client.file-block-storage-locations.timeout.millis<br>1000<br>在 DistributedFileSystem#getFileBlockStorageLocations() 中进行的并行 RPC 的超时(以毫秒为单位).</p>
<p>dfs.client.https.keystore.resource<br>ssl-client.xml<br>将从中提取 ssl 客户端密钥库信息的资源文件</p>
<p>dfs.client.https.need-auth<br>FALSE<br>是否需要 SSL 客户端证书认证</p>
<p>dfs.client.local.interfaces<br>未配置<br>以逗号分隔的网络接口名称列表,用于客户端和数据节点之间的数据传输.当创建连接以读取或写入数据节点时,客户端随机选择指定接口之一并将其套接字绑定到该接口的 IP.单个名称可以指定为接口名称(例如&quot;eth0&quot;)/子接口名称(例如&quot;eth0:0&quot;)或 IP 地址(可以使用 CIDR 表示法指定以匹配 IP 范围).</p>
<p>dfs.client.mmap.cache.size<br>256<br>当使用零拷贝读取时,DFSClient 会保留最近使用的内存映射区域的缓存.此参数控制我们将保留在该缓存中的最大条目数.这个数字越大,我们可能用于内存映射文件的文件描述符就越多.mmaped 文件也使用虚拟地址空间.在增加客户端 mmap 缓存大小之前,您可能需要增加 ulimit 虚拟地址空间限制.请注意,当此大小设置为 0 时,您仍然可以进行零拷贝读取.</p>
<p>dfs.client.mmap.cache.timeout.ms<br>3600000<br>我们将在两次使用之间在缓存中保留 mmap 条目的最短时间.如果一个条目在缓存中的时间比这个长,并且没有人使用它,它将被后台线程删除.</p>
<p>dfs.client.mmap.enabled<br>TRUE<br>如果设置为 false,客户端将不会尝试执行内存映射读取.</p>
<p>dfs.client.mmap.retry.timeout.ms<br>300000<br>在重试失败的 mmap 操作之前我们将等待的最短时间.</p>
<p>dfs.client.read.shortcircuit<br>FALSE<br>此配置参数打开短路本地读取.</p>
<p>dfs.client.read.shortcircuit.skip.checksum<br>FALSE<br>如果设置了此配置参数,短路本地读取将跳过校验和.通常不建议这样做,但它可能对特殊设置有用.如果您在 HDFS 之外进行自己的校验和,则可以考虑使用它.</p>
<p>dfs.client.read.shortcircuit.streams.cache.expiry.ms<br>300000<br>这控制了文件描述符在因为太长时间处于非活动状态而被关闭之前需要位于客户端缓存上下文中的最短时间.</p>
<p>dfs.client.read.shortcircuit.streams.cache.size<br>256<br>DFSClient 维护最近打开的文件描述符的缓存.此参数控制该缓存的大小.将此设置得更高将使用更多文件描述符,但可能会在涉及大量搜索的工作负载上提供更好的性能.</p>
<p>dfs.client.short.circuit.replica.stale.threshold.ms<br>1800000<br>如果 DataNode 没有通信,我们将认为短路副本有效的最长时间.这段时间过去后,我们将重新获取短路副本,即使它在缓存中.</p>
<p>dfs.client.slow.io.warning.threshold.ms<br>30000<br>我们将在 dfsclient 中记录慢速 io 警告的阈值(以毫秒为单位).默认情况下,此参数设置为 30000 毫秒(30 秒).</p>
<p>dfs.client.use.datanode.hostname<br>FALSE<br>客户端在连接到数据节点时是否应该使用数据节点主机名.</p>
<p>dfs.client.use.legacy.blockreader.local<br>FALSE<br>如果此配置参数为真,则使用基于 HDFS-2246 的传统短路读取器实现.这适用于 Linux 以外的平台,其中基于 HDFS-347 的新实现不可用.</p>
<p>dfs.client.write.exclude.nodes.cache.expiry.interval.millis<br>600000<br>在客户端的排除节点列表中保留 DN 的最长时间.在此时间段之后,以毫秒为单位,先前排除的节点将自动从缓存中删除,并将再次被认为有利于块分配.在您保持文件打开很长时间(例如预写日志(WAL)文件)的情况下降低或提高很有用,以使写入器能够容忍集群维护重新启动.默认为 10 分钟.</p>
<p>dfs.client-write-packet-size<br>65536<br>客户端写入的数据包大小</p>
<p>dfs.cluster.administrators<br>未配置<br>管理员的 ACL,此配置用于控制谁可以访问 namenode 中的默认 servlet 等.该值应该是逗号分隔的用户和组列表.用户列表在前,由一个空格隔开,后面是组列表,例如&quot;user1,user2 group1,group2&quot;.用户和组都是可选的,因此&quot;user1&quot;/&quot;group1&quot;/&quot;&quot;/&quot;user1 group1&quot;/&quot;user1,user2 group1,group2&quot;都是有效的(注意&quot;group1&quot;中的前导空格).&#39;<em>&#39; 授予所有用户和组的访问权限,例如&#39;</em>&#39;/&#39;<em>&#39; 和&#39;</em>&#39; 都是有效的.</p>
<p>dfs.data.transfer.protection<br>未配置<br>以逗号分隔的 SASL 保护值列表,用于在读取或写入块数据时与 DataNode 的安全连接.可能的值是身份验证/完整性和隐私.身份验证意味着仅身份验证,没有完整性或隐私性；完整性意味着启用了身份验证和完整性；隐私意味着启用所有身份验证/完整性和隐私.如果 dfs.encrypt.data.transfer 设置为 true,则它将取代 dfs.data.transfer.protection 的设置并强制所有连接必须使用专门的加密 SASL 握手.对于侦听特权端口的 DataNode 的连接,此属性将被忽略.在这种情况下,假设使用特权端口建立了足够的信任.</p>
<p>dfs.data.transfer.saslproperties.resolver.class<br>未配置<br>SaslPropertiesResolver 用于在读取或写入块数据时解析用于连接到 DataNode 的 QOP.如果未指定,则使用 hadoop.security.saslproperties.resolver.class 的值作为默认值.</p>
<p>dfs.datanode.address<br>0.0.0.0:50010<br>数据传输的datanode服务器地址和端口.</p>
<p>dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction<br>0.75f<br>仅当 dfs.datanode.fsdataset.volume.choosing.policy 设置为 org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy 时使用.此设置控制将多少百分比的新块分配发送到可用磁盘空间比其他卷更多的卷.此设置应在 0.0 - 1.0 的范围内,但实际上是 0.5 - 1.0,因为没有理由希望具有较少可用磁盘空间的卷接收更多块分配.</p>
<p>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold<br>10737418240<br>仅当 dfs.datanode.fsdataset.volume.choosing.policy 设置为 org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy 时使用.此设置控制 DN 卷在被视为不平衡之前允许在可用磁盘空间字节方面存在多少差异.如果所有卷的可用空间都在此范围内,则卷将被认为是平衡的,并且块分配将在纯循环的基础上完成.</p>
<p>dfs.datanode.balance.bandwidthPerSec<br>1048576<br>以每秒字节数的形式指定每个数据节点可用于平衡目的的最大带宽量.</p>
<p>dfs.datanode.block.id.layout.upgrade.threads<br>12<br>在将 DataNode 升级到基于块 ID 的块布局期间创建从当前块到先前块的硬链接时使用的线程数(有关布局的详细信息,请参阅 HDFS-6482).</p>
<p>dfs.datanode.bp-ready.timeout<br>20<br>在接收到的请求失败之前,datanode 准备就绪的最大等待时间.如果数据节点尚未向名称节点注册,则将此设置为 0 会立即失败请求.此等待时间减少了 datanode 重新启动后的初始请求失败.</p>
<p>dfs.datanode.cache.revocation.polling.ms<br>500<br>DataNode 应该多久轮询一次以查看客户端是否停止使用 DataNode 想要取消缓存的副本.</p>
<p>dfs.datanode.cache.revocation.timeout.ms<br>900000<br>当 DFSClient 从 DataNode 缓存的块文件中读取数据时,DFSClient 可以跳过验证校验和.DataNode 会将块文件保存在缓存中,直到客户端完成.但是,如果客户端花费了异常长的时间,DataNode 可能需要从缓存中逐出块文件.该值控制 DataNode 等待客户端释放它正在读取的副本而没有校验和的时间.</p>
<p><font color="#dd0000">dfs.datanode.data.dir</font><br>file://<code>$&#123;hadoop.tmp.dir&#125;</code>/dfs/data<br>确定 DFS 数据节点应在本地文件系统上存储其块的位置.如果这是一个逗号分隔的目录列表,那么数据将存储在所有命名的目录中,通常在不同的设备上.不存在的目录将被忽略.</p>
<p>dfs.datanode.data.dir.perm<br>700<br>DFS 数据节点存储其块的本地文件系统上的目录的权限.权限可以是八进制或符号.</p>
<p>dfs.datanode.directoryscan.interval<br>21600<br>Datanode 扫描数据目录并协调内存和磁盘块之间的差异的时间间隔(以秒为单位).</p>
<p>dfs.datanode.directoryscan.threads<br>1<br>用于并行编译卷报告的线程池应该有多少线程.</p>
<p>dfs.datanode.dns.interface<br>default<br>数据节点应报告其 IP 地址的网络接口的名称.</p>
<p>dfs.datanode.dns.nameserver<br>default<br>名称服务器 (DNS) 的主机名或 IP 地址,DataNode 应使用它来确定 NameNode 用于通信和显示目的的主机名.</p>
<p>dfs.datanode.drop.cache.behind.reads<br>FALSE<br>在某些工作负载中,已知从 HDFS 读取的数据非常大,以至于将其缓存在操作系统缓冲区缓存中不太可能有用.在这种情况下,DataNode 可以配置为在将数据传递给客户端后自动清除缓冲区缓存中的所有数据.对于只读取块的一小部分的工作负载(例如 HBase 随机 IO 工作负载),此行为会自动禁用.这可以通过释放缓冲区高速缓存页面使用以获取更多可高速缓存数据来提高某些工作负载的性能.如果 Hadoop 本机库不可用,则此配置无效.</p>
<p>dfs.datanode.drop.cache.behind.writes<br>FALSE<br>在某些工作负载中,已知写入 HDFS 的数据足够大,以至于将其缓存在操作系统缓冲区缓存中不太可能有用.在这种情况下,DataNode 可以配置为在写入磁盘后自动从缓冲区缓存中清除所有数据.这可以通过释放缓冲区高速缓存页面使用以获取更多可高速缓存数据来提高某些工作负载的性能.如果 Hadoop 本机库不可用,则此配置无效.</p>
<p><font color="#dd0000">dfs.datanode.du.reserved</font><br>0<br>每个卷的保留空间(以字节为单位).始终留出这么多空间供非 dfs 使用.</p>
<p><font color="#dd0000">dfs.datanode.failed.volumes.tolerated</font><br>0<br>在数据节点停止提供服务之前允许失败的卷数.默认情况下,任何卷故障都会导致数据节点关闭.</p>
<p>dfs.datanode.fsdatasetcache.max.threads.per.volume<br>4<br>每个卷用于在数据节点上缓存新数据的最大线程数.这些线程同时消耗 I/O 和 CPU.这可能会影响正常的数据节点操作.</p>
<p><font color="#dd0000">dfs.datanode.handler.count</font><br>10<br>数据节点的服务器线程数.</p>
<p>dfs.datanode.hdfs-blocks-metadata.enabled<br>FALSE<br>布尔值,它启用对实验性 DistributedFileSystem#getFileVBlockStorageLocations API 的后端数据节点端支持.</p>
<p>dfs.datanode.http.address<br>0.0.0.0:50075<br>datanode http 服务器地址和端口.</p>
<p>dfs.datanode.https.address<br>0.0.0.0:50475<br>datanode 保护 http 服务器地址和端口.</p>
<p>dfs.datanode.ipc.address<br>0.0.0.0:50020<br>datanode ipc 服务器地址和端口.</p>
<p>dfs.datanode.max.locked.memory<br>0<br>用于在数据节点上的内存中缓存块副本的内存量(以字节为单位).数据节点的最大锁定内存软 ulimit (RLIMIT_MEMLOCK) 必须至少设置为该值,否则数据节点将在启动时中止.默认情况下,此参数设置为 0,即禁用内存缓存.如果本机库对 DataNode 不可用,则此配置无效.</p>
<p><font color="#dd0000">dfs.datanode.max.transfer.threads</font><br>4096<br>指定用于将数据传入和传出 DN 的最大线程数.</p>
<p>dfs.datanode.plugins<br>未配置<br>要激活的数据节点插件的逗号分隔列表.</p>
<p>dfs.datanode.readahead.bytes<br>4193404<br>在读取块文件时,如果 Hadoop 本地库可用,则数据节点可以使用 posix_fadvise 系统调用将数据显式分页到当前读取器位置之前的操作系统缓冲区缓存中.这可以提高性能,尤其是在磁盘高度争用时.此配置指定数据节点将尝试提前读取的当前读取位置之前的字节数.通过将此属性配置为 0 可以禁用此功能.如果本机库不可用,则此配置无效.</p>
<p>dfs.datanode.shared.file.descriptor.paths<br>/dev/shm,/tmp<br>创建将在 DataNode 和 DFSClient 之间共享的文件描述符时使用的路径的逗号分隔列表.通常我们使用 /dev/shm,这样文件描述符就不会被写入磁盘.默认情况下,没有 /dev/shm 的系统将回退到 /tmp.</p>
<p>dfs.datanode.shared.file.descriptor.paths<br>/dev/shm,/tmp<br>创建共享内存段的目录的逗号分隔路径.客户端和 DataNode 通过这个共享内存段交换信息.它按顺序尝试路径,直到创建共享内存段成功.</p>
<p>dfs.datanode.slow.io.warning.threshold.ms<br>300<br>我们将在数据节点中记录慢速 io 警告的阈值(以毫秒为单位).默认情况下,此参数设置为 300 毫秒.</p>
<p>dfs.datanode.sync.behind.writes<br>FALSE<br>如果启用此配置,datanode 将指示操作系统在写入后立即将所有写入的数据排队到磁盘.这与通常的操作系统策略不同,通常的操作系统策略可能会等待最多 30 秒才能触发回写.这可以通过平滑写入磁盘的数据的 IO 配置文件来提高某些工作负载的性能.如果 Hadoop 本机库不可用,则此配置无效.</p>
<p>dfs.datanode.use.datanode.hostname<br>FALSE<br>在连接到其他数据节点进行数据传输时,数据节点是否应使用数据节点主机名.</p>
<p>dfs.default.chunk.view.size<br>32768<br>在浏览器上查看文件的字节数.</p>
<p>dfs.domain.socket.path<br>未配置<br>可选的.这是一个 UNIX 域套接字的路径,将用于 DataNode 和本地 HDFS 客户端之间的通信.如果此路径中存在字符串&quot;<code>_PORT</code>&quot;,它将被 DataNode 的 TCP 端口替换.</p>
<p>dfs.encrypt.data.transfer<br>FALSE<br>从 HDFS 读取/写入/写入 HDFS 的实际块数据是否应在线加密.只需在 NN 和 DN 上设置,客户端会自动推断.可以通过 dfs.trustedchannel.resolver.class 指定自定义逻辑来覆盖每个连接的此设置.</p>
<p>dfs.encrypt.data.transfer.algorithm<br>未配置<br>该值可以设置为&quot;3des&quot;或&quot;rc4&quot;.如果未设置任何内容,则使用系统上配置的 JCE 默认值(通常为 3DES).人们普遍认为 3DES 在密码学上更安全,但 RC4 的速度要快得多.请注意,如果客户端和服务器都支持 AES,则此加密算法将仅用于最初传输 AES 的密钥.(参见 dfs.encrypt.data.transfer.cipher.suites.)</p>
<p>dfs.encrypt.data.transfer.cipher.key.bitlength<br>128<br>由 dfsclient 和 datanode 协商的用于加密的密钥位长.该值可以设置为 128/192 或 256.</p>
<p>dfs.encrypt.data.transfer.cipher.suites<br>未配置<br>该值可以是未定义的或 AES/CTR/NoPadding.如果已定义,则 dfs.encrypt.data.transfer 使用指定的密码套件进行数据加密.如果未定义,则仅使用 dfs.encrypt.data.transfer.algorithm 中指定的算法.默认情况下,该属性未定义.</p>
<p>dfs.encryption.key.provider.uri<br>未配置<br>与读取和写入加密区域时使用的加密密钥交互时使用的 KeyProvider.</p>
<p><font color="#dd0000">dfs.ha.automatic-failover.enabled&gt;</font><br>FALSE<br>是否启用自动故障转移.有关自动 HA 配置的详细信息,请参阅 HDFS 高可用性文档.</p>
<p>dfs.ha.log-roll.period<br>120<br>StandbyNode 应要求活动节点滚动编辑日志的频率(以秒为单位).由于 StandbyNode 仅从最终确定的日志段中读取,因此 StandbyNode 将仅与日志滚动的频率一样是最新的.请注意,故障转移会触发日志滚动,因此 StandbyNode 在变为活动状态之前将是最新的.</p>
<p>dfs.ha.namenode.id<br>未配置<br>此名称节点的 ID.如果 namenode ID 未配置,则通过将本地节点的地址与配置的地址匹配来自动确定.</p>
<p><font color="#dd0000">dfs.ha.namenodes.EXAMPLENAMESERVICE</font><br>未配置<br>给定名称服务的前缀包含一个以逗号分隔的名称节点列表,用于给定名称服务(例如,EXAMPLENAMESERVICE).</p>
<p>dfs.ha.tail-edits.period<br>60<br>StandbyNode 应以秒为单位检查共享编辑日志中新的最终日志段的频率.</p>
<p>dfs.heartbeat.interval<br>3<br>以秒为单位确定 datanode 心跳间隔.</p>
<p><font color="#dd0000">dfs.hosts</font><br>未配置<br>命名一个包含允许连接到名称节点的主机列表的文件.必须指定文件的完整路径名.如果该值为空,则允许所有主机.</p>
<p><font color="#dd0000">dfs.hosts.exclude</font><br>未配置<br>命名一个包含不允许连接到名称节点的主机列表的文件.必须指定文件的完整路径名.如果该值为空,则不排除任何主机.</p>
<p>dfs.http.policy<br>HTTP_ONLY<br>决定 HDFS 是否支持 HTTPS(SSL) 这将为 HDFS 守护进程配置 HTTP 端点:支持以下值: - HTTP_ONLY :仅在 http 上提供服务 - HTTPS_ONLY :仅在 https 上提供服务 - HTTP_AND_HTTPS :同时提供服务在 http 和 https</p>
<p>dfs.https.enable<br>FALSE<br>已弃用.请改用&quot;dfs.http.policy&quot;.</p>
<p>dfs.https.server.keystore.resource<br>ssl-server.xml<br>将从中提取 ssl 服务器密钥库信息的资源文件</p>
<p>dfs.image.compress<br>FALSE<br>dfs图像应该被压缩吗?</p>
<p>dfs.image.compression.codec<br>org.apache.hadoop.io.compress.DefaultCodec<br>如果dfs图像被压缩了,应该怎么压缩呢?这必须是 io.compression.codecs 中定义的编解码器.</p>
<p>dfs.image.transfer.bandwidthPerSec<br>0<br>用于图像传输的最大带宽,以每秒字节数为单位.这有助于在检查点期间保持正常的名称节点操作响应.应设置 dfs.image.transfer.timeout 中的最大带宽和超时,以便正常图像传输可以成功完成.默认值 0 表示禁用限制.</p>
<p>dfs.image.transfer.chunksize<br>65536<br>以字节为单位上传检查点的块大小.分块流用于避免对大尺寸图像文件的内容进行内部缓冲.</p>
<p>dfs.image.transfer.timeout<br>60000<br>图像传输的套接字超时(以毫秒为单位).应配置此超时和相关的 dfs.image.transfer.bandwidthPerSec 参数,以便正常图像传输可以成功完成.此超时可防止在图像传输期间发送方失败时客户端挂起.这是图像传输期间的套接字超时.</p>
<p>dfs.internal.nameservices<br>未配置<br>属于此集群的名称服务的逗号分隔列表.Datanode 将向此列表中的所有名称服务报告.默认情况下,这设置为 dfs.nameservices 的值.</p>
<p>dfs.journalnode.http-address<br>0.0.0.0:8480<br>JournalNode HTTP 服务器监听的地址和端口.如果端口为 0,则服务器将在空闲端口上启动.</p>
<p>dfs.journalnode.https-address<br>0.0.0.0:8481<br>JournalNode HTTPS 服务器监听的地址和端口.如果端口为 0,则服务器将在空闲端口上启动.</p>
<p>dfs.journalnode.rpc-address<br>0.0.0.0:8485<br>JournalNode RPC 服务器地址和端口.</p>
<p>dfs.metrics.percentiles.intervals<br>未配置<br>以逗号分隔的整数集,表示 Namenode 和 Datanode 上百分位延迟指标的所需翻转间隔(以秒为单位).默认情况下,百分位延迟指标被禁用.</p>
<p>dfs.namenode.accesstime.precision<br>3600000<br>HDFS 文件的访问时间精确到此值.默认值为 1 小时.将值设置为 0 将禁用 HDFS 的访问时间.</p>
<p>dfs.namenode.acls.enabled<br>FALSE<br>设置为 true 以启用对 HDFS ACL(访问控制列表)的支持.默认情况下,ACL 被禁用.当 ACL 被禁用时,NameNode 会拒绝所有与设置或获取 ACL 相关的 RPC.</p>
<p>dfs.namenode.audit.loggers<br>default<br>实现将接收审计事件的审计记录器的类列表.这些应该是 org.apache.hadoop.hdfs.server.namenode.AuditLogger 的实现.特殊值&quot;default&quot;可用于引用默认审计记录器,该记录器使用配置的日志系统.安装自定义审计记录器可能会影响 NameNode 的性能和稳定性.有关更多详细信息,请参阅自定义记录器的文档.</p>
<p>dfs.namenode.avoid.read.stale.datanode<br>FALSE<br>指示是否避免从名称节点未收到心跳消息超过指定时间间隔的&quot;陈旧&quot;数据节点读取.陈旧的数据节点将被移动到返回的节点列表的末尾以供读取.有关写入的类似设置,请参见 dfs.namenode.avoid.write.stale.datanode.</p>
<p>dfs.namenode.avoid.write.stale.datanode<br>FALSE<br>指示是否避免写入名称节点超过指定时间间隔未收到心跳消息的&quot;陈旧&quot;数据节点.写入将避免使用陈旧的数据节点,除非超过配置的数据节点比率 (dfs.namenode.write.stale.datanode.ratio) 被标记为陈旧.有关读取的类似设置,请参见 dfs.namenode.avoid.read.stale.datanode.</p>
<p>dfs.namenode.backup.address<br>0.0.0.0:50100<br>备份节点服务器地址和端口.如果端口为 0,则服务器将在空闲端口上启动.</p>
<p>dfs.namenode.backup.http-address<br>0.0.0.0:50105<br>备份节点http服务器地址和端口.如果端口为 0,则服务器将在空闲端口上启动.</p>
<p><font color="#dd0000">dfs.namenode.checkpoint.check.period</font><br>60<br>SecondaryNameNode 和 CheckpointNode 将每隔 &#39;dfs.namenode.checkpoint.check.period&#39; 秒轮询 NameNode 以查询未检查点事务的数量.</p>
<p><font color="#dd0000">dfs.namenode.checkpoint.dir</font><br>file://<code>$&#123;hadoop.tmp.dir&#125;</code>/dfs/namesecondary<br>确定 DFS 辅助名称节点应在本地文件系统上存储要合并的临时图像的位置.如果这是一个以逗号分隔的目录列表,则该映像将复制到所有目录中以实现冗余.</p>
<p>dfs.namenode.checkpoint.edits.dir<br>${dfs.namenode.checkpoint.dir}<br>确定 DFS 辅助名称节点应在本地文件系统上存储临时编辑以合并的位置.如果这是一个以逗号分隔的目录列表,则编辑将复制到所有目录中以实现冗余.默认值与 dfs.namenode.checkpoint.dir 相同</p>
<p>dfs.namenode.checkpoint.max-retries<br>3<br>SecondaryNameNode 重试失败的检查点.如果在加载 fsimage 或重播编辑时发生故障,则重试次数受此变量限制.</p>
<p><font color="#dd0000">dfs.namenode.checkpoint.period</font><br>3600<br>两个定期检查点之间的秒数.</p>
<p><font color="#dd0000">dfs.namenode.checkpoint.txns</font><br>1000000<br>辅助 NameNode 或 CheckpointNode 将在每个 &#39;dfs.namenode.checkpoint.txns&#39; 事务中创建一个命名空间的检查点,无论 &#39;dfs.namenode.checkpoint.period&#39; 是否已过期.</p>
<p>dfs.namenode.datanode.registration.ip-hostname-check<br>TRUE<br>如果为真(默认值),则名称节点要求连接数据节点的地址必须解析为主机名.如有必要,将执行反向 DNS 查找.所有从无法解析的地址注册数据节点的尝试都被拒绝.建议保留此设置,以防止在 DNS 中断期间意外注册排除文件中的主机名列出的数据节点.仅在没有支持反向 DNS 查找的基础设施的环境中将此设置为 false.</p>
<p>dfs.namenode.decommission.interval<br>30<br>Namenode 以秒为单位的周期检查是否完成退役.</p>
<p>dfs.namenode.decommission.nodes.per.interval<br>5<br>节点数namenode检查是否在每个dfs.namenode.decommission.interval中完成了退役.</p>
<p>dfs.namenode.delegation.key.update-interval<br>86400000<br>名称节点中委托令牌的主密钥的更新间隔(以毫秒为单位).</p>
<p>dfs.namenode.delegation.token.max-lifetime<br>604800000<br>委托令牌有效的最大生命周期(以毫秒为单位).</p>
<p>dfs.namenode.delegation.token.renew-interval<br>86400000<br>委托令牌的更新间隔,以毫秒为单位.</p>
<p>dfs.namenode.edit.log.autoroll.check.interval.ms<br>300000<br>活动名称节点多久检查一次是否需要滚动其编辑日志,以毫秒为单位.</p>
<p>dfs.namenode.edit.log.autoroll.multiplier.threshold<br>2<br>确定活动名称节点何时滚动其自己的编辑日志.实际阈值(以编辑次数计)是通过将此值乘以 dfs.namenode.checkpoint.txns 来确定的.这可以防止非常大的编辑文件在活动名称节点上累积,这可能导致名称节点启动期间超时并造成管理麻烦.当备用或辅助名称节点未能按正常检查点阈值滚动编辑日志时,此行为旨在作为故障保护.</p>
<p>dfs.namenode.edits.dir<br><code>$&#123;dfs.namenode.name.dir&#125;</code><br>确定 DFS 名称节点应在本地文件系统上存储事务(编辑)文件的位置.如果这是一个以逗号分隔的目录列表,则事务文件将复制到所有目录中,以实现冗余.默认值与 dfs.namenode.name.dir 相同</p>
<p>dfs.namenode.edits.journal-plugin.qjournal<br>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</p>
<p>dfs.namenode.edits.noeditlogchannelflush<br>FALSE<br>指定是否刷新编辑日志文件通道.设置后,将跳过昂贵的 FileChannel#force 调用,而是通过打开带有 RandomAccessFile(&quot;rws&quot;) 标志的编辑日志文件来启用同步磁盘写入.这可以显着提高 Windows 平台上编辑日志写入的性能.请注意,&quot;rws&quot;标志的行为是特定于平台和硬件的,可能无法提供与 FileChannel#force 相同级别的保证.例如,写入将跳过 SAS 和 SCSI 设备上的磁盘缓存,而它可能不会在 SATA 设备上.这是专家级别的设置,请谨慎更改.</p>
<p>dfs.namenode.enable.retrycache<br>TRUE<br>这会在名称节点上启用重试缓存.Namenode 跟踪非幂等请求的相应响应.如果客户端重试请求,则发送来自重试缓存的响应.此类操作在名称节点协议中使用注释 @AtMostOnce 进行标记.建议将此标志设置为 true.将其设置为 false,将导致客户端获得对重试请求的失败响应.必须在 HA 设置中启用此标志以进行透明故障转移.缓存中的条目具有使用 dfs.namenode.retrycache.expirytime.millis 可配置的过期时间.</p>
<p>dfs.namenode.fs-limits.max-blocks-per-file<br>1048576<br>每个文件的最大块数,由 Namenode 在写入时强制执行.这可以防止创建会降低性能的超大文件.</p>
<p>dfs.namenode.fs-limits.max-component-length<br>255<br>定义路径的每个组件中 UTF-8 编码的最大字节数.值 0 将禁用检查.</p>
<p>dfs.namenode.fs-limits.max-directory-items<br>1048576<br>定义目录可能包含的最大项目数.值 0 将禁用检查.</p>
<p>dfs.namenode.fs-limits.max-xattr-size<br>16384<br>扩展属性的名称和值的最大组合大小(以字节为单位).</p>
<p>dfs.namenode.fs-limits.max-xattrs-per-inode<br>32<br>每个 inode 的最大扩展属性数.</p>
<p><font color="#dd0000">dfs.namenode.fs-limits.min-block-size</font><br>1048576<br>Namenode 在创建时强制执行的最小块大小(以字节为单位).这可以防止意外创建具有小块大小(因此有很多块)的文件,这会降低性能.</p>
<p><font color="#dd0000">dfs.namenode.handler.count</font><br>10<br>namenode 的服务器线程数.</p>
<p><font color="#dd0000">dfs.namenode.http-address</font><br>0.0.0.0:50070<br>dfs namenode web ui 将侦听的地址和基本端口.</p>
<p>dfs.namenode.http-bind-host<br>未配置<br>HTTP 服务器将绑定到的实际地址.如果设置了这个可选地址,它只会覆盖 dfs.namenode.http-address 的主机名部分.它也可以为 HA/Federation 的每个名称节点或名称服务指定.这对于通过将名称节点 HTTP 服务器设置为 0.0.0.0 来侦听所有接口非常有用.</p>
<p>dfs.namenode.https-address<br>0.0.0.0:50470<br>namenode 保护 http 服务器地址和端口.</p>
<p>dfs.namenode.https-bind-host<br>未配置<br>HTTPS 服务器将绑定到的实际地址.如果设置了这个可选地址,它只会覆盖 dfs.namenode.https-address 的主机名部分.它也可以为 HA/Federation 的每个名称节点或名称服务指定.这对于通过将名称节点 HTTPS 服务器设置为 0.0.0.0 来侦听所有接口非常有用.</p>
<p>dfs.namenode.inotify.max.events.per.rpc<br>1000<br>在单个 RPC 响应中将发送到 inotify 客户端的最大事件数.默认值尝试分摊此 RPC 的开销,同时避免客户端和 NameNode 的巨大内存需求(1000 个事件消耗的内存不应超过 1 MB.)</p>
<p>dfs.namenode.invalidate.work.pct.per.iteration<br>0.32f<br><em>注意</em>:高级属性.谨慎更改.这决定了对单个 DN 检测信号删除命令执行的块失效(删除)百分比.最终删除计数是通过将此百分比应用于系统中的活动节点数来确定的.结果数字是从删除列表中选择的块数,用于在单个 DN 的单个心跳上正确失效.值应该是浮点表示法 (X.Yf) 中的正非零百分比,其中 1.0f 表示 100%.</p>
<p>dfs.namenode.kerberos.internal.spnego.principal<br>${dfs.web.authentication.kerberos.principal}</p>
<p>dfs.namenode.lazypersist.file.scrub.interval.sec<br>300<br>NameNode 定期扫描名称空间中缺少块的 LazyPersist 文件,并将它们与名称空间断开链接.此配置键控制连续扫描之间的间隔.将其设置为负值以禁用此行为.</p>
<p>dfs.namenode.legacy-oiv-image.dir<br>未配置<br>确定在备用 NameNode 或 SecondaryNameNode 进行检查点期间以旧 fsimage 格式保存命名空间的位置.用户可以通过 oiv_legacy 命令转储旧格式 fsimage 的内容.如果未指定该值,旧格式的 fsimage 将不会保存在检查点中.</p>
<p>dfs.namenode.list.cache.directives.num.responses<br>100<br>此值控制 NameNode 将通过线路发送以响应 listDirectives RPC 的缓存指令的数量.</p>
<p>dfs.namenode.list.cache.pools.num.responses<br>100<br>此值控制 NameNode 将通过线路发送以响应 listPools RPC 的缓存池数量.</p>
<p>dfs.namenode.list.encryption.zones.num.responses<br>100<br>列出加密区域时,将批量返回的最大区域数.分批增量获取列表可以提高名称节点的性能.</p>
<p>dfs.namenode.logging.level<br>info<br>dfs namenode 的日志记录级别.其他值是&quot;dir&quot;(跟踪命名空间突变)/&quot;block&quot;(跟踪块下/过度复制和块创建/删除)或&quot;all&quot;.</p>
<p>dfs.namenode.max.extra.edits.segments.retained<br>10000<br>应该保留的额外编辑日志段的最大数量超出了 NN 重新启动所需的最低限度.当与 dfs.namenode.num.extra.edits.retained 一起使用时,此配置属性用于将额外编辑文件的数量限制为合理的值.</p>
<p>dfs.namenode.max.objects<br>0<br>dfs 支持的文件/目录和块的最大数量.零值表示 dfs 支持的对象数量没有限制.</p>
<p><font color="#dd0000">dfs.namenode.name.dir</font><br>file://<code>$&#123;hadoop.tmp.dir&#125;</code>/dfs/name<br>确定 DFS 名称节点应在本地文件系统上存储名称表 (fsimage) 的位置.如果这是一个以逗号分隔的目录列表,则名称表将复制到所有目录中,以实现冗余.</p>
<p>dfs.namenode.name.dir.restore<br>FALSE<br>设置为 true 以启用 NameNode 尝试恢复以前失败的 dfs.namenode.name.dir.启用后,将在检查点期间尝试恢复任何失败的目录.</p>
<p><font color="#dd0000">dfs.namenode.num.checkpoints.retained</font><br>2<br>NameNode 和Secondary NameNode 将在其存储目录中保留的图像检查点文件的数量.从最早保留的检查点恢复最新命名空间所需的所有编辑日志也将被保留.</p>
<p>dfs.namenode.num.extra.edits.retained<br>1000000<br>应该保留的额外事务的数量超出了 NN 重新启动所需的最低限度.这对于审计目的或 HA 设置很有用,其中远程备用节点可能已经离线一段时间并且需要保留更长的保留编辑积压才能重新开始.通常,每次编辑大约为几百字节,因此默认的 100 万次编辑应该大约为数百 MB 或低 GB.注意:如果这样做意味着保留的段数多于 dfs.namenode.max.extra.edits.segments.retained 配置的数量,则保留的额外编辑可能少于为此设置指定的值.</p>
<p>dfs.namenode.path.based.cache.block.map.allocation.percent<br>0.25<br>我们将分配给缓存块映射的 Java 堆百分比.缓存块映射是使用链式哈希的哈希映射.如果缓存块的数量很大,则访问较小的地图可能会更慢；更大的地图会消耗更多的内存.</p>
<p>dfs.namenode.path.based.cache.refresh.interval.ms<br>30000<br>后续路径缓存重新扫描之间的毫秒数.路径缓存重新扫描是我们计算应该缓存哪些块以及在哪些数据节点上.默认情况下,此参数设置为 30 秒.</p>
<p>dfs.namenode.path.based.cache.retry.interval.ms<br>30000<br>当 NameNode 需要取消缓存已缓存的内容或缓存未缓存的内容时,它必须通过发送 DNA_CACHE 或 DNA_UNCACHE 命令来响应 DataNode 心跳来指示 DataNode 这样做.此参数控制 NameNode 重新发送这些命令的频率.</p>
<p>dfs.namenode.plugins<br>未配置<br>要激活的名称节点插件的逗号分隔列表.</p>
<p>dfs.namenode.reject-unresolved-dn-topology-mapping<br>FALSE<br>如果该值设置为 true,则如果数据节点的拓扑映射未解析并返回 NULL(net.topology.script.file.name 定义的脚本无法执行),namenode 将拒绝数据节点注册.否则,将注册datanode,并将默认机架分配为拓扑路径.拓扑路径对于数据弹性很重要,因为它们定义了故障域.因此,如果解析拓扑失败,允许数据节点注册到默认机架可能是不受欢迎的行为.</p>
<p>dfs.namenode.replication.considerLoad<br>TRUE<br>决定chooseTarget是否考虑目标的负载</p>
<p>dfs.namenode.replication.interval<br>3<br>namenode 计算数据节点的复制工作的周期(以秒为单位).</p>
<p>dfs.namenode.replication.min<br>1<br>最小块复制.</p>
<p>dfs.namenode.replication.work.multiplier.per.iteration<br>2<br>高级属性.谨慎更改.当这样的命令列表由 NN 通过 DN 心跳发送时,这决定了在 DN 处并行开始的用于复制的块传输总量.实际数量是通过将此乘数乘以集群中的活动节点总数获得的.结果数是每个 DN 心跳立即开始传输的块数.该数字可以是任何正的非零整数.</p>
<p>dfs.namenode.resource.check.interval<br>5000<br>NameNode 资源检查器运行的时间间隔(以毫秒为单位).检查器计算可用空间大于 dfs.namenode.resource.du.reserved 的 NameNode 存储卷的数量,如果数量低于 dfs.namenode.resource.checked.volumes 指定的最小值,则进入安全模式.最低限度.</p>
<p>dfs.namenode.resource.checked.volumes<br>未配置<br>NameNode 资源检查器除了本地编辑目录之外要检查的本地目录列表.</p>
<p>dfs.namenode.resource.checked.volumes.minimum<br>1<br>所需的冗余 NameNode 存储卷的最小数量.</p>
<p>dfs.namenode.resource.du.reserved<br>104857600<br>NameNode 存储目录保留/需要的空间量(以字节为单位).默认值为 100MB.</p>
<p>dfs.namenode.retrycache.expirytime.millis<br>600000<br>保留重试缓存条目的时间.</p>
<p>dfs.namenode.retrycache.heap.percent<br>0.03f<br>此参数配置为重试缓存分配的堆大小(不包括缓存的响应).这对应于每 64MB 的 namenode 进程 java 堆大小大约有 4096 个条目.假设重试缓存条目过期时间(使用 dfs.namenode.retrycache.expirytime.millis 配置)为 10 分钟,这使重试缓存能够支持每秒 7 次操作,持续 10 分钟.随着堆大小的增加,操作率线性增加.</p>
<p><font color="dd0000">dfs.namenode.rpc-address</font><br>未配置<br>处理所有客户端请求的 RPC 地址.在存在多个名称节点的 HA/Federation 的情况下,名称服务 id 将添加到名称中,例如 dfs.namenode.rpc-address.ns1 dfs.namenode.rpc-address.EXAMPLENAMESERVICE 该属性的值将采用以下形式nn-host1:rpc 端口.</p>
<p>dfs.namenode.rpc-bind-host<br>未配置<br>RPC 服务器将绑定到的实际地址.如果设置了这个可选地址,它只会覆盖 dfs.namenode.rpc-address 的主机名部分.它也可以为 HA/Federation 的每个名称节点或名称服务指定.这对于通过将名称节点设置为 0.0.0.0 来使名称节点在所有接口上侦听很有用.</p>
<p>dfs.namenode.safemode.extension<br>30000<br>在达到阈值级别后确定安全模式的扩展(以毫秒为单位).</p>
<p>dfs.namenode.safemode.min.datanodes<br>0<br>指定名称节点退出安全模式之前必须被视为活动的数据节点数.小于或等于 0 的值表示在决定是否在启动期间保持安全模式时不考虑活动数据节点的数量.大于集群中数据节点数量的值将使安全模式永久化.</p>
<p>dfs.namenode.safemode.threshold-pct<br>0.999f<br>指定应满足由 dfs.namenode.replication.min 定义的最小复制要求的块的百分比.小于或等于 0 的值意味着在退出安全模式之前不等待任何特定百分比的块.大于 1 的值将使安全模式永久化.</p>
<p>dfs.namenode.secondary.http-address<br>0.0.0.0:50090<br>二级namenode http服务器地址和端口.</p>
<p>dfs.namenode.secondary.https-address<br>0.0.0.0:50091<br>辅助名称节点 HTTPS 服务器地址和端口.</p>
<p>dfs.namenode.servicerpc-address<br>未配置<br>HDFS 服务通信的 RPC 地址.如果已配置,BackupNode/Datanodes 和所有其他服务应连接到此地址.在 HA/Federation 存在多个名称节点的情况下,名称服务 id 将添加到名称中,例如 dfs.namenode.servicerpc-address.ns1 dfs.namenode.rpc-address.EXAMPLENAMESERVICE 此属性的值将采用以下形式nn-host1:rpc 端口.如果未设置此属性的值,则 dfs.namenode.rpc-address 的值将用作默认值.</p>
<p>dfs.namenode.servicerpc-bind-host<br>未配置<br>服务 RPC 服务器将绑定到的实际地址.如果设置了这个可选地址,它只会覆盖 dfs.namenode.servicerpc-address 的主机名部分.它也可以为 HA/Federation 的每个名称节点或名称服务指定.这对于通过将名称节点设置为 0.0.0.0 来使名称节点在所有接口上侦听很有用.</p>
<p><font color="#dd0000">dfs.namenode.shared.edits.dir</font><br>未配置<br>HA 集群中多个名称节点之间共享存储上的目录.该目录将由活动写入并由备用读取,以保持命名空间同步.这个目录不需要在上面的 dfs.namenode.edits.dir 中列出.在非 HA 集群中它应该留空.</p>
<p>dfs.namenode.stale.datanode.interval<br>30000<br>将datanode标记为&quot;stale&quot;的默认时间间隔,即如果namenode超过此时间间隔没有收到来自datanode的heartbeat msg,则默认将datanode标记为&quot;stale&quot;.陈旧间隔不能太小,否则可能会导致陈旧状态的频繁变化.因此我们设置了一个最小的stale间隔值(默认值为heartbeat interval的3倍),并保证stale间隔不能小于最小值.在租约/块恢复期间避免了陈旧的数据节点.可以有条件地避免读取(参见 dfs.namenode.avoid.read.stale.datanode)和写入(参见 dfs.namenode.avoid.write.stale.datanode).</p>
<p>dfs.namenode.startup.delay.block.deletion.sec<br>0<br>Namenode 启动后我们将暂停删除块的延迟(以秒为单位).默认情况下它被禁用.如果目录有大量目录并且文件被删除,建议延迟一小时,以便管理员有足够的时间注意到大量挂起的删除块并采取纠正措施.</p>
<p>dfs.namenode.support.allow.format<br>TRUE<br>HDFS 名称节点是否允许自己被格式化?您可以考虑为任何生产集群将其设置为 false,以避免格式化正在运行的 DFS 的任何可能性.</p>
<p>dfs.namenode.write.stale.datanode.ratio<br>0.5f<br>当失效数据节点数占标记数据节点总数的比例大于该比例时,停止避免写入失效节点,以免造成热点.</p>
<p>dfs.namenode.xattrs.enabled<br>TRUE<br>NameNode 是否开启了对扩展属性的支持.</p>
<p>dfs.nameservice.id<br>未配置<br>此名称服务的 ID.如果名称服务 ID 未配置或为 dfs.nameservices 配置了多个名称服务,则通过将本地节点的地址与配置的地址匹配来自动确定.</p>
<p><font color="#dd0000">dfs.nameservices</font><br>未配置<br>逗号分隔的名称服务列表.</p>
<p><font color="#dd0000">dfs.permissions.enabled</font><br>TRUE<br>如果为&quot;true&quot;,则在 HDFS 中启用权限检查.如果为&quot;false&quot;,则关闭权限检查,但所有其他行为不变.从一个参数值切换到另一个参数值不会更改文件或目录的模式/所有者或组.</p>
<p>dfs.permissions.superusergroup<br>supergroup<br>超级用户组的名称.该值应该是单个组名.</p>
<p><font color="#dd0000">dfs.replication</font><br>3<br>默认块复制.可以在创建文件时指定实际的复制次数.如果在创建时未指定复制,则使用默认值.</p>
<p>dfs.replication.max<br>512<br>最大块复制.</p>
<p>dfs.secondary.namenode.kerberos.internal.spnego.principal<br>${dfs.web.authentication.kerberos.principal}</p>
<p>dfs.short.circuit.shared.memory.watcher.interrupt.check.ms<br>60000<br>短路共享内存观察程序在检查从其他线程发送的 java 中断之间的时间长度(以毫秒为单位).这主要用于单元测试.</p>
<p>dfs.storage.policy.enabled<br>TRUE<br>允许用户更改文件和目录的存储策略.</p>
<p>dfs.stream-buffer-size<br>4096<br>流文件的缓冲区大小.这个缓冲区的大小应该是硬件页面大小的倍数(Intel x86 上为 4096),它决定了在读写操作期间缓冲了多少数据.</p>
<p>dfs.support.append<br>TRUE<br>HDFS 是否允许附加到文件?</p>
<p>dfs.trustedchannel.resolver.class<br>未配置<br>TrustedChannelResolver 用于确定对于纯数据传输是否信任通道.TrustedChannelResolver 在客户端和服务器端都被调用.如果解析器指示该通道是可信的,那么即使 dfs.encrypt.data.transfer 设置为 true,数据传输也不会被加密.默认实现返回 false 表示通道不受信任.</p>
<p>dfs.user.home.dir.prefix<br>/user<br>附加到用户名以获取用户主目录的目录.</p>
<p><font color="#dd0000">dfs.webhdfs.enabled</font><br>TRUE<br>在 Namenodes 和 Datanodes 中启用 WebHDFS (REST API).</p>
<p>dfs.webhdfs.user.provider.user.pattern<br><code>^[A-Za-z_][A-Za-z0-9._-]*[$]?$</code><br>webhdfs 的用户名和组名的有效模式,它必须是有效的 java 正则表达式.</p>
<p>hadoop.fuse.connection.timeout<br>300<br>我们将在 fuse_dfs 中缓存 libhdfs 连接对象的最小秒数.较低的值将导致较低的内存消耗；较高的值可以通过避免创建新连接对象的开销来加快访问速度.</p>
<p>hadoop.fuse.timer.period<br>5<br>fuse_dfs 中缓存过期检查之间的秒数.较低的值将导致 fuse_dfs 更快地注意到 Kerberos 票证缓存的更改.</p>
<p>hadoop.hdfs.configuration.version<br>1<br>此配置文件的版本</p>
<p>nfs.allow.insecure.ports<br>TRUE<br>当设置为 false 时,来自非特权端口(1023 以上的端口)的客户端连接将被拒绝.这是为了确保连接到此 NFS 网关的客户端必须在它们连接的计算机上具有 root 权限.</p>
<p>nfs.dump.dir<br>/tmp/.hdfs-nfs<br>此目录用于在写入 HDFS 之前临时保存乱序写入.对于每个文件,乱序写入在内存中累积超过某个阈值(例如,1MB)后将被转储.需要确保目录有足够的空间.</p>
<p>nfs.kerberos.principal<br>未配置<br>高级属性.谨慎更改.这是 kerberos 主体的名称.在集群进行 kerberized 时,这是必需的.它必须采用以下格式:nfs-gateway-user/nfs-gateway-host@kerberos-realm</p>
<p>nfs.keytab.file<br>未配置<br>高级属性.谨慎更改.这是 hdfs-nfs 网关的 keytab 文件的路径.当集群被 Kerberized 时,这是必需的.</p>
<p>nfs.mountd.port<br>4242<br>指定 Hadoop 挂载守护程序使用的端口号.</p>
<p>nfs.rtmax<br>1048576<br>这是 NFS 网关支持的 READ 请求的最大字节数.如果您更改此设置,请确保您还更新了 nfs 挂载的 rsize(将 rsize= # of bytes 添加到 mount 指令).</p>
<p>nfs.server.port<br>2049<br>指定 Hadoop NFS 使用的端口号.</p>
<p>nfs.wtmax<br>1048576<br>这是 NFS 网关支持的 WRITE 请求的最大字节数.如果您更改此设置,请确保您还更新了 nfs 挂载的 wsize(将 wsize= # of bytes 添加到 mount 指令).</p>
<p><font color="#dd0000">dfs.journalnode.edits.dir</font><br>/tmp/hadoop/dfs/journalnode/</p>
<h2 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h2><h3 id="常用"><a href="#常用" class="headerlink" title="常用"></a>常用</h3><p><font color="#dd0000">dfs.ha.fencing.methods</font><br>未配置<br>用于服务防护的防护方法列表.可能包含内置方法(例如 shell 和 sshfence)或用户定义的方法.</p>
<p>dfs.ha.fencing.ssh.connect-timeout<br>30000<br>SSH 连接超时,以毫秒为单位,用于内置的 sshfence fencer.</p>
<!-- more -->
<p><font color="#dd0000">dfs.ha.fencing.ssh.private-key-files</font><br>未配置<br>与内置 sshfence 围栏一起使用的 SSH 私钥文件.</p>
<p><font color="#dd0000">file.blocksize</font><br>67108864<br>块大小</p>
<p>file.bytes-per-checksum<br>512<br>每个校验和的字节数.不得大于 file.stream-buffer-size</p>
<p>file.client-write-packet-size<br>65536<br>客户端写入的数据包大小</p>
<p>file.replication<br>1<br>复制因子</p>
<p>file.stream-buffer-size<br>4096<br>流文件的缓冲区大小.这个缓冲区的大小应该是硬件页面大小的倍数(Intel x86 上为 4096),它决定了在读写操作期间缓冲了多少数据.</p>
<p>fs.AbstractFileSystem.file.impl<br>org.apache.hadoop.fs.local.LocalFs<br>文件的 AbstractFileSystem:uris.</p>
<p>fs.AbstractFileSystem.har.impl<br>org.apache.hadoop.fs.HarFs<br>har 的 AbstractFileSystem:uris.</p>
<p>fs.AbstractFileSystem.hdfs.impl<br>org.apache.hadoop.fs.Hdfs<br>hdfs 的文件系统:uris.</p>
<p>fs.AbstractFileSystem.viewfs.impl<br>org.apache.hadoop.fs.viewfs.ViewFs<br>用于viewfs 的视图文件系统的AbstractFileSystem:uris(即客户端挂载表:).</p>
<p>fs.automatic.close<br>TRUE<br>默认情况下,FileSystem 实例在程序退出时使用 JVM 关闭挂钩自动关闭.将此属性设置为 false 将禁用此行为.这是一个高级选项,仅应由需要更精心安排的关闭顺序的服务器应用程序使用.</p>
<p>fs.client.resolve.remote.symlinks<br>TRUE<br>访问远程 Hadoop 文件系统时是否解析符号链接.将此设置为 false 会导致在遇到符号链接时引发异常.此设置不适用于自动解析本地符号链接的本地文件系统.</p>
<p>fs.default.name<br>file:///<br>已弃用.改用 (fs.defaultFS) 属性</p>
<p><font color="#dd0000">fs.defaultFS</font><br>file:///<br>默认文件系统的名称.一个 URI,其方案和权限决定了 FileSystem 的实现.uri 的方案确定命名 FileSystem 实现类的配置属性 (fs.SCHEME.impl).uri 的权限用于确定文件系统的主机/端口等.</p>
<p>fs.df.interval<br>60000<br>磁盘使用统计刷新间隔,以毫秒为单位.</p>
<p>fs.du.interval<br>600000<br>以毫秒为单位的文件空间使用统计刷新间隔.</p>
<p>fs.ftp.host<br>0.0.0.0<br>FTP 文件系统连接到此服务器</p>
<p>fs.ftp.host.port<br>21<br>FTP 文件系统连接到这个端口上的 fs.ftp.host</p>
<p>fs.har.impl.disable.cache<br>TRUE<br>不要缓存&quot;har&quot;文件系统实例.</p>
<p>fs.permissions.umask-mode<br>22<br>创建文件和目录时使用的 umask.可以是八进制或符号.例如:&quot;022&quot;(八进制表示 u=rwx,g=rx,o=rx 的符号),或&quot;u=rwx,g=rwx,o=&quot;(符号表示 007 的八进制).</p>
<p>fs.swift.impl<br>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem<br>OpenStack Swift Filesystem 的实现类</p>
<p>fs.trash.checkpoint.interval<br>0<br>垃圾检查点之间的分钟数.应该小于或等于 fs.trash.interval.如果为零,则将该值设置为 fs.trash.interval 的值.每次检查点运行时,它都会从当前创建一个新的检查点,并删除在 fs.trash.interval 分钟前创建的检查点.</p>
<p><font color="#dd0000">fs.trash.interval</font><br>0<br>检查点被删除的分钟数.如果为零,则禁用垃圾功能.可以在服务器和客户端上都配置此选项.如果垃圾在服务器端被禁用,则检查客户端配置.如果在服务器端启用了垃圾,则使用服务器上配置的值并忽略客户端配置值.</p>
<p><font color="#dd0000">fs.blocksize</font><br>67108864<br>块大小</p>
<p>ftp.bytes-per-checksum<br>512<br>每个校验和的字节数.不得大于 ftp.stream-buffer-size</p>
<p>ftp.client-write-packet-size<br>65536<br>客户端写入的数据包大小</p>
<p>ftp.replication<br>3<br>复制因子</p>
<p>ftp.stream-buffer-size<br>4096<br>流文件的缓冲区大小.这个缓冲区的大小应该是硬件页面大小的倍数(Intel x86 上为 4096),它决定了在读写操作期间缓冲了多少数据.</p>
<p>ha.failover-controller.cli-check.rpc-timeout.ms<br>20000<br>CLI(手动)FC 等待 monitorHealth/getServiceState 的超时</p>
<p>ha.failover-controller.graceful-fence.connection.retries<br>1<br>FC 连接重试优雅防护</p>
<p>ha.failover-controller.graceful-fence.rpc-timeout.ms<br>5000<br>FC 等待旧活动进入待机的超时</p>
<p>ha.failover-controller.new-active.rpc-timeout.ms<br>60000<br>FC 等待新活动变为活动的超时</p>
<p>ha.health-monitor.check-interval.ms<br>1000<br>多久检查一次服务.</p>
<p>ha.health-monitor.connect-retry-interval.ms<br>1000<br>重试连接到服务的频率.</p>
<p>ha.health-monitor.rpc-timeout.ms<br>45000<br>实际 monitorHealth() 调用的超时.</p>
<p>ha.health-monitor.sleep-after-disconnect.ms<br>1000<br>意外的 RPC 错误后休眠多长时间.</p>
<p>ha.zookeeper.acl<br>world:anyone:rwcda<br>ZooKeeper ACL 的逗号分隔列表,用于自动故障转移使用的 znode.这些 ACL 的指定格式与 ZooKeeper CLI 使用的格式相同.如果 ACL 本身包含机密,则可以改为指定文件路径,并以&quot;@&quot;符号为前缀,并且将从内部加载此配置的值.</p>
<p>ha.zookeeper.auth<br>未配置<br>连接到 ZooKeeper 时要添加的 ZooKeeper 身份验证的逗号分隔列表.这些以与 ZK CLI 中的&quot;addauth&quot;命令相同的格式指定.重要的是,此处指定的身份验证足以使用 ha.zookeeper.acl 中指定的 ACL 访问 znode.如果 auths 包含秘密,您可以改为指定文件的路径,前缀为&quot;@&quot;符号,并且将从内部加载此配置的值.</p>
<p>ha.zookeeper.parent-znode<br>/hadoop-ha<br>ZK 故障转移控制器存储其信息的 ZooKeeper znode.请注意,名称服务 ID 会自动附加到此 znode,因此通常不需要配置它,即使在联合环境中也是如此.</p>
<p><font color="#dd0000">ha.zookeeper.quorum</font><br>未配置<br>ZKFailoverController 在自动故障转移中使用的 ZooKeeper 服务器地址列表,以逗号分隔.</p>
<p>ha.zookeeper.session-timeout.ms<br>5000<br>ZKFC 连接到 ZooKeeper 时使用的会话超时.将此值设置为较低的值意味着将更快地检测到服务器崩溃,但在发生瞬时错误或网络故障的情况下可能会过于激进地触发故障转移.</p>
<p>hadoop.common.configuration.version<br>0.23.0<br>此配置文件的版本</p>
<p>hadoop.http.filter.initializers<br>org.apache.hadoop.http.lib.StaticUserWebFilter<br>以逗号分隔的类名列表.列表中的每个类都必须扩展 org.apache.hadoop.http.FilterInitializer.相应的过滤器将被初始化.然后,过滤器将应用于所有面向用户的 jsp 和 servlet 网页.列表的顺序定义了过滤器的顺序.</p>
<p>hadoop.http.staticuser.user<br>dr.who<br>在呈现内容时在静态 Web 过滤器上过滤的用户名.一个示例使用是 HDFS Web UI(用于浏览文件的用户).</p>
<p>hadoop.jetty.logs.serve.aliases<br>TRUE<br>启用/禁用从码头服务的别名</p>
<p>hadoop.rpc.protection<br>authentication<br>安全 sasl 连接的保护值的逗号分隔列表.可能的值是身份验证/完整性和隐私.身份验证意味着仅身份验证,没有完整性或隐私性；完整性意味着启用了身份验证和完整性；隐私意味着启用所有身份验证/完整性和隐私.hadoop.security.saslproperties.resolver.class 可用于覆盖服务器端连接的 hadoop.rpc.protection.</p>
<p>hadoop.rpc.socket.factory.class.ClientProtocol<br>未配置<br>用于连接 DFS 的 SocketFactory.如果为 null 或为空,请使用 hadoop.rpc.socket.class.default.DFSClient 也使用这个套接字工厂来创建到 DataNode 的套接字.</p>
<p>hadoop.rpc.socket.factory.class.default<br>org.apache.hadoop.net.StandardSocketFactory<br>要使用的默认 SocketFactory.该参数的格式应为&quot;package.FactoryClassName&quot;.</p>
<p>hadoop.socks.server<br>未配置<br>SocksSocketFactory 使用的 SOCKS 服务器的地址(主机:端口).</p>
<p><font color="#dd0000">hadoop.tmp.dir</font><br>/tmp/hadoop-<code>$&#123;user.name&#125;</code><br>其他临时目录的基础.</p>
<p>hadoop.user.group.static.mapping.overrides<br>dr.who=;<br>用户到组的静态映射.如果指定用户在系统中可用,这将覆盖组.换句话说,这些用户不会进行组查找,而是使用在此配置中映射的组.映射应采用这种格式.用户 1=组 1,组 2；用户 2=；用户 3=组 2；默认,&quot;dr.who=;&quot; 将&quot;dr.who&quot;视为没有组的用户.</p>
<p>hadoop.util.hash.type<br>murmur<br>哈希的默认实现.目前这可以采用以下两个值之一:&#39;murmur&#39; 选择 MurmurHash 和 &#39;jenkins&#39; 选择 JenkinsHash.</p>
<p>hadoop.work.around.non.threadsafe.getpwuid<br>FALSE<br>已知某些操作系统或身份验证模块破坏了 getpwuid_r 和 getpwgid_r 的实现,因此这些调用不是线程安全的.此问题的症状包括 JVM 崩溃并在这些函数中出现堆栈跟踪.如果您的系统出现此问题,请启用此配置参数以将调用锁定作为解决方法.</p>
<p>io.bytes.per.checksum<br>512<br>每个校验和的字节数.不得大于 io.file.buffer.size.</p>
<p>io.compression.codec.bzip2.library<br>system-native<br>bzip2 编解码器用于压缩和解压缩的本机代码库.该库可以通过名称或完整路径名指定.在前一种情况下,库由动态链接器定位,通常搜索环境变量 LD_LIBRARY_PATH 中指定的目录.&quot;system-native&quot;的值表示应该使用默认的系统库.要指示该算法应完全在 Java 中运行,请指定&quot;java-builtin&quot;.</p>
<p><font color="#dd0000">io.compression.codecs</font><br>未配置<br>可用于压缩/解压缩的压缩编解码器类的逗号分隔列表.除了使用此属性指定的任何类(优先)之外,类路径上的编解码器类是使用 Java ServiceLoader 发现的.</p>
<p><font color="#dd0000">io.file.buffer.size</font><br>4096<br>用于序列文件的缓冲区大小.这个缓冲区的大小应该是硬件页面大小的倍数(Intel x86 上为 4096),它决定了在读写操作期间缓冲了多少数据.</p>
<p>io.map.index.interval<br>128<br>MapFile 由两个文件组成——数据文件(元组)和索引文件(键).对于数据文件中写入的每个 io.map.index.interval 记录,都会在索引文件中写入一个条目(record-key,data-file-position).这是为了允许稍后在索引文件中进行二进制搜索,以通过键查找记录并获取它们在数据文件中的最近位置.</p>
<p>io.map.index.skip<br>0<br>每个条目之间要跳过的索引条目数.默认为零.将此值设置为大于零的值有助于使用更少的内存打开大型 MapFile.</p>
<p>io.mapfile.bloom.error.rate<br>0.005<br>BloomMapFile 中使用的 BloomFilter-s 中的误报率.随着该值的减小,BloomFilter-s 的大小呈指数增长.该值是遇到误报的概率(默认为 0.5%).</p>
<p>io.mapfile.bloom.size<br>1048576<br>BloomMapFile 中使用的 BloomFilter-s 的大小.每次添加这么多键时,都会创建下一个 BloomFilter(在 DynamicBloomFilter 内).较大的值会最小化过滤器的数量,这会略微提高性能,但如果键的总数通常远小于此数量,则可能会浪费太多空间.</p>
<p>io.native.lib.available<br>TRUE<br>是否应该使用本机 hadoop 库(如果存在).</p>
<p>io.seqfile.compress.blocksize<br>1000000<br>块压缩序列文件中压缩的最小块大小.</p>
<p>io.seqfile.lazydecompress<br>TRUE<br>仅在必要时才应解压缩块压缩序列文件的值.</p>
<p>io.seqfile.local.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/io/local<br>序列文件在合并过程中存储中间数据文件的本地目录.可能是不同设备上以逗号分隔的目录列表,以便分散磁盘 i/o.不存在的目录将被忽略.</p>
<p>io.seqfile.sorter.recordlimit<br>1000000<br>在 SequenceFiles.Sorter 中溢出时保留在内存中的记录数限制</p>
<p>io.serializations<br>org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization<br>可用于获取序列化器和反序列化器的序列化类列表.</p>
<p>io.skip.checksum.errors<br>FALSE<br>如果为 true,则在读取序列文件时遇到校验和错误时,将跳过条目,而不是抛出异常.</p>
<p>ipc.client.connect.max.retries<br>10<br>指示客户端为建立服务器连接而重试的次数.</p>
<p>ipc.client.connect.max.retries.on.timeouts<br>45<br>指示客户端将在套接字超时时重试以建立服务器连接的次数.</p>
<p>ipc.client.connect.retry.interval<br>1000<br>指示客户端在重试建立服务器连接之前将等待的毫秒数.</p>
<p>ipc.client.connect.timeout<br>20000<br>表示客户端等待套接字建立服务器连接的毫秒数.</p>
<p>ipc.client.connection.maxidletime<br>10000<br>客户端断开与服务器的连接的最长时间(以毫秒为单位).</p>
<p>ipc.client.fallback-to-simple-auth-allowed<br>FALSE<br>当客户端配置为尝试安全连接,但尝试连接到不安全的服务器时,该服务器可能会指示客户端切换到 SASL SIMPLE(不安全)身份验证.此设置控制客户端是否会接受来自服务器的此指令.当为 false(默认值)时,客户端将不允许回退到 SIMPLE 身份验证,并将中止连接.</p>
<p>ipc.client.idlethreshold<br>4000<br>定义连接的阈值数量,之后将检查连接是否空闲.</p>
<p>ipc.client.kill.max<br>10<br>定义一次断开连接的最大客户端数.</p>
<p>ipc.client.ping<br>TRUE<br>如果设置为 true,则在读取响应超时时向服务器发送 ping.如果没有检测到失败,客户端会重试,直到至少读取一个字节.</p>
<p>ipc.client.rpc-timeout.ms<br>0<br>等待服务器响应超时,以毫秒为单位.目前,此超时仅在 ipc.client.ping 设置为 true 时有效,因为它使用与 IPC ping 相同的工具.超时会覆盖 ipc.ping.interval 并且客户端将在超过间隔时抛出异常而不是发送 ping.</p>
<p>ipc.ping.interval<br>60000<br>等待服务器响应超时,以毫秒为单位.如果 ipc.client.ping 设置为 true,则客户端将在超过间隔时发送 ping 而不接收字节.</p>
<p>ipc.server.listen.queue.size<br>128<br>指示接受客户端连接的服务器的侦听队列长度.</p>
<p>net.topology.impl<br>org.apache.hadoop.net.NetworkTopology<br>NetworkTopology 的默认实现是经典的三层第一.</p>
<p>net.topology.node.switch.mapping.impl<br>org.apache.hadoop.net.ScriptBasedMapping<br>DNSToSwitchMapping 的默认实现.它调用 net.topology.script.file.name 中指定的脚本来解析节点名称.如果未设置 net.topology.script.file.name 的值,则为所有节点名称返回默认值 DEFAULT_RACK.</p>
<p>net.topology.script.file.name<br>未配置<br>应调用以将 DNS 名称解析为 NetworkTopology 名称的脚本名称.示例:脚本将 host.foo.bar 作为参数,并返回 /rack1 作为输出.</p>
<p>net.topology.script.number.args<br>100<br>使用 net.topology.script.file.name 配置的脚本应该运行的最大参数数.每个 arg 是一个 IP 地址.</p>
<p>net.topology.table.file.name<br>未配置<br>拓扑文件的文件名,当 net.topology.node.switch.mapping.impl 属性设置为 org.apache.hadoop.net.TableMapping 时使用.文件格式是一个两列文本文件,列用空格分隔.第一列是 DNS 或 IP 地址,第二列指定地址映射的机架.如果没有找到与集群中的主机对应的条目,则假定为 /default-rack.</p>
<p>nfs.exports.allowed.hosts<br><code>* rw</code><br>默认情况下,任何客户端都可以挂载导出.值字符串包含机器名称和访问权限,以空格字符分隔.机器名格式可以是单个主机/Java 正则表达式或 IPv4 地址.访问权限使用 rw 或 ro 指定机器对导出的读/写或只读访问.如果未提供访问权限,则默认为只读.条目用&quot;;&quot;分隔.例如:&quot;192.168.0.0/22 rw;host.<code>*\.example\.</code>com;host1.test.org ro;&quot;.更新此属性后,仅 NFS 网关需要重新启动.</p>
<p>rpc.metrics.percentiles.intervals<br>未配置<br>描述 RPC 队列/处理时间的第 50/75/90/95/99 个百分位延迟的指标的以秒为单位的粒度的逗号分隔列表.如果 rpc.metrics.quantile.enable 设置为 true,则输出指标.</p>
<p>rpc.metrics.quantile.enable<br>FALSE<br>将此属性设置为 true 并将 rpc.metrics.percentiles.intervals 设置为以逗号分隔的粒度列表(以秒为单位),将 rpc 队列/处理时间(以毫秒为单位)的 50/75/90/95/99 百分位延迟添加到 rpc 指标.</p>
<h3 id="authentication"><a href="#authentication" class="headerlink" title="authentication"></a>authentication</h3><p>hadoop.http.authentication.cookie.domain<br>未配置<br>用于存储身份验证令牌的 HTTP cookie 的域.为了在所有 Hadoop 节点 Web 控制台上正确进行身份验证,必须正确设置域.重要提示:使用 IP 地址时,浏览器会忽略带有域设置的 cookie.要使此设置正常工作,必须将集群中的所有节点配置为生成带有 hostname.domain 名称的 URL.</p>
<p>hadoop.http.authentication.kerberos.keytab<br>${user.home}/hadoop.keytab<br>带有主体凭据的 keytab 文件的位置.参考 Oozie 用于其 Hadoop 的 Kerberos 凭证的相同密钥表文件.</p>
<p>hadoop.http.authentication.kerberos.principal<br><code>HTTP/_HOST@LOCALHOST</code><br>指示要用于 HTTP 端点的 Kerberos 主体.根据 Kerberos HTTP SPNEGO 规范,主体必须以&quot;HTTP/&quot;开头.</p>
<p>hadoop.http.authentication.signature.secret.file<br>${user.home}/hadoop-http-auth-signature-secret<br>用于签署身份验证令牌的签名密钥.JT/NN/DN/TT 配置应使用相同的密钥.</p>
<p>hadoop.http.authentication.simple.anonymous.allowed<br>TRUE<br>指示在使用&quot;简单&quot;身份验证时是否允许匿名请求.</p>
<p>hadoop.http.authentication.token.validity<br>36000<br>指示身份验证令牌在必须更新之前的有效时间(以秒为单位).</p>
<p>hadoop.http.authentication.type<br>simple<br>定义用于 Oozie HTTP 端点的身份验证.支持的值是:simple |kerberos|#AUTHENTICATION_HANDLER_CLASSNAME#</p>
<p>hadoop.kerberos.kinit.command<br>kinit<br>用于在提供给 Hadoop 时定期更新 Kerberos 凭据.默认设置假定 kinit 位于运行 Hadoop 客户端的用户的 PATH 中.如果不是这种情况,请将其更改为 kinit 的绝对路径.</p>
<h3 id="security"><a href="#security" class="headerlink" title="security"></a>security</h3><p>hadoop.security.auth_to_local<br>未配置<br>将 kerberos 主体映射到本地用户名</p>
<p>hadoop.security.authentication<br>simple<br>可能的值很简单(无身份验证)和 kerberos</p>
<p>hadoop.security.authorization<br>FALSE<br>是否启用了服务级别授权?</p>
<p>hadoop.security.crypto.buffer.size<br>8192<br>CryptoInputStream 和 CryptoOutputStream 使用的缓冲区大小.</p>
<p>hadoop.security.crypto.cipher.suite<br>AES/CTR/NoPadding<br>加密编解码器的密码套件.</p>
<p>hadoop.security.crypto.codec.classes.aes.ctr.nopadding<br>org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec<br>AES/CTR/NoPadding 的加密编解码器实现的逗号分隔列表.如果可用,将使用第一个实现,其他实现是后备.</p>
<p>hadoop.security.crypto.codec.classes.EXAMPLECIPHERSUITE<br>未配置<br>给定密码编解码器的前缀包含给定密码编解码器的实现类的逗号分隔列表(例如,EXAMPLECIPHERSUITE).如果可用,将使用第一个实现,其他实现是后备.</p>
<p>hadoop.security.crypto.jce.provider<br>未配置<br>CryptoCodec 中使用的 JCE 提供者名称.</p>
<p>hadoop.security.group.mapping<br>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback<br>ACL 的用户到组映射(获取给定用户的组)的类.默认实现 org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 将确定 Java 本地接口 (JNI) 是否可用.如果 JNI 可用,则实现将使用 hadoop 中的 API 为用户解析组列表.如果 JNI 不可用,则使用 shell 实现 ShellBasedUnixGroupsMapping.此实现使用 bash -c groups 命令解析到 Linux/Unix 环境,以解析用户的组列表.</p>
<p>hadoop.security.group.mapping.ldap.base<br>未配置<br>LDAP 连接的搜索库.这是一个专有名称,通常是 LDAP 目录的根目录.</p>
<p>hadoop.security.group.mapping.ldap.bind.password.file<br>未配置<br>包含绑定用户密码的文件的路径.重要提示:该文件应该只能由运行守护程序的 Unix 用户读取.</p>
<p>hadoop.security.group.mapping.ldap.bind.user<br>未配置<br>连接到 LDAP 服务器时要绑定的用户的专有名称.如果 LDAP 服务器支持匿名绑定,这可能会留空.</p>
<p>hadoop.security.group.mapping.ldap.directory.search.timeout<br>10000<br>该属性应用于 LDAP SearchControl 属性以在搜索和等待结果时设置最大时间限制.如果需要无限等待时间,则设置为 0.默认值为 10 秒.以毫秒为单位.</p>
<p>hadoop.security.group.mapping.ldap.search.attr.group.name<br>cn<br>标识组名的组对象的属性.默认值通常适用于所有 LDAP 系统.</p>
<p>hadoop.security.group.mapping.ldap.search.attr.member<br>member<br>组对象的属性,用于标识作为组成员的用户.默认值通常适用于任何 LDAP 安装.</p>
<p>hadoop.security.group.mapping.ldap.search.filter.group<br>(objectClass=group)<br>搜索 LDAP 组时使用的附加过滤器.在针对非 Active Directory 安装解析组时,应更改此设置.posixGroups 当前不是受支持的组类.</p>
<p>hadoop.security.group.mapping.ldap.search.filter.user<br>(&amp;(objectClass=user)(sAMAccountName={0}))<br>搜索 LDAP 用户时使用的附加过滤器.默认值通常适用于 Active Directory 安装.如果连接到具有非 AD 架构的 LDAP 服务器,则应将其替换为 (&amp;(objectClass=inetOrgPerson)(uid={0}).{0} 是一个特殊字符串,用于表示用户名适合过滤器的位置.</p>
<p>hadoop.security.group.mapping.ldap.ssl<br>FALSE<br>连接到 LDAP 服务器时是否使用 SSL.</p>
<p>hadoop.security.group.mapping.ldap.ssl.keystore<br>未配置<br>包含 LDAP 服务器所需的 SSL 证书的 SSL 密钥库的文件路径.</p>
<p>hadoop.security.group.mapping.ldap.ssl.keystore.password.file<br>未配置<br>包含 LDAP SSL 密钥库密码的文件的路径.重要提示:该文件应该只能由运行守护程序的 Unix 用户读取.</p>
<p>hadoop.security.group.mapping.ldap.url<br>未配置<br>使用 LdapGroupsMapping 用户到组映射时用于解析用户组的 LDAP 服务器的 URL.</p>
<p>hadoop.security.groups.cache.secs<br>300<br>这是控制缓存中包含用户-&gt;组映射的条目有效性的配置.当此持续时间到期时,将调用组映射提供程序的实现以获取用户的组,然后将其缓存回来.</p>
<p>hadoop.security.groups.cache.warn.after.ms<br>5000<br>如果查找单个用户到组的时间超过此毫秒数,我们将记录一条警告消息.</p>
<p>hadoop.security.groups.negative-cache.secs<br>30<br>负用户到组映射缓存中条目的过期时间,以秒为单位.这在无效用户频繁重试时很有用.建议将此过期设置一个较小的值,因为组查找中的瞬时错误可能会暂时锁定合法用户.将此设置为零或负值以禁用负用户到组缓存.</p>
<p>hadoop.security.impersonation.provider.class<br>未配置<br>一个实现 ImpersonationProvider 接口的类,用于授权一个用户是否可以模拟一个特定的用户.如果未指定,将使用 DefaultImpersonationProvider.如果指定了一个类,则该类将用于确定模拟能力.</p>
<p>hadoop.security.instrumentation.requires.admin<br>FALSE<br>指示是否需要管理员 ACL 才能访问检测 servlet(JMX/METRICS/CONF/堆栈).</p>
<p>hadoop.security.java.secure.random.algorithm<br>SHA1PRNG<br>java安全随机算法.</p>
<p>hadoop.security.kms.client.authentication.retry-count<br>1<br>身份验证失败时重试连接到 KMS 的次数</p>
<p>hadoop.security.kms.client.encrypted.key.cache.expiry<br>43200000<br>一个Key的缓存过期时间,超过这个时间这个key的缓存Queue就会被丢弃.默认 = 12 小时</p>
<p>hadoop.security.kms.client.encrypted.key.cache.low-watermark<br>0.3f<br>如果 EncryptedKeyVersion 缓存队列的大小低于低水位线,则该缓存队列将被安排重新填充</p>
<p>hadoop.security.kms.client.encrypted.key.cache.num.refill.threads<br>2<br>用于重新填充耗尽的 EncryptedKeyVersion 缓存队列的线程数</p>
<p>hadoop.security.kms.client.encrypted.key.cache.size<br>500<br>每个密钥的 EncryptedKeyVersion 缓存队列的大小</p>
<p>hadoop.security.random.device.file.path<br>/dev/urandom<br>操作系统安全随机设备文件路径.</p>
<p>hadoop.security.saslproperties.resolver.class<br>未配置<br>SaslPropertiesResolver 用于解析用于连接的 QOP.如果未指定,则在确定用于连接的 QOP 时使用 hadoop.rpc.protection 中指定的完整值集.如果指定了一个类,则在确定用于连接的 QOP 时,将使用该类返回的 QOP 值.</p>
<p>hadoop.security.secure.random.impl<br>未配置<br>实施安全随机.</p>
<p>hadoop.security.sensitive-config-keys<br><code>password$,fs.s3.*[Ss]ecret.?[Kk]ey,fs.azure.account.key.*,dfs.webhdfs.oauth2.[a-z]+.token,hadoop.security.sensitive-config-keys</code><br>一个以逗号分隔的正则表达式列表,用于与配置键匹配,在适当的情况下应进行编辑,例如,在重新配置期间记录修改的属性时,不应记录私有凭据.</p>
<p>hadoop.security.service.user.name.key<br>未配置<br>对于由多个服务器实现相同的 RPC 协议的情况,当客户端希望进行 RPC 调用时,需要此配置来指定用于服务的主体名称.</p>
<p>hadoop.security.uid.cache.secs<br>14400<br>这是控制缓存中条目有效性的配置,其中包含 NativeIO getFstat() 使用的 userId 到 userName 和 groupId 到 groupName.</p>
<h3 id="ssl"><a href="#ssl" class="headerlink" title="ssl"></a>ssl</h3><p>hadoop.ssl.client.conf<br>ssl-client.xml<br>将从中提取 ssl 客户端密钥库信息的资源文件 此文件在类路径中查找,通常应位于 Hadoop conf/ 目录中.</p>
<p>hadoop.ssl.enabled<br>FALSE<br>已弃用.请改用 dfs.http.policy 和 yarn.http.policy.</p>
<p>hadoop.ssl.enabled.protocols<br>TLSv1<br>ssl 支持的协议.</p>
<p>hadoop.ssl.hostname.verifier<br>DEFAULT<br>为 HttpsURLConnections 提供的主机名验证器.有效值为:DEFAULT/STRICT/STRICT_I6/DEFAULT_AND_LOCALHOST 和 ALLOW_ALL</p>
<p>hadoop.ssl.keystores.factory.class<br>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory<br>用于检索证书的密钥库工厂.</p>
<p>hadoop.ssl.require.client.cert<br>FALSE<br>是否需要客户端证书</p>
<p>hadoop.ssl.server.conf<br>ssl-server.xml<br>将从中提取 ssl 服务器密钥库信息的资源文件.该文件在类路径中查找,通常它应该在 Hadoop conf/ 目录中.</p>
<h3 id="s3相关"><a href="#s3相关" class="headerlink" title="s3相关"></a>s3相关</h3><p>fs.s3.block.size<br>67108864<br>将文件写入 S3 时使用的块大小.</p>
<p>fs.s3.buffer.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/s3<br>确定 S3 文件系统在将文件发送到 S3 之前(或从 S3 检索它们之后)应在本地文件系统上存储文件的位置.</p>
<p>fs.s3.maxRetries<br>4<br>在我们向应用程序发出失败信号之前,向 S3 读取或写入文件的最大重试次数.</p>
<p>fs.s3.sleepTimeSeconds<br>10<br>每次 S3 重试之间的休眠秒数.</p>
<p>fs.s3a.access.key<br>未配置<br>AWS 访问密钥 ID.省略基于角色的身份验证.</p>
<p>fs.s3a.acl.default<br>未配置<br>为新创建和复制的对象设置标准 ACL.值可以是私有/公共读取/公共读取写入/身份验证读取/日志传递写入/存储桶所有者读取或存储桶所有者完全控制.</p>
<p>fs.s3a.attempts.maximum<br>10<br>我们应该在瞬态错误上重试命令多少次.</p>
<p>fs.s3a.buffer.dir<br><code>$&#123;hadoop.tmp.dir&#125;</code>/s3a<br>将用于缓冲文件上传到的目录的逗号分隔列表.</p>
<p>fs.s3a.connection.maximum<br>15<br>控制同时连接到 S3 的最大数量.</p>
<p>fs.s3a.connection.ssl.enabled<br>TRUE<br>启用或禁用到 S3 的 SSL 连接.</p>
<p>fs.s3a.connection.timeout<br>5000<br>套接字连接超时(以秒为单位).</p>
<p>fs.s3a.impl<br>org.apache.hadoop.fs.s3a.S3AFileSystem<br>S3A文件系统的实现类</p>
<p>fs.s3a.multipart.purge<br>FALSE<br>如果您要清除可能未正确完成/中止的现有分段上传,则为 True</p>
<p>fs.s3a.multipart.purge.age<br>86400<br>要清除的分段上传的最小时间(以秒为单位)</p>
<p>fs.s3a.multipart.size<br>104857600<br>将上传或复制操作拆分成多大(以字节为单位).</p>
<p>fs.s3a.multipart.threshold<br>2147483647<br>上传或复制之前的阈值使用并行多部分操作.</p>
<p>fs.s3a.paging.maximum<br>5000<br>一次执行目录列表时从 S3 请求多少个键.</p>
<p>fs.s3a.secret.key<br>未配置<br>AWS 密钥.省略基于角色的身份验证.</p>
<p>fs.s3n.block.size<br>67108864<br>使用本机 S3 文件系统 (s3n: URIs) 读取文件时使用的块大小.</p>
<p>fs.s3n.multipart.copy.block.size<br>5368709120<br>本机 S3 文件系统中多部分复制的块大小.默认大小为 5GB.</p>
<p>fs.s3n.multipart.uploads.block.size<br>67108864<br>分段上传到本机 S3 文件系统的块大小.默认大小为 64MB.</p>
<p>fs.s3n.multipart.uploads.enabled<br>FALSE<br>将此属性设置为 true 可以多次上传到本机 S3 文件系统.上传文件时,如果大小大于 fs.s3n.multipart.uploads.block.size,则将其拆分为块.</p>
<p>fs.s3n.server-side-encryption-algorithm<br>未配置<br>为 S3 指定服务器端加密算法.默认值为 NULL,当前唯一允许的值为 AES256.</p>
<p>s3.blocksize<br>67108864<br>块大小</p>
<p>s3.bytes-per-checksum<br>512<br>每个校验和的字节数.不得大于 s3.stream-buffer-size</p>
<p>s3.client-write-packet-size<br>65536<br>客户端写入的数据包大小</p>
<p>s3.replication<br>3<br>复制因子</p>
<p>s3.stream-buffer-size<br>4096<br>流文件的缓冲区大小.这个缓冲区的大小应该是硬件页面大小的倍数(Intel x86 上为 4096),它决定了在读写操作期间缓冲了多少数据.</p>
<p>s3native.blocksize<br>67108864<br>块大小</p>
<p>s3native.bytes-per-checksum<br>512<br>每个校验和的字节数.不得大于 s3native.stream-buffer-size</p>
<p>s3native.client-write-packet-size<br>65536<br>客户端写入的数据包大小</p>
<p>s3native.replication<br>3<br>复制因子</p>
<p>s3native.stream-buffer-size<br>4096<br>流文件的缓冲区大小.这个缓冲区的大小应该是硬件页面大小的倍数(Intel x86 上为 4096),它决定了在读写操作期间缓冲了多少数据.</p>
<h3 id="tfile"><a href="#tfile" class="headerlink" title="tfile"></a>tfile</h3><p>tfile.fs.input.buffer.size<br>262144<br>用于 FSDataInputStream 的缓冲区大小(以字节为单位).</p>
<p>tfile.fs.output.buffer.size<br>262144<br>用于 FSDataOutputStream 的缓冲区大小(以字节为单位).</p>
<p>tfile.io.chunk.size<br>1048576<br>值块大小(以字节为单位).默认为 1MB.长度小于块大小的值保证在读取时具有已知的值长度(另见 TFile.Reader.Scanner.Entry.isValueLengthKnown()).</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/07/29/spark%20on%20hive/" rel="prev" title="spark on hive">
                  <i class="fa fa-chevron-left"></i> spark on hive
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/01/namenode%E7%9A%84%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6%E5%92%8C%E7%BC%96%E8%BE%91%E6%97%A5%E5%BF%97/" rel="next" title="namenode的镜像文件和编辑日志">
                  namenode的镜像文件和编辑日志 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
