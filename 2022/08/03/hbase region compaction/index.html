<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="当 MemStore 达到给定大小 ( hbase.hregion.memstore.flush.size) 时,它会将其内容刷新到 StoreFile.StoreFiles 的数量随着时间的推移而增加.压缩是一种操作,它通过将存储文件合并在一起来减少存储中的存储文件数量,以提高读取操作的性能.执行压缩可能会占用大量资源,并且会根据许多因素帮助或阻碍性能.">
<meta property="og:type" content="article">
<meta property="og:title" content="hbase region compaction">
<meta property="og:url" content="https://maoeryu.github.io/2022/08/03/hbase%20region%20compaction/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="当 MemStore 达到给定大小 ( hbase.hregion.memstore.flush.size) 时,它会将其内容刷新到 StoreFile.StoreFiles 的数量随着时间的推移而增加.压缩是一种操作,它通过将存储文件合并在一起来减少存储中的存储文件数量,以提高读取操作的性能.执行压缩可能会占用大量资源,并且会根据许多因素帮助或阻碍性能.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc3.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc1.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc4.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc5.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc6.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc7.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc8.png">
<meta property="og:image" content="https://maoeryu.github.io/images/hbc9.png">
<meta property="article:published_time" content="2022-08-02T16:00:00.000Z">
<meta property="article:modified_time" content="2023-02-17T11:51:55.106Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="hbase">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://maoeryu.github.io/images/hbc3.png">


<link rel="canonical" href="https://maoeryu.github.io/2022/08/03/hbase%20region%20compaction/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>hbase region compaction | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.1.</span> <span class="nav-text">类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#minor"><span class="nav-number">1.1.1.</span> <span class="nav-text">minor</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#major"><span class="nav-number">1.1.2.</span> <span class="nav-text">major</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%88%A0%E9%99%A4"><span class="nav-number">1.2.</span> <span class="nav-text">压缩和删除</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E5%92%8C%E7%89%88%E6%9C%AC"><span class="nav-number">1.3.</span> <span class="nav-text">压缩和版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%8E%8B%E7%BC%A9%E4%BC%9A%E5%BD%B1%E5%93%8D%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C"><span class="nav-number">1.4.</span> <span class="nav-text">主要压缩会影响查询结果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E7%AD%96%E7%95%A5"><span class="nav-number">2.</span> <span class="nav-text">压缩策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ExploringCompactionPolicy-%E7%AE%97%E6%B3%95"><span class="nav-number">2.1.</span> <span class="nav-text">ExploringCompactionPolicy 算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RatioBasedCompactionPolicy%E7%AE%97%E6%B3%95"><span class="nav-number">2.2.</span> <span class="nav-text">RatioBasedCompactionPolicy算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E5%8F%82%E6%95%B0"><span class="nav-number">3.</span> <span class="nav-text">压缩算法参数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hstore-compaction-min"><span class="nav-number">3.1.</span> <span class="nav-text">hbase.hstore.compaction.min</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hstore-compaction-max"><span class="nav-number">3.2.</span> <span class="nav-text">hbase.hstore.compaction.max</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hstore-compaction-min-size"><span class="nav-number">3.3.</span> <span class="nav-text">hbase.hstore.compaction.min.size</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hstore-compaction-max-size"><span class="nav-number">3.4.</span> <span class="nav-text">hbase.hstore.compaction.max.size</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hstore-compaction-ratio"><span class="nav-number">3.5.</span> <span class="nav-text">hbase.hstore.compaction.ratio</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hstore-compaction-ratio-offpeak"><span class="nav-number">3.6.</span> <span class="nav-text">hbase.hstore.compaction.ratio.offpeak</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-offpeak-start-hour"><span class="nav-number">3.7.</span> <span class="nav-text">hbase.offpeak.start.hour</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-offpeak-end-hour"><span class="nav-number">3.8.</span> <span class="nav-text">hbase.offpeak.end.hour</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-regionserver-thread-compaction-throttle"><span class="nav-number">3.9.</span> <span class="nav-text">hbase.regionserver.thread.compaction.throttle</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hregion-majorcompaction"><span class="nav-number">3.10.</span> <span class="nav-text">hbase.hregion.majorcompaction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hbase-hregion-majorcompaction-jitter"><span class="nav-number">3.11.</span> <span class="nav-text">hbase.hregion.majorcompaction.jitter</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E6%B5%81%E7%A8%8B"><span class="nav-number">4.</span> <span class="nav-text">压缩流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A6%E5%8F%91%E6%97%B6%E6%9C%BA"><span class="nav-number">4.1.</span> <span class="nav-text">触发时机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Memstore-Flush"><span class="nav-number">4.1.1.</span> <span class="nav-text">Memstore Flush</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B%E5%91%A8%E6%9C%9F%E6%80%A7%E6%A3%80%E6%9F%A5"><span class="nav-number">4.1.2.</span> <span class="nav-text">后台线程周期性检查</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="nav-number">4.1.3.</span> <span class="nav-text">手动触发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Compaction%E8%AF%B1%E5%8F%91%E5%9B%A0%E5%AD%90"><span class="nav-number">4.2.</span> <span class="nav-text">Compaction诱发因子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82HFile%E5%90%88%E5%B9%B6"><span class="nav-number">4.3.</span> <span class="nav-text">选择合适HFile合并</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E9%80%89%E5%90%88%E9%80%82%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0"><span class="nav-number">4.4.</span> <span class="nav-text">挑选合适的线程池</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8CHFile%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="nav-number">4.5.</span> <span class="nav-text">执行HFile文件合并</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Compaction-%E5%AF%B9%E8%AF%BB%E5%86%99%E8%AF%B7%E6%B1%82%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">4.6.</span> <span class="nav-text">Compaction 对读写请求的影响</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E4%B8%8A%E7%9A%84%E5%86%99%E5%85%A5%E6%94%BE%E5%A4%A7"><span class="nav-number">4.6.1.</span> <span class="nav-text">存储上的写入放大</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%BB%E8%B7%AF%E5%BE%84%E4%B8%8A%E7%9A%84%E5%BB%B6%E6%97%B6%E6%AF%9B%E5%88%BA"><span class="nav-number">4.6.2.</span> <span class="nav-text">读路径上的延时毛刺</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%99%E8%AF%B7%E6%B1%82%E4%B8%8A%E7%9A%84%E7%9F%AD%E6%9A%82%E9%98%BB%E5%A1%9E"><span class="nav-number">4.6.3.</span> <span class="nav-text">写请求上的短暂阻塞</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.7.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-number">5.</span> <span class="nav-text">基本原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E4%BD%9C%E7%94%A8"><span class="nav-number">6.</span> <span class="nav-text">核心作用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E4%BD%9C%E7%94%A8"><span class="nav-number">6.1.</span> <span class="nav-text">副作用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="nav-number">7.</span> <span class="nav-text">基本流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A6%E5%8F%91%E6%97%B6%E6%9C%BA-1"><span class="nav-number">7.1.</span> <span class="nav-text">触发时机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MemStore-Flush"><span class="nav-number">7.1.1.</span> <span class="nav-text">MemStore Flush</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A"><span class="nav-number">7.1.1.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B%E5%91%A8%E6%9C%9F%E6%80%A7%E6%A3%80%E6%9F%A5-1"><span class="nav-number">7.1.2.</span> <span class="nav-text">后台线程周期性检查</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A-1"><span class="nav-number">7.1.2.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A6%E5%8F%91-1"><span class="nav-number">7.1.3.</span> <span class="nav-text">手动触发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%85%E5%90%88%E5%B9%B6HFile%E9%9B%86%E5%90%88%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5"><span class="nav-number">7.2.</span> <span class="nav-text">待合并HFile集合选择策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RatioBasedCompactionPolicy"><span class="nav-number">7.2.1.</span> <span class="nav-text">RatioBasedCompactionPolicy</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A-2"><span class="nav-number">7.2.1.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ExploringCompactionPolicy"><span class="nav-number">7.2.2.</span> <span class="nav-text">ExploringCompactionPolicy</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E5%BE%85%E5%90%88%E5%B9%B6%E6%96%87%E4%BB%B6%E7%9A%84%E6%8C%91%E9%80%89%E6%9D%A1%E4%BB%B6"><span class="nav-number">7.2.2.1.</span> <span class="nav-text">修改待合并文件的挑选条件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A5%E7%BB%84%E5%90%88%E4%BD%9C%E4%B8%BA%E8%AE%A1%E7%AE%97%E5%8D%95%E5%85%83"><span class="nav-number">7.2.2.2.</span> <span class="nav-text">以组合作为计算单元</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E9%80%89%E5%90%88%E9%80%82%E7%9A%84%E6%89%A7%E8%A1%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0"><span class="nav-number">7.3.</span> <span class="nav-text">挑选合适的执行线程池</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A-3"><span class="nav-number">7.3.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HFile%E6%96%87%E4%BB%B6Compaction%E6%89%A7%E8%A1%8C"><span class="nav-number">7.4.</span> <span class="nav-text">HFile文件Compaction执行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96"><span class="nav-number">8.</span> <span class="nav-text">其他</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AA%E6%9C%89Major-Compaction%E5%8F%AF%E4%BB%A5%E7%9C%9F%E6%AD%A3%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE"><span class="nav-number">8.1.</span> <span class="nav-text">为什么只有Major Compaction可以真正删除数据?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BE%BE%E5%88%B0TTL%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E4%BB%A5%E8%A2%ABMinor-Compaction%E5%88%A0%E9%99%A4"><span class="nav-number">8.2.</span> <span class="nav-text">为什么达到TTL的数据可以被Minor Compaction删除?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B"><span class="nav-number">9.</span> <span class="nav-text">示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%A4%BA%E4%BE%8B"><span class="nav-number">9.1.</span> <span class="nav-text">基本示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B2%A1%E6%9C%89%E8%B6%B3%E5%A4%9F%E7%9A%84%E6%96%87%E4%BB%B6%E6%9D%A5%E5%8E%8B%E7%BC%A9"><span class="nav-number">9.2.</span> <span class="nav-text">没有足够的文件来压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%90%E5%88%B6%E8%A6%81%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%96%87%E4%BB%B6"><span class="nav-number">9.3.</span> <span class="nav-text">限制要压缩的文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%A1%E7%BA%B9%E5%8E%8B%E5%AE%9E"><span class="nav-number">10.</span> <span class="nav-text">条纹压实</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8%E6%9D%A1%E7%BA%B9%E5%8E%8B%E7%BC%A9"><span class="nav-number">10.1.</span> <span class="nav-text">何时使用条纹压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E6%94%B9%E8%BF%9B"><span class="nav-number">10.1.1.</span> <span class="nav-text">性能改进</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E7%94%A8%E6%9D%A1%E5%B8%A6%E5%8E%8B%E7%BC%A9"><span class="nav-number">10.1.2.</span> <span class="nav-text">启用条带压缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%9D%A1%E5%B8%A6%E5%8E%8B%E7%BC%A9"><span class="nav-number">10.1.3.</span> <span class="nav-text">配置条带压缩</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8C%BA%E5%9F%9F%E5%92%8C%E6%9D%A1%E5%B8%A6%E5%A4%A7%E5%B0%8F"><span class="nav-number">10.2.</span> <span class="nav-text">区域和条带大小</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9D%A1%E5%B8%A6%E5%A4%A7%E5%B0%8F%E8%AE%BE%E7%BD%AE"><span class="nav-number">10.3.</span> <span class="nav-text">条带大小设置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hbase-store-stripe-initialStripeCount"><span class="nav-number">10.3.1.</span> <span class="nav-text">hbase.store.stripe.initialStripeCount</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hbase-store-stripe-sizeToSplit"><span class="nav-number">10.3.2.</span> <span class="nav-text">hbase.store.stripe.sizeToSplit</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hbase-store-stripe-splitPartCount"><span class="nav-number">10.3.3.</span> <span class="nav-text">hbase.store.stripe.splitPartCount</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MemStore-%E5%A4%A7%E5%B0%8F%E8%AE%BE%E7%BD%AE"><span class="nav-number">10.4.</span> <span class="nav-text">MemStore 大小设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%B8%B8%E5%8E%8B%E7%BC%A9%E9%85%8D%E7%BD%AE%E5%92%8C%E6%9D%A1%E5%B8%A6%E5%8E%8B%E7%BC%A9"><span class="nav-number">10.5.</span> <span class="nav-text">正常压缩配置和条带压缩</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">220</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2022/08/03/hbase%20region%20compaction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hbase region compaction
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-08-03 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-03T00:00:00+08:00">2022-08-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-02-17 19:51:55" itemprop="dateModified" datetime="2023-02-17T19:51:55+08:00">2023-02-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>当 MemStore 达到给定大小 ( hbase.hregion.memstore.flush.size) 时,它会将其内容刷新到 StoreFile.<br>StoreFiles 的数量随着时间的推移而增加.<br>压缩是一种操作,它通过将存储文件合并在一起来减少存储中的存储文件数量,以提高读取操作的性能.<br>执行压缩可能会占用大量资源,并且会根据许多因素帮助或阻碍性能.</p>
<span id="more"></span>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h3><p>压实分为两类:次要(minor)和主要(major).<br>次要和主要压缩在以下方面有所不同.</p>
<h4 id="minor"><a href="#minor" class="headerlink" title="minor"></a>minor</h4><p>Minor compaction通常选择少量相邻的小 StoreFile,并将它们重写为单个 StoreFile.<br>由于潜在的副作用,次要压缩<font color="red">不会丢弃(过滤掉)删除或过期的版本</font>.<br>次要压缩的最终结果是<font color="red">给定 Store 的 StoreFiles 更少/更大</font>.</p>
<h4 id="major"><a href="#major" class="headerlink" title="major"></a>major</h4><p>主要压缩的最终结果是<font color="red">每个 Store 有一个 StoreFile</font>.<br>主要压缩还<font color="red">处理删除标记和最大版本</font>.</p>
<img src="/images/hbc3.png" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="压缩和删除"><a href="#压缩和删除" class="headerlink" title="压缩和删除"></a>压缩和删除</h3><p>当 HBase 中发生显式删除时,实际上并没有删除数据.<br>相反,写了一个墓碑标记.<br>墓碑标记可防止数据随查询一起返回.<br>在主要压缩过程中,数据实际上被删除,逻辑删除标记从 StoreFile 中删除.<br>如果删除是由于 TTL 过期而发生的,则不会创建逻辑删除.<br>相反,过期数据会被过滤掉,不会写回压缩的 StoreFile.</p>
<h3 id="压缩和版本"><a href="#压缩和版本" class="headerlink" title="压缩和版本"></a>压缩和版本</h3><p>创建列族时,您可以指定要保留的最大版本数,方法是指定<code>HColumnDescriptor.setMaxVersions(int versions)</code>.默认值为3.<br>如果存在超过指定最大值的版本,则多余的版本将被过滤掉并且不会写回压缩的 StoreFile.</p>
<h3 id="主要压缩会影响查询结果"><a href="#主要压缩会影响查询结果" class="headerlink" title="主要压缩会影响查询结果"></a>主要压缩会影响查询结果</h3><p>在某些情况下,如果明确删除较新的版本,则可能会无意中恢复较旧的版本.<br>这种情况只有在压缩完成之前才有可能.</p>
<p>从理论上讲,主要压缩可以提高性能.<br>但是,在高负载系统上,主要压缩可能需要不适当数量的资源并对性能产生不利影响.<br>在默认配置中,主要压缩被自动安排为在 7 天内运行一次.<br>这有时不适合生产系统.<br>您可以手动管理主要压缩.</p>
<p>压缩不执行区域合并.</p>
<h2 id="压缩策略"><a href="#压缩策略" class="headerlink" title="压缩策略"></a>压缩策略</h2><p>一次压缩大型 StoreFiles 或太多 StoreFiles 会导致 IO 负载超过集群在不引起性能问题的情况下能够处理的负载.<br>HBase 选择将哪些 StoreFiles 包含在压缩中(以及压缩是次要压缩还是主要压缩)的方法称为压缩策略.</p>
<p>在 HBase 0.96.x 之前,只有一种压缩策略.<br>原来的压缩策略仍然可以作为<font color="blue">RatioBasedCompactionPolicy</font>.<br>新的压缩默认策略,称为<font color="blue">ExploringCompactionPolicy</font>,随后被反向移植到 HBase 0.94 和 HBase 0.95,并且是 HBase 0.96 和更新版本中的默认策略.<br>它在HBASE-7842中实现.<br>简而言之,ExploringCompactionPolicy尝试选择尽可能最好的 StoreFiles 集以用最少的工作量进行压缩,同时选择RatioBasedCompactionPolicy满足条件的第一组.</p>
<p>无论使用何种压缩策略,文件选择都由几个可配置参数控制,并以多步方法进行.</p>
<blockquote>
<p><font color="red">被卡住</font><br>当 MemStore 变得太大时,它需要将其内容刷新到 StoreFile.<br>但是Store只能有<code>hbase.hstore.blockingStoreFiles</code>文件,所以MemStore需要等待StoreFiles的数量减少一次或多次compaction.<br>但是,如果 MemStore 增长大于<code>hbase.hregion.memstore.flush.size</code>,则它无法将其内容刷新到 StoreFile.<br>如果 MemStore 太大并且 StoreFiles 的数量也太多,则称该算法&quot;卡住&quot;了.<br>压缩算法检查这种&quot;卡住&quot;情况并提供机制来缓解它.</p>
</blockquote>
<h3 id="ExploringCompactionPolicy-算法"><a href="#ExploringCompactionPolicy-算法" class="headerlink" title="ExploringCompactionPolicy 算法"></a>ExploringCompactionPolicy 算法</h3><p>ExploringCompactionPolicy 算法在选择压缩最有利的集合之前会考虑每个可能的相邻 StoreFiles 集合.</p>
<p>ExploringCompactionPolicy 特别适用的一种情况是,当您批量加载数据时,批量加载创建的 StoreFiles 比保存比批量加载数据更早的数据的 StoreFiles 更大.<br>这可以&quot;诱骗&quot;HBase 在每次需要压缩时选择执行主要压缩,并导致大量额外开销.<br>使用 ExploringCompactionPolicy,主要压缩发生的频率要低得多,因为次要压缩更有效.</p>
<p>一般来说,ExploringCompactionPolicy 是大多数情况下的正确选择,因此是默认的压缩策略.</p>
<p>以下是 ExploringCompactionPolicy 逻辑:</p>
<ol>
<li>列出store中所有现有的 StoreFiles.<br>算法的其余部分过滤此列表以得出将被选择用于压缩的 HFiles 子集.</li>
<li>如果这是用户请求的压缩,请尝试执行请求的压缩类型,而不管通常会选择什么.<br>请注意,即使用户请求进行主要压缩,也可能无法执行主要压缩.<br>这可能是因为并非列族中的所有 StoreFile 都可用于压缩,或者列族中的 Store 太多.</li>
<li>某些 StoreFiles 会自动排除在考虑范围之外.<br>这些包括:</li>
</ol>
<ul>
<li>大于的 StoreFiles <code>hbase.hstore.compaction.max.size</code></li>
<li>由明确排除压缩的批量加载操作创建的 StoreFiles.<br>您可以决定从压缩中排除由批量加载产生的 StoreFiles.<br>为此,请在批量加载操作期间指定参数<code>hbase.mapreduce.hfileoutputformat.compaction.exclude</code>.</li>
</ul>
<ol start="4">
<li>遍历步骤 1 中的列表,并列出所有可能的 StoreFiles 集以压缩在一起.<br>潜在集是<code>hbase.hstore.compaction.min</code>列表中一组连续的 StoreFiles.<br>对于每个集合,执行一些健全性检查并确定这是否是可以完成的最佳压缩:</li>
</ol>
<ul>
<li>如果此集合中的 StoreFiles 数量(不是 StoreFiles 的大小)小于<code>hbase.hstore.compaction.min</code>或大于<code>hbase.hstore.compaction.max</code>,则不予考虑.</li>
<li>将这组 StoreFiles 的大小与目前在列表中找到的最小可能压缩的大小进行比较.<br>如果这组 StoreFiles 的大小代表可以完成的最小压缩,则存储它以在算法&quot;卡住&quot;时用作后备,否则不会选择任何 StoreFiles.</li>
<li>对这组 StoreFile 中的每个 StoreFile 进行基于大小的健全性检查.<ul>
<li>如果这个 StoreFile 的大小大于<code>hbase.hstore.compaction.max.size</code>,则不予考虑.</li>
<li>如果大小大于或等于<code>hbase.hstore.compaction.min.size</code>,则根据基于文件的比率对其进行完整性检查,以查看它是否太大而无法考虑.</li>
<li>如果出现以下情况,则完整性检查成功:</li>
<li>此集合中只有一个 StoreFile,或者对于每个 StoreFile,其大小乘以<code>hbase.hstore.compaction.ratio</code>(或者<code>hbase.hstore.compaction.ratio.offpeak</code>如果配置了非高峰时段并且它在非高峰时段)小于集合中其他 HFile 的大小总和.</li>
</ul>
</li>
</ul>
<ol start="5">
<li>如果这组 StoreFiles 仍在考虑中,请将其与之前选择的最佳压缩进行比较.<br>如果更好,用这个替换之前选择的最佳压实.</li>
<li>处理完所有潜在压缩列表后,执行找到的最佳压缩.<br>如果没有选择 StoreFiles 进行压缩,但有多个 StoreFiles,则假设算法被卡住了,如果是这样,则执行在步骤 3 中找到的最小压缩.</li>
</ol>
<h3 id="RatioBasedCompactionPolicy算法"><a href="#RatioBasedCompactionPolicy算法" class="headerlink" title="RatioBasedCompactionPolicy算法"></a>RatioBasedCompactionPolicy算法</h3><p>RatioBasedCompactionPolicy 是 HBase 0.96 之前唯一的压缩策略,尽管 ExploringCompactionPolicy 现在已经反向移植到 HBase 0.94 和 0.95.<br>要使用 RatioBasedCompactionPolicy 而不是 ExploringCompactionPolicy,请在hbase-site.xml 文件中<code>hbase.hstore.defaultengine.compactionpolicy.class</code>设置为 RatioBasedCompactionPolicy.<br>要切换回 ExploringCompactionPolicy,请从hbase-site.xml中删除设置.</p>
<p>以下部分将向您介绍用于在 RatioBasedCompactionPolicy 中选择要压缩的 StoreFiles 的算法.</p>
<ol>
<li>第一阶段是创建一个包含所有压缩候选者的列表.<br>创建一个列表,其中包含尚未在压缩队列中的所有 StoreFiles,以及比当前正在压缩的最新文件更新的所有 StoreFiles.<br>此 StoreFiles 列表按序列 ID 排序.<br>序列 ID 在将 Put 附加到预写日志 (WAL) 时生成,并存储在 HFile 的元数据中.</li>
<li>检查算法是否被卡住(如果是,则强制进行主要压缩.)<br>这是一个关键领域,ExploringCompactionPolicy 算法通常是比 RatioBasedCompactionPolicy 更好的选择.</li>
<li>如果压缩是用户请求的,请尝试执行请求的压缩类型.<br>请注意,如果所有 HFile 都不可用于压缩或存在太多 StoreFile(超过<code>hbase.hstore.compaction.max</code>),则可能无法进行主要压缩.</li>
<li>某些 StoreFiles 会自动排除在考虑范围之外.<br>这些包括:</li>
</ol>
<ul>
<li>大于的 StoreFiles <code>hbase.hstore.compaction.max.size</code></li>
<li>由明确排除压缩的批量加载操作创建的 StoreFiles.<br>您可以决定从压缩中排除由批量加载产生的 StoreFiles.<br>为此,请在批量加载操作期间指定参数<code>hbase.mapreduce.hfileoutputformat.compaction.exclude</code>.</li>
</ul>
<ol start="5">
<li>主要压缩中允许的 StoreFiles 的最大数量由<code>hbase.hstore.compaction.max</code>参数控制.<br>如果列表包含的 StoreFiles 数量超过此数量,则即使进行了主要压缩,也会执行次要压缩.<br>然而,即使有多个<code>hbase.hstore.compaction.max</code> StoreFiles 要压缩,用户请求的主要压缩仍然会发生.</li>
<li>如果列表包含少于<code>hbase.hstore.compaction.min</code>要压缩的 StoreFiles,则中止次要压缩.<br>请注意,可以在单个 HFile 上执行主要压缩.<br>它的功能是删除删除和过期的版本,并重置 StoreFile 上的位置.</li>
<li>该<code>hbase.hstore.compaction.ratio</code>参数的值乘以小于给定文件的 StoreFiles 的总和,以确定是否在次要压缩期间选择该 StoreFile 进行压缩.<br>例如,如果 <code>hbase.hstore.compaction.ratio</code> 为 1.2,FileX 为 5MB,FileY 为 2MB,FileZ 为 3MB:<br><code>5 &lt;= 1.2 x (2 + 3) 或 5 &lt;= 6</code><br>在这种情况下,FileX 有资格进行次要压缩.<br>如果 FileX 为 7MB,则它不符合次要压缩的条件.<br>此比率有利于较小的 StoreFile.<br>如果您还配置<code>hbase.offpeak.start.hour</code>和<code>hbase.offpeak.end.hour</code>,则可以使用参数<code>hbase.hstore.compaction.ratio.offpeak</code>为非高峰时段配置不同的比率.</li>
<li>如果最后一次主要压缩太久以前并且有多个 StoreFile 要压缩,则运行主要压缩,即使它本来是次要压缩.<br>默认情况下,主要压缩之间的最长时间为 7 天,加上或减去 4.8 小时的时间段,并在这些参数内随机确定.<br>在 HBase 0.96 之前,主要压缩周期为 24 小时.<br>请参阅<code>hbase.hregion.majorcompaction</code>下表以调整或禁用基于时间的主要压缩.</li>
</ol>
<h2 id="压缩算法参数"><a href="#压缩算法参数" class="headerlink" title="压缩算法参数"></a>压缩算法参数</h2><h3 id="hbase-hstore-compaction-min"><a href="#hbase-hstore-compaction-min" class="headerlink" title="hbase.hstore.compaction.min"></a>hbase.hstore.compaction.min</h3><p>在运行压缩之前必须符合压缩条件的最小 StoreFiles 数.<br>调优的目的是避免以太多小的 StoreFiles 结束而无法压缩.<br>每次您在 Store 中有两个 StoreFiles 时,将此值设置为 2 会导致较小的压缩,这可能是不合适的.<br>如果您将此值设置得太高,则所有其他值都需要相应调整.<br>对于大多数情况,默认值是合适的.<br>在以前的 HBase 版本中,该参数hbase.hstore.compaction.min称为 <code>hbase.hstore.compactionThreshold</code>.</p>
<p>默认值:3</p>
<h3 id="hbase-hstore-compaction-max"><a href="#hbase-hstore-compaction-max" class="headerlink" title="hbase.hstore.compaction.max"></a>hbase.hstore.compaction.max</h3><p>无论符合条件的 StoreFiles 的数量如何,将为单个次要压缩选择的 StoreFiles 的最大数量.<br>实际上, hbase.hstore.compaction.max的值控制了完成一次压缩所需的时间长度.<br>将它设置得更大意味着压缩中包含更多的 StoreFiles.<br>对于大多数情况,默认值是合适的.</p>
<p>默认值:10</p>
<h3 id="hbase-hstore-compaction-min-size"><a href="#hbase-hstore-compaction-min-size" class="headerlink" title="hbase.hstore.compaction.min.size"></a>hbase.hstore.compaction.min.size</h3><p>小于此大小的 StoreFile 将始终符合次要压缩的条件.<br>此大小或更大的 StoreFiles 由<code>hbase.hstore.compaction.ratio</code>评估以确定它们是否符合条件.<br>因为此限制表示所有小于此值的 StoreFiles 的&quot;自动包含&quot;限制,所以在刷新 1-2 MB 范围内的许多文件的写入密集型环境中可能需要减少此值,因为每个 StoreFile 都将成为目标用于压缩,生成的 StoreFiles 可能仍小于最小大小,需要进一步压缩.<br>如果降低此参数,则会更快地触发比率检查.<br>这解决了早期版本的 HBase 中出现的一些问题,但在大多数情况下不再需要更改此参数.</p>
<p>默认值:128 MB</p>
<h3 id="hbase-hstore-compaction-max-size"><a href="#hbase-hstore-compaction-max-size" class="headerlink" title="hbase.hstore.compaction.max.size"></a>hbase.hstore.compaction.max.size</h3><p>大于此大小的 StoreFile 将被排除在压缩之外.<br>提高的效果是更少/更大的不经常压缩的 StoreFiles.<br>如果你觉得压缩发生得太频繁而没有太大好处,你可以尝试提高这个值.</p>
<p>默认值:Long.MAX_VALUE</p>
<h3 id="hbase-hstore-compaction-ratio"><a href="#hbase-hstore-compaction-ratio" class="headerlink" title="hbase.hstore.compaction.ratio"></a>hbase.hstore.compaction.ratio</h3><p>对于小型压缩,此比率用于确定大于<code>hbase.hstore.compaction.min.size</code>的给定 StoreFile 是否符合压缩条件.<br>它的作用是限制大型 StoreFile 的压缩.<br>值表示为浮点小数.</p>
<ol>
<li>较大的比率(例如 10)将产生一个巨大的 StoreFile.<br>相反,值为 0.25 将产生类似于 BigTable 压缩算法的行为,产生四个 StoreFiles.</li>
<li>建议使用介于 1.0 和 1.4 之间的适中值.<br>调整此值时,您正在平衡写入成本和读取成本.<br>提高该值(到 1.4 之类的值)将产生更多的写入成本,因为您将压缩更大的 StoreFiles.<br>然而,在读取期间,HBase 将需要通过更少的 StoreFiles 来完成读取.<br>如果您不能利用Bloom Filters,请考虑这种方法.</li>
<li>或者,您可以将此值降低到 1.0 之类的值以降低写入的后台成本,并用于限制读取期间接触的 StoreFiles 的数量.<br>对于大多数情况,默认值是合适的.</li>
</ol>
<p>默认值:1.2F</p>
<h3 id="hbase-hstore-compaction-ratio-offpeak"><a href="#hbase-hstore-compaction-ratio-offpeak" class="headerlink" title="hbase.hstore.compaction.ratio.offpeak"></a>hbase.hstore.compaction.ratio.offpeak</h3><p>如果还配置了非高峰时间,则在非高峰压缩期间使用的压缩比率.<br>表示为浮点小数.<br>hbase.hstore.compaction.ratio这允许在设定的时间段内进行更积极(或更不积极,如果您将其设置为低于)压缩.<br>如果禁用非高峰期则忽略(默认).<br>这与 hbase.hstore.compaction.ratio.</p>
<p>默认值:5.0F</p>
<h3 id="hbase-offpeak-start-hour"><a href="#hbase-offpeak-start-hour" class="headerlink" title="hbase.offpeak.start.hour"></a>hbase.offpeak.start.hour</h3><p>非高峰时段的开始,表示为 0 到 23 之间的整数,包括 0 和 23.<br>设置为 -1 以禁用非高峰期.</p>
<p>默认值:(-1禁用)</p>
<h3 id="hbase-offpeak-end-hour"><a href="#hbase-offpeak-end-hour" class="headerlink" title="hbase.offpeak.end.hour"></a>hbase.offpeak.end.hour</h3><p>非高峰时段的结束时间,表示为 0 到 23 之间的整数,包括 0 和 23.<br>设置为 -1 以禁用非高峰期.</p>
<p>默认值:(-1禁用)</p>
<h3 id="hbase-regionserver-thread-compaction-throttle"><a href="#hbase-regionserver-thread-compaction-throttle" class="headerlink" title="hbase.regionserver.thread.compaction.throttle"></a>hbase.regionserver.thread.compaction.throttle</h3><p>有两种不同的线程池用于压缩,一种用于大型压缩,另一种用于小型压缩.<br>这有助于快速压缩精简表(例如hbase:meta).<br>如果压缩大于此阈值,它将进入大型压缩池.<br>在大多数情况下,默认值是合适的.</p>
<p>默认值:(2 x <code>hbase.hstore.compaction.max</code> x <code>hbase.hregion.memstore.flush.size</code> 默认为128)</p>
<h3 id="hbase-hregion-majorcompaction"><a href="#hbase-hregion-majorcompaction" class="headerlink" title="hbase.hregion.majorcompaction"></a>hbase.hregion.majorcompaction</h3><p>主要压缩之间的时间,以毫秒表示.<br>设置为 0 以禁用基于时间的自动主要压缩.<br>用户请求的和基于大小的主要压缩仍然会运行.<br>该值乘以<code>hbase.hregion.majorcompaction.jitter</code>导致压缩在给定时间窗口内的某个随机时间开始.</p>
<p>默认值:7 天(604800000毫秒)</p>
<h3 id="hbase-hregion-majorcompaction-jitter"><a href="#hbase-hregion-majorcompaction-jitter" class="headerlink" title="hbase.hregion.majorcompaction.jitter"></a>hbase.hregion.majorcompaction.jitter</h3><p>应用于 hbase.hregion.majorcompaction 的乘数,使压缩在hbase.hregion.majorcompaction的任一侧发生给定的时间量.<br>数字越小,压缩越接近间隔 hbase.hregion.majorcompaction.<br>表示为浮点小数.</p>
<p>默认值:.50F</p>
<h2 id="压缩流程"><a href="#压缩流程" class="headerlink" title="压缩流程"></a>压缩流程</h2><p>整个Compaction始于特定的触发条件,比如flush操作/周期性地Compaction检查操作等.<br>一旦触发,HBase会将该Compaction交由一个独立的线程处理,该线程首先会从对应store中选择合适的hfile文件进行合并,这一步是整个Compaction的核心,选取文件需要遵循很多条件,比如文件数不能太多/不能太少/文件大小不能太大等等.<br>最理想的情况是,选取那些承载IO负载重/文件小的文件集.<br>实际实现中,HBase提供了多个文件选取算法:RatioBasedCompactionPolicy/ExploringCompactionPolicy/StripeCompactionPolicy等.<br>用户也可以通过特定接口实现自己的Compaction算法.<br>选出待合并的文件后,HBase会根据这些hfile文件总大小挑选对应的线程池处理,最后对这些文件执行具体的合并操作.<br>可以通过下图简单地梳理上述流程:</p>
<img src="/images/hbc1.png" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h3><p>HBase中可以触发compaction的因素有很多,最常见的因素有这么三种:Memstore Flush/后台线程周期性检查/手动触发.</p>
<h4 id="Memstore-Flush"><a href="#Memstore-Flush" class="headerlink" title="Memstore Flush"></a>Memstore Flush</h4><p>应该说compaction操作的源头就来自flush操作,memstore flush会产生HFile文件,文件越来越多就需要compact.<br>因此在每次执行完Flush操作之后,都会对当前Store中的文件数进行判断,符合条件就会触发compaction.<br>需要说明的是,compaction都是以Store为单位进行的,而在Flush触发条件下,整个Region的所有Store都会执行compact,所以会在短时间内执行多次compaction.</p>
<h4 id="后台线程周期性检查"><a href="#后台线程周期性检查" class="headerlink" title="后台线程周期性检查"></a>后台线程周期性检查</h4><p>CompactionChecker是RS上的工作线程(Chore).<br>后台线程CompactionChecker定期触发检查是否需要执行compaction,设置执行周期是通过threadWakeFrequency指定.<br>大小通过<code>hbase.server.thread.wakefrequency</code>配置(默认10000毫秒),<br>然后乘以默认倍数<code>hbase.server.compactchecker.interval.multiplier</code>(1000),毫秒时间转换为秒.<br>因此,在不做参数修改的情况下,CompactionChecker大概是2h 46m 40s 执行一次.</p>
<p>和flush不同的是,该线程优先检查文件数＃是否大于,一旦大于就会触发compaction.<br>如果不满足,它会接着检查是否满足major compaction条件,简单来说,如果当前store中hfile的最早更新时间早于某个值mcTime,就会触发major compaction,HBase预想通过这种机制定期删除过期数据.<br>上文mcTime是一个浮动值,浮动区间默认为<code>[7-7*0.2,7+7*0.2]</code>,其中7为<code>hbase.hregion.majorcompaction</code>,0.2为<code>hbase.hregion.majorcompaction.jitter</code>,可见默认在7天左右就会执行一次major compaction.<br>用户如果想禁用major compaction,只需要将参数<code>hbase.hregion.majorcompaction</code>设为0.</p>
<h4 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h4><p>手动触发compaction通常是为了执行major compaction,原因如下:</p>
<ol>
<li>很多业务担心自动major compaction影响读写性能,因此会选择低峰期手动触发.</li>
<li>用户在执行完alter操作之后希望立刻生效,执行手动触发major compaction.</li>
<li>HBase管理员发现硬盘容量不够的情况下手动触发major compaction删除大量过期数据.</li>
</ol>
<p>无论哪种触发动机,一旦手动触发,HBase会不做很多自动化检查,直接执行合并.</p>
<h3 id="Compaction诱发因子"><a href="#Compaction诱发因子" class="headerlink" title="Compaction诱发因子"></a>Compaction诱发因子</h3><table>
<thead>
<tr>
<th align="left">参数名</th>
<th align="left">配置项</th>
<th align="left">默认值</th>
</tr>
</thead>
<tbody><tr>
<td align="left">minFilesToCompact</td>
<td align="left">hbase.hstore.compactionThreshold</td>
<td align="left">3</td>
</tr>
<tr>
<td align="left">maxFilesToCompact</td>
<td align="left">hbase.hstore.compaction.max</td>
<td align="left">10</td>
</tr>
<tr>
<td align="left">minCompactSize</td>
<td align="left">hbase.hstore.compaction.min.size</td>
<td align="left">128MB即(memstoreFlushSize)</td>
</tr>
<tr>
<td align="left">maxCompactSize</td>
<td align="left">hbase.hstore.compaction.max.size</td>
<td align="left">Long.MAX_VALUE</td>
</tr>
</tbody></table>
<p>在以前版本的HBase中,hbase.hstore.compaction.min调用了该参数hbase.hstore.compactionThreshold.</p>
<p>compactionChecker实现类是CompactionChecker,其继承了ScheduledChore,这个类通过实现chore方法而实现周期性的调用,其初始化是在initializeThreads中.直接看其Chore方法,</p>
<img src="/images/hbc4.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>方法比较简单,取出所有在线的region,遍历region上的所有store(HStore)判断是否需要compact,<br>判断是needsCompaction()方法去判断是否足够多的文件触发了Compaction的条件.</p>
<img src="/images/hbc5.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>条件为:HStore中StoreFiles的个数–正在执行Compacting的文件个数 &gt; minFilesToCompact.</p>
<p>chore方法中needsCompaction判断的是minorcompact是否需要执行.<br>chore方法中可以直观的看到majorCompact是通过isMajorCompaction()方法判断的这是很多判断条件的合成.<br>isMajorCompaction判断上次进行majorCompaction到当前的时间间隔是否超过hbase.hregion.majorcompaction设置的值.</p>
<h3 id="选择合适HFile合并"><a href="#选择合适HFile合并" class="headerlink" title="选择合适HFile合并"></a>选择合适HFile合并</h3><p>选择合适的文件进行合并是整个compaction的核心,因为合并文件的大小以及其当前承载的IO数直接决定了compaction的效果.<br>最理想的情况是,这些文件承载了大量IO请求但是大小很小,这样compaction本身不会消耗太多IO,而且合并完成之后对读的性能会有显著提升.<br>然而现实情况可能大部分都不会是这样,在0.96版本和0.98版本,分别提出了两种选择策略,在充分考虑整体情况的基础上选择最佳方案.<br>无论哪种选择策略,都会首先对该Store中所有HFile进行一一排查,排除不满足条件的部分文件:</p>
<p>执行RatioBasedCompactionPolicy的selectCompaction算法.</p>
<img src="/images/hbc6.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>第一个红框:排除当前正在执行compact的文件及其比这些文件更新的所有文件(SequenceId更大).</p>
<img src="/images/hbc7.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>第二个红框:排除某些过大的单个文件,如果文件大小大于hbase.hzstore.compaction.max.size(默认Long最大值),则被排除,否则会产生大量IO消耗.</p>
<p>经过排除的文件称为候选文件,HBase接下来会再判断是否满足major compaction条件,如果满足,就会选择全部文件进行合并.</p>
<img src="/images/hbc8.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>第三个红框:判断是否需要进行major Compaction,这是很多判断条件的合成.</p>
<p>判断条件有下面三条,只要满足其中一条就会执行major compaction:</p>
<ol>
<li>用户强制执行major compaction</li>
<li>长时间没有进行compact,hbase.hregion.majorcompaction设置的值,也就是判断上次进行major Compaction到当前的时间间隔,如果超过设置值,并且满足另外一个条件是compactSelection.getFilesToCompact().size() &lt; this.maxFilesToCompact(即候选文件数小于hbase.hstore.compaction.max).</li>
<li>Store中含有Reference文件,Reference文件是split region产生的临时文件,只是简单的引用文件,一般必须在compact过程中删除</li>
</ol>
<blockquote>
<p>因此,通过设置hbase.hregion.majorcompaction = 0可以关闭CompactionChecke触发的major compaction,但是无法关闭用户调用级别的major Compaction.</p>
</blockquote>
<p>如果不满足major compaction条件,就必然为minor compaction,第四个红框绿线处是进行minor策略,HBase主要有两种minor策略:<br>RatioBasedCompactionPolicy/ExploringCompactionPolicy.</p>
<p>Ratio策略是0.94版本的默认策略,而0.96版本之后默认策略就换为了Exploring策略.</p>
<p>ExploringCompactionPolicy跟RatioBasedCompactionPolicy的区别,<br>简单的说就是RatioBasedCompactionPolicy是简单的从头到尾遍历StoreFile列表,遇到一个符合Ratio条件的序列就选定执行Compaction.<br>而ExploringCompactionPolicy则是从头到尾遍历的同时记录下当前最优,然后从中选择一个全局最优列表.</p>
<p>ratio默认值是1.2,但是打开了非高峰时间段的优化时,可以有不同的值,非高峰的ratio默认值是5.0,此优化目的是为了在业务低估时可以合并更多的数据,目前此优化只能是天的小说时间段,还不算灵活.<br>其有如下四个参数控制,</p>
<table>
<thead>
<tr>
<th align="left">配置项</th>
<th align="left">默认值</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">hbase.hstore.compaction.ratio</td>
<td align="left">1.2F</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">hbase.hstore.compaction.ratio.offpeak</td>
<td align="left">5.0F</td>
<td align="left">与下面两个参数联用</td>
</tr>
<tr>
<td align="left">hbase.offpeak.start.hour</td>
<td align="left">-1</td>
<td align="left">设置HBaseoffpeak开始时间[0,23]</td>
</tr>
<tr>
<td align="left">hbase.offpeak.end.hour</td>
<td align="left">-1</td>
<td align="left">设置HBaseoffpeak结束时间[0,23]</td>
</tr>
</tbody></table>
<p>如果默认没有设置offpeak时间的话,那么完全按照hbase.hstore.compaction.ration来进行控制.<br>如下图所示,如果filesSize[i]过大,超过后面8个文件总和<code>*1.2</code>,那么该文件被认为过大,而不纳入minor Compaction的范围.</p>
<img src="/images/hbc9.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>这样做使得Compaction尽可能工作在最近刷入HDFS的小文件的合并,从而使得提高Compaction的执行效率.</p>
<p>ExploringCompactionPolicy继承RatioBasedCompactionPolicy,重写了applyCompactionPolicy方法,applyCompactionPolicy是对minor compaction的选择文件的策略算法.</p>
<p>接着通过selectCompaction选出的文件,加入到filesCompacting队列中,创建compactionRequest,提交请求.</p>
<h3 id="挑选合适的线程池"><a href="#挑选合适的线程池" class="headerlink" title="挑选合适的线程池"></a>挑选合适的线程池</h3><p>HBase实现中有一个专门的线程CompactSplitThead负责接收compact请求以及split请求,而且为了能够独立处理这些请求,这个线程内部构造了多个线程池:largeCompactions/smallCompactions以及splits等,<br>其中splits线程池负责处理所有的split请求,<br>largeCompactions和smallCompaction负责处理所有的compaction请求,<br>其中前者用来处理大规模compaction,后者处理小规模compaction.</p>
<blockquote>
<p>哪些compaction应该分配给largeCompactions处理,哪些应该分配给smallCompactions处理?<br>是不是Major Compaction就应该交给largeCompactions线程池处理?</p>
</blockquote>
<p>不对.<br>而是根据一个配置hbase.regionserver.thread.compaction.throttle的设置值(一般在hbase-site.xml没有该值的设置)<br>而是采用默认值2 * minFilesToCompact * memstoreFlushSize,如果compactRequest需要处理的storefile文件的大小总和,大于throttle的值,则会提交到largeCompactions线程池进行处理,反之亦然.</p>
<p>这里需要明白三点:</p>
<ol>
<li>上述设计目的是为了能够将请求独立处理,提供系统的处理性能.</li>
<li>这两个线程池不是根据CR来自于Major Compaction Minor Compaction来进行区分</li>
<li>largeCompactions线程池和smallCompactions线程池默认都只有一个线程,用户可以通过参数<code>hbase.regionserver.thread.compaction.large</code>和<br><code>hbase.regionserver.thread.compaction.small</code>进行配置.</li>
</ol>
<h3 id="执行HFile文件合并"><a href="#执行HFile文件合并" class="headerlink" title="执行HFile文件合并"></a>执行HFile文件合并</h3><p>上文一方面选出了待合并的HFile集合,一方面也选出来了合适的处理线程,万事俱备,只欠最后真正的合并.<br>合并流程说起来也简单,主要分为如下几步:</p>
<ol>
<li>分别读出待合并hfile文件的KV,并顺序写到位于./tmp目录下的临时文件中</li>
<li>将临时文件移动到对应region的数据目录</li>
<li>将compaction的输入文件路径和输出文件路径封装为KV写入WAL日志,并打上compaction标记,最后强制执行sync</li>
<li>将对应region数据目录下的compaction输入文件全部删除</li>
</ol>
<p>上述四个步骤看起来简单,但实际是很严谨的,具有很强的容错性和完美的幂等性:</p>
<ol>
<li><p>如果RS在步骤2之前发生异常,本次compaction会被认为失败,如果继续进行同样的compaction,上次异常对接下来的compaction不会有任何影响,也不会对读写有任何影响.<br>唯一的影响就是多了一份多余的数据.</p>
</li>
<li><p>如果RS在步骤2之后/步骤3之前发生异常,同样的,仅仅会多一份冗余数据.</p>
</li>
<li><p>如果在步骤3之后/步骤4之前发生异常,RS在重新打开region之后首先会从WAL中看到标有compaction的日志,因为此时输入文件和输出文件已经持久化到HDFS,因此只需要根据WAL移除掉compaction输入文件即可.</p>
</li>
</ol>
<h3 id="Compaction-对读写请求的影响"><a href="#Compaction-对读写请求的影响" class="headerlink" title="Compaction 对读写请求的影响"></a>Compaction 对读写请求的影响</h3><h4 id="存储上的写入放大"><a href="#存储上的写入放大" class="headerlink" title="存储上的写入放大"></a>存储上的写入放大</h4><p>HBase Compaction会带来写入放大,特别是在写多读少的场景下,写入放大就会比较明显.<br>随着minor compaction以及major Compaction的发生,可以看到,这条数据被反复读取/写入了多次,这是导致写放大的一个关键原因,这里的写放大,涉及到网络IO与磁盘IO,因为数据在HDFS中默认有三个副本.</p>
<h4 id="读路径上的延时毛刺"><a href="#读路径上的延时毛刺" class="headerlink" title="读路径上的延时毛刺"></a>读路径上的延时毛刺</h4><p>HBase执行compaction操作结果会使文件数基本稳定,进而IO Seek次数相对稳定,延迟就会稳定在一定范围.<br>然而,compaction操作会带来很大的带宽压力以及短时间IO压力.<br>因此compaction就是使用短时间的IO消耗以及带宽消耗换取后续查询的低延迟.<br>这种短时间的压力就会造成读请求在延时上会有比较大的毛刺.</p>
<h4 id="写请求上的短暂阻塞"><a href="#写请求上的短暂阻塞" class="headerlink" title="写请求上的短暂阻塞"></a>写请求上的短暂阻塞</h4><p>Compaction对写请求也会有比较大的影响.<br>主要体现在HFile比较多的场景下,HBase会限制写请求的速度.<br>当写请求非常多,导致不断生成HFile,compact的速度远远跟不上HFile生成的速度,这样就会使HFile的数量会越来越多,导致读性能急剧下降.</p>
<p>为了避免这种情况,在HFile的数量过多的时候会限制写请求的速度,每次MemStore执行flush的操作前,会查看HFile数量,<br>如果数量超过hbase.hstore.blockingStoreFiles配置值(默认10),flush操作将会受到阻塞,<br>阻塞时间为hbase.hstore.blockingWaitTime(默认90000,即1.5分钟),<br>在这段时间内,如果compaction操作使得HFile下降到blockingStoreFiles配置值,则停止阻塞.<br>另外阻塞超过时间后,也会恢复执行flush操作.<br>这样做可以有效地控制大量写请求的速度,但同时这也是影响写请求速度的主要原因之一.</p>
<p>Compaction执行合并操作生成的文件生效过程,需要对Store的写操作加锁,阻塞Store内的更新操作,直到更新Store的storeFiles完成为止.<br>Memstore无法刷新磁盘,此时如果memstore的内存耗尽,客户端就会导致阻塞或者是超时.</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在大多数情况下,Major是发生在storefiles和filesToCompact文件个数相同,并且满足各种条件的前提下执行.</p>
<p>触发major compaction的可能条件有:major_compact命令/majorCompact()API/regionserver自动运行.</p>
<blockquote>
<p>相关参数:<br>hbase.hregion.majoucompaction默认为24小时,<br>hbase.hregion.majorcompaction.jetter默认值为0.5,<br>防止regionserver在同一时间进行major compaction.</p>
</blockquote>
<p>hbase.hregion.majorcompaction.jetter参数的作用是,对参数hbase.hregion.majoucompaction规定的值起到浮动的作用.<br>minor compaction的运行机制要复杂一些,它由一下几个参数共同决定:</p>
<p>hbase.hstore.compaction.min<br>默认值为3,表示至少需要三个满足条件的store file时,minor compaction才会启动.</p>
<p>hbase.hstore.compaction.max<br>默认值为10,表示一次minor compaction中最多选取10个store file.</p>
<p>hbase.hstore.compaction.min.size<br>表示文件大小小于该值的store file一定会加入到minor compaction的store file中.</p>
<p>hbase.hstore.compaction.max.size<br>表示文件大小大于该值的store file 一定会被minor compaction排除.</p>
<p>hbase.hstore.compaction.ratio<br>将store file按照文件年龄排序(older to younger),minor compaction总是从older store file开始选择,如果该文件的size小于它后面hbase.hstore.compaction.max个store file size 之和乘以该ratio,则该store file 也将加入到minor compaction中.</p>
<p>另外,一般情况下,Major Compaction时间会持续比较长,整个过程会消耗大量系统资源,对上层业务有比较大的影响.<br>因此线上业务都会将关闭自动触发Major Compaction功能,改为手动在业务低峰期触发.</p>
<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>Compaction 是从一个 Region 的一个 Store 中选择部分 HFile 文件进行合并,即Compaction是以Store为单位的.</p>
<blockquote>
<p>合并原理:<br>先从这些待合并的数据文件中依次读出 KeyValue,再由小到大排序后写入一个新的文件.<br>之后,这个新生成的文件就会取代之前已合并的所有文件对外提供服务.</p>
</blockquote>
<p>HBase 根据合并规模将 Compaction 分为两类:<font color="red">Minor Compaction</font> 和 <font color="red">Major Compaction</font>.</p>
<p>Minor Compaction:<br>选取部分小的/相邻的HFile,将它们合并成一个更大的HFile.<br>在这个过程中达到TTL的数据会被移除,但是被手动删除的数据不会被移除.<br>这种合并触发频率较高.</p>
<p>Major Compaction:<br><font color="red">将一个Store中所有的HFile合并成一个HFile</font>,<br>这个过程还会完全清理三类无意义数据:<font color="red">被删除的数据/TTL过期数据/版本号超过设定版本号的数据</font>.<br>这种合并触发频率较低,默认为<font color="red">7天一次</font>.</p>
<h2 id="核心作用"><a href="#核心作用" class="headerlink" title="核心作用"></a>核心作用</h2><p>在HBase的体系架构下,Compaction有以下核心作用:</p>
<ol>
<li>合并小文件,减少文件数,稳定随机读延迟.</li>
<li>提高数据的本地化率.</li>
<li>清除无效数据,减少数据存储量.</li>
</ol>
<p>随着HFile文件数不断增多,查询可能需要越来越多的IO操作,读取延迟必然会越来越大.</p>
<p>执行Compaction会使文件个数基本稳定,进而读取IO的次数会比较稳定,延迟就会稳定在一定范围.<br>从图上看,虽然数据读取延迟相比上图稳定了一些,但是读取响应时间有了很大的毛刺,这是因为Compaction在执行的时候占用系统资源导致业务读取性能受到一定波及.</p>
<p>Compaction 的一个重要作用是提高数据的本地化率.<br>本地化率越高,在 HDFS 上访问数据时延迟就越小.<br>相反,本地化率越低,访问数据就可能大概率需要通过网络访问,延迟必然会比较大.</p>
<p>Compaction 合并小文件的同时会将落在远程 DataNode 上的数据读取出来重新写入大文件,合并后的大文件在当前 DataNode 节点上有一个副本,因此可以提高数据的本地化率.<br>极端情况下,Major Compaction 可以将当前 Region 的本地化率提高到100%.<br>这也是最常用的一种提高数据本地化率的方法.</p>
<h3 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h3><p>Compaction 在执行过程中有个比较明显的副作用:<br>Compaction 操作重写文件会带来很大的带宽压力以及短时间 IO 压力.<br>这点比较容易理解,要将小文件的数据读出来需要 IO,很多小文件数据跨网络传输需要带宽,读出来之后又要写成一个大文件,因为是三副本写入,必然需要网络开销,当然写入 IO 开销也避免不了.<br>因此可以认为,Compaction 就是使用短时间的 IO 消耗以及带宽消耗换取后续查询的低延迟.</p>
<h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>HBase中Compaction只有在特定的触发条件才会执行,一旦触发,HBase会将该Compaction交由一个独立的线程处理,该线程首先会从对应Store中选择合适的HFile文件进行合并,这一步是整个Compaction的核心.<br>选出待合并的文件后,HBase会根据这些HFile文件总大小挑选对应的线程池处理,最后对这些文件执行具体的合并操作.</p>
<h3 id="触发时机-1"><a href="#触发时机-1" class="headerlink" title="触发时机"></a>触发时机</h3><p>HBase 中触发 Compaction 的时机有很多,最常见的时机有如下三种:MemStore Flush/后台线程周期性检查/手动触发.</p>
<h4 id="MemStore-Flush"><a href="#MemStore-Flush" class="headerlink" title="MemStore Flush"></a>MemStore Flush</h4><p>应该说 Compaction 操作的源头来自 flush 操作,MemStore Flush 会产生 HFile,文件越来越多就需要执行Compaction.<br>因此在每次执行完 flush 操作之后,都会对当前 Store 中的文件数进行判断,一旦 Store 中总文件数大于 <font color="blue">hbase.hstore.compactionThreshold</font>,就会触发 Compaction.<br>需要说明的是,Compaction 都是以 Store 为单位进行的,而在 flush 触发条件下,整个 Region 的所有 Store 都会执行 compact 检查,所以一个 Region 有可能会在短时间内执行多次 Compaction.</p>
<h5 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h5><p>hbase.hstore.compactionThreshold<br>默认值为3,如果在任何一个Store中存在超过这个数量的HFile,运行Compaction将所有HFile重写为单个HFile.<br>将该参数设置成较大的值会延迟Compaction,但是当Compaction运行时,则需要更长的时间.</p>
<h4 id="后台线程周期性检查-1"><a href="#后台线程周期性检查-1" class="headerlink" title="后台线程周期性检查"></a>后台线程周期性检查</h4><p>RegionServer 会在后台启动一个线程 <font color="blue">CompactionChecker</font>,定期触发检查对应 Store 是否需要执行 Compaction,检查周期为 <font color="blue">hbase.server.thread.wakefrequency * hbase.server.compactchecker.interval.multiplier</font>,大概2小时40分左右执行一次.</p>
<p>和 MemStore flush 不同的是,该线程优先检查 Store 中总文件数是否大于阈值 <code>hbase.hstore.compactionThreshold</code>,一旦大于阀值就会触发 Compaction.如果不大于阀值,接着检查是否满足 Major Compaction 条件.<br>简单来说,如果当前 Store 中 HFile 的最早更新时间早于某个值 mcTime,就会触发 Major Compaction.</p>
<p>mcTime 是一个浮动值,浮动区间默认为<code>[7-7×0.5,7+7×0.5]</code>,其中7为参数 <font color="blue">hbase.hregion.majorcompaction</font> 的值,0.5为参数 <font color="blue">hbase.hregion.majorcompaction.jitter</font> 的值,可见默认在7天左右就会执行一次 Major Compaction.</p>
<h5 id="参数解释-1"><a href="#参数解释-1" class="headerlink" title="参数解释"></a>参数解释</h5><p>hbase.server.thread.wakefrequency<br>默认值为10000ms,作为服务线程(如日志roller)的睡眠时间间隔.</p>
<p>hbase.server.compactchecker.interval.multiplier<br>默认值为1000,用于决定周期任务频率的值,以确定是否需要Compaction.<br>通常情况下,Compaction是在一些事件(如memstore刷新)之后执行的,但是如果Region在一段时间内没有收到很多写操作,或者由于不同的Compaction策略,可能需要定期检查它.</p>
<p>hbase.hregion.majorcompaction<br>默认值为604800000ms,即7天,表示两次Major Compaction之间的时间间隔.<br>设置为0可以禁用基于时间的自动Major Compaction,但手动触发和基于Store中HFile文件数量的Major Compaction仍将运行.</p>
<p>hbase.hregion.majorcompaction.jitter<br>默认值为0.5,这个值乘以<code>hbase.hregion.majorcompaction</code>使Compaction在给定的时间窗口中以某种随机的时间开始.<br>该参数的值越小,Major Compaction就会越接近<code>hbase.hregion.majorcompaction</code>区间.</p>
<h4 id="手动触发-1"><a href="#手动触发-1" class="headerlink" title="手动触发"></a>手动触发</h4><p>一般来讲,手动触发 Compaction 大多是为了执行 Major Compaction.</p>
<p>使用手动触发 Major Compaction 的原因通常有三个,</p>
<ol>
<li>很多业务担心自动 Major Compaction 影响读写性能,因此会选择低峰期手动触发.</li>
<li>在执行完 alter 操作之后希望立刻生效,手动触发 Major Compaction.</li>
<li>HBase 管理员发现硬盘容量不够时手动触发 Major Compaction,删除大量过期数据.</li>
</ol>
<h3 id="待合并HFile集合选择策略"><a href="#待合并HFile集合选择策略" class="headerlink" title="待合并HFile集合选择策略"></a>待合并HFile集合选择策略</h3><p>选择合适的文件进行合并是整个 Compaction 的核心,因为合并文件的大小及其当前承载的 IO 数直接决定了 Compaction 的效果以及对整个系统其他业务的影响程度.<br>理想的情况是,选择的待合并 HFile 文件集合承载了大量 IO 请求但是文件本身很小,这样Compaction 本身不会消耗太多 IO,而且合并完成之后对读的性能会有显著提升.<br>然而现实中可能大部分 HFile 文件都不会这样.</p>
<p>要选择待合并的HFile文件,首先会对该Store中所有HFile逐一进行排查,排除不满足条件的部分文件,排除条件如下:</p>
<ol>
<li>排除当前正在执行 Compaction 的文件以及比这些文件更加新的所有文件.</li>
<li>排除某些过大的文件,如果文件大于 <font color="blue">hbase.hstore.compaction.max.size</font>,则被排除,否则会产生大量IO消耗.</li>
</ol>
<blockquote>
<p>参数解释<br>hbase.hstore.compaction.max.size<br>默认值:Long.MAX_VALUE,以字节表示,大于这个大小的HFile文件将被排除在Compaction之外.<br>当Compaction发生得太频繁时,可以尝试提高这个值.</p>
</blockquote>
<p>经过排除后留下来的文件称为<font color="red">候选文件</font>,接下来 HBase <font color="red">再判断侯选文件是否满足 Major Compaction 条件,如果满足,就会选择全部文件进行合并</font>.<br>判断条件如下所列,只要满足其中一条就会执行 Major Compaction:</p>
<ol>
<li>用户强制执行 Major Compaction.</li>
<li>满足CompactionChecker条件二,且候选文件数小于 <code>hbase.hstore.compaction.max</code>.</li>
<li>Store 中含有 reference 文件,reference 文件是 region 分裂产生的临时文件,一般必须在 Compaction 过程中清理.</li>
</ol>
<blockquote>
<p>参数解释<br>hbase.hstore.compaction.max<br>默认值为10,执行单次Minor Compaction过程可以被选择的HFile的最大数量,而与符合条件的HFile的数量无关.<br>实际上,该参数的值控制完成一次Compaction所需的时间长度.<br>将其设置得更大意味着Compaction中包含更多的HFile文件.<br>对于大多数情况,默认值是合适的.</p>
</blockquote>
<p>如果满足Major Compaction条件,文件选择这一步就结束了,待合并HFile文件就是Store中所有HFile文件.<br>如果不满足Major Compaction条件,就必然为Minor Compaction.</p>
<p>HBase主要有两种Minor Compaction文件选择策略,一种是RatioBasedCompactionPolicy,另一种是 ExploringCompactionPolicy.<br>后者在前者的基础上做了进一步修正.</p>
<h4 id="RatioBasedCompactionPolicy"><a href="#RatioBasedCompactionPolicy" class="headerlink" title="RatioBasedCompactionPolicy"></a>RatioBasedCompactionPolicy</h4><p>从老到新逐一扫描所有候选文件,满足其中条件之一便停止扫描:</p>
<ol>
<li>当前文件大小 &lt; 比当前文件新的所有文件大小总和 * ratio.<br>其中ratio是一个可变的比例,在高峰期ratio为1.2,受参数<font color="red">hbase.hstore.compaction.ratio</font>控制,非高峰期ratio为5,受参数<font color="red">hbase.hstore.compaction.ratio.offpeak</font>控制,也就是非高峰期允许compact更大的文件.</li>
<li>当前所剩候选文件数 &lt;= hbase.hstore.compaction.min.</li>
</ol>
<h5 id="参数解释-2"><a href="#参数解释-2" class="headerlink" title="参数解释"></a>参数解释</h5><p>hbase.hstore.compaction.ratio<br>默认值为1.2F,对于Minor Compaction,这个比率用于确定给定的HFile文件大于等于<code>hbase.hstore.compaction.min.size</code>情况下是否适合进行Compaction.<br>它的作用是限制对较大的HFile的进行Compaction.<br>推荐取值范围为1.0和1.4之间的中等值.<br>对于大多数情况,默认值是合适的.</p>
<p>hbase.hstore.compaction.ratio.offpeak<br>默认值为5.0F,工作原理同<code>hbase.hstore.compaction.ratio</code>参数,但是该值用于非高峰时间段内的Mimor Compaction.<br>默认情况下非高峰时间段是关闭的,因此该参数的值不会生效.</p>
<p>hbase.offpeak.start.hour<br>默认值为-1,非高峰时间的开始,表示为0到23之间的整数.<br>设置为-1禁用非峰值,即默认禁用.</p>
<p>hbase.offpeak.end.hour<br>默认值为-1,非高峰时间的结束,表示为0到23之间的整数.<br>设置为-1禁用非峰值,即默认禁用.</p>
<p>hbase.hstore.compaction.min<br>默认为3,在运行Compaction之前必须符合Compaction条件的HFile文件的最小数量.<br>调优该参数的的目的是避免产生太多需要Compaction的小HFile文件.<br>将该值设置为2将导致每次在一个Store中有两个HFile文件时进行Minor Compaction,这可能不合适.<br>如果您将该值设置得过高,则需要相应地调整所有其他值.<br>对于大多数情况,默认值是合适的.<br>在HBase的早期版本中,该参数被命名为<code>hbase.hstore.compactionThreshold</code>.</p>
<p>hbase.hstore.compaction.min.size<br>默认值为134217728,即128M,小于此大小的HFile文件将始终适合进行Minor Compaction.<br>大于等于此大小的HFiles文件由<code>hbase.hstore.compact.ratio</code>评估,以确定它们是否符合条件.</p>
<p>停止扫描后,待合并文件就选择出来了,即当前扫描文件以及比它更新的所有文件.</p>
<p>实际情况下的RatioBasedCompactionPolicy算法效果很差,经常引发大面积的 Minor Compaction,而Minor Compaction过程中不能写入数据,经常因为Compaction而影响IO.</p>
<h4 id="ExploringCompactionPolicy"><a href="#ExploringCompactionPolicy" class="headerlink" title="ExploringCompactionPolicy"></a>ExploringCompactionPolicy</h4><p>该策略思路基本和 RatioBasedCompactionPolicy 相同,不同的是,Ratio策略在找到一个合适的文件集合之后就停止扫描了,而Exploring策略会记录所有合适的文件集合,并在这些文件集合中寻找最优解.<br>最优解可以理解为:待合并文件数最多或者待合并文件数相同的情况下文件较小,这样有利于减少Compaction带来的IO消耗.</p>
<h5 id="修改待合并文件的挑选条件"><a href="#修改待合并文件的挑选条件" class="headerlink" title="修改待合并文件的挑选条件"></a>修改待合并文件的挑选条件</h5><p>不再武断地认为,某个文件满足条件就把更加新的文件全部合并进去.<br>确切地说,现在的遍历不强调顺序性了,是把所有的文件都遍历一遍之后每一个文件都去考虑.<br>如果当前文件大小小于最小Compaction大小,则直接进入待合并列表.<br>最小合并大小的配置项:<code>hbase.hstore.compaction.min.size</code>.<br>如果没设定该配置项,则使用<code>hbase.hregion.memstore.flush.size</code>.</p>
<p>如果不小于最小Compaction大小,则根据&quot;<font color="red">该文件大小 &lt; (所有文件大小总和 - 该文件大小) * ratio</font>&quot;条件判断符合条件而进入待合并列表的文件.</p>
<h5 id="以组合作为计算单元"><a href="#以组合作为计算单元" class="headerlink" title="以组合作为计算单元"></a>以组合作为计算单元</h5><p>新的算法不再按文件为单元进行比较了,而是挑出多个文件组合.<br>挑选组合的条件是:<br>被挑选的文件必须能通过以上提到的筛选条件,并且组合内含有的文件数必须大于<code>hbase.hstore.compaction.min</code>,小于<code>hbase.hstore.compaction.max</code>.</p>
<p>文件太少了没必要合并,还浪费资源.文件太多了太消耗资源,怕机器受不了.</p>
<p>挑选完组合后,比较哪个文件组合包含的文件更多,就合并哪个组合.<br>如果出现平局,就挑选那个文件尺寸总和更小的组合.</p>
<h3 id="挑选合适的执行线程池"><a href="#挑选合适的执行线程池" class="headerlink" title="挑选合适的执行线程池"></a>挑选合适的执行线程池</h3><p>HBase实现中有一个专门的类<code>org.apache.hadoop.hbase.regionserver.CompactSplit</code>负责接收Compaction请求和Split请求,而且为了能够独立处理这些请求,这个类内部构造了三个线程池:<br>longCompactions/shortCompactions/splits.<br>splits线程池负责处理所有的split请求,longCompactions用来处理大型Compaction,shortCompactions负责处理小型Compaction.</p>
<p>这里需要明确:</p>
<ol>
<li>上述设计目的是能够将请求独立处理,提高系统的处理性能.</li>
<li>大型Compaction并不是Major Compaction,小型Compaction 也并不是MinorCompaction.</li>
<li>HBase 定义了一个阈值<code>hbase.regionserver.thread.compaction.throttle</code>,如果Compaction合并的总文件大小超过这个阈值就认为是大型Compaction,否则认为是小型Compaction.<br>大Compaction会分配给longCompactions线程池处理,小Compaction会分配给shortCompactions线程池处理.</li>
<li>longCompactions线程池和shortCompactions线程池默认都只有一个线程,用户可以通过参数<code>hbase.regionserver.thread.compaction.large</code> 和<code>hbase.regionserver.thread.compaction.small</code>进行配置.</li>
</ol>
<h4 id="参数解释-3"><a href="#参数解释-3" class="headerlink" title="参数解释"></a>参数解释</h4><p>hbase.regionserver.thread.compaction.throttle<br>默认值为2684354560,即2G,Compaction有两个不同的线程池,一个用于大型Compaction,另一个用于小型Compaction.<br>这有助于保持精简表(如hbase:meta)的快速Compaction.<br>如果Compaction大于此阈值,则将进入大型Compaction池.<br>在大多数情况下,默认值是合适的.<br>默认值是<code>2 * hbase.hstore.compaction.max * hbase.hregion.memstore.flush.size</code>.</p>
<h3 id="HFile文件Compaction执行"><a href="#HFile文件Compaction执行" class="headerlink" title="HFile文件Compaction执行"></a>HFile文件Compaction执行</h3><p>选出待合并的HFile集合,再选出合适的处理线程,接下来执行合并流程.</p>
<p>合并流程主要分为如下几步:</p>
<ol>
<li>分别读出待合并 HFile 文件的 KeyValue,进行归并排序处理,之后写到region目录下的.tmp目录下新创建HFile文件中.<br>以下两种数据不会被读取出来:</li>
</ol>
<ul>
<li>如果数据过期了(达到 TTL 所规定的时间),那么这些数据不会被读取出来.</li>
<li>如果是Major Compaction,那么数据带了墓碑标记也不会被读取出来.</li>
</ul>
<ol start="2">
<li>将<code>/&lt;Region&gt;/.tmp</code>目录下新创建的HFile文件移动到对应列族数据目录.</li>
<li>将Compaction的输入文件路径和输出文件路径封装为KV写入HLog日志,并打上 Compaction标记,最后强制执行sync.</li>
<li>将对应列族数据目录下的Compaction输入文件全部删除.</li>
</ol>
<p>上述4个步骤看起来简单,但实际是很严谨的,具有很强的容错性和幂等性:</p>
<ol>
<li>如果 RegionServer 在步骤2之前发生异常,本次 Compaction 会被认定为失败,如果继续进行同样的 Compaction,上次异常对接下来的 Compaction 不会有任何影响,也不会对读写有任何影响.<br>唯一的影响就是多了一份多余的数据.</li>
<li>如果 RegionServer 在步骤2之后/步骤3之前发生异常,同样,仅仅会多一份冗余数据.</li>
<li>如果 RegionServer 在步骤3之后/步骤4之前发生异常,RegionServer 在重新打开 Region 之后首先会从 HLog 中看到标有 Compaction 的日志,因为此时输入文件和输出文件已经持久化到 HDFS,因此只需要根据 HLog 移除 Compaction 输入文件即可.</li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="为什么只有Major-Compaction可以真正删除数据"><a href="#为什么只有Major-Compaction可以真正删除数据" class="headerlink" title="为什么只有Major Compaction可以真正删除数据?"></a>为什么只有Major Compaction可以真正删除数据?</h3><p>其实HBase一直拖到Major Compaction的时候才真正把带墓碑标记的数据删掉,并不是因为性能要求,而是之前真的做不到.<br>HBase是建立在HDFS这种只有增加删除而没有修改的文件系统之上的,所以就连用户删除这个动作,在底层都是由新增实现的:</p>
<ol>
<li>用户增加一条数据就在 HFile 上增加一条 KeyValue,类型是 PUT.</li>
<li>用户删除一条数据还是在 HFile 上增加一条 KeyValue,类型是 DELETE,这就是墓碑标记.<br>所以墓碑标记没有什么神秘的,它也就只是另外一个 KeyValue,只不过 value 没有值,而类型是 DELETE.</li>
</ol>
<p>现在会遇到一个问题:<br>当用户删除数据的时候之前的数据已经被刷写到磁盘上的另外一个HFile了.<br>这种情况很常见,也就是说,墓碑标记和原始数据这两个KeyValue 压根就不在同一个HFile上.</p>
<p>在查询的时候Scan指针其实是把所有的HFile都看过了一遍,它知道了有这条数据,也知道它有墓碑标记,而在返回数据的时候选择不把数据返回给用户,这样在用户的Scan操作看来这条数据就是被删掉了.<br>如果带上RAW=&gt;true参数来Scan,就可以查询到这条被打上墓碑标记的数据.</p>
<h3 id="为什么达到TTL的数据可以被Minor-Compaction删除"><a href="#为什么达到TTL的数据可以被Minor-Compaction删除" class="headerlink" title="为什么达到TTL的数据可以被Minor Compaction删除?"></a>为什么达到TTL的数据可以被Minor Compaction删除?</h3><p>这是因为当数据达到TTL的时候,并不需要额外的一个KeyValue来记录.<br>Compaction时创建的Scan在查询数据的时候,根据&quot;当前时间now - cell的timestamp &gt; TTL&quot;公式来判断cell是否过期.</p>
<p>如果过期了就不返回这条数据.<br>这样当Compaction完成后,过期的数据因为没有被写入新文件,自然就消失了.</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>次要压缩文件选择.<br>配置如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hbase.hstore.compaction.ratio &#x3D; 1.0f</span><br><span class="line">hbase.hstore.compaction.min &#x3D; 3 (files)</span><br><span class="line">hbase.hstore.compaction.max &#x3D; 5 (files)</span><br><span class="line">hbase.hstore.compaction.min.size &#x3D; 10 (bytes)</span><br><span class="line">hbase.hstore.compaction.max.size &#x3D; 1000 (bytes)</span><br></pre></td></tr></table></figure>

<h3 id="基本示例"><a href="#基本示例" class="headerlink" title="基本示例"></a>基本示例</h3><p>存在以下 StoreFiles:100/50/23/12/12 个字节(从旧到新).<br>使用上述参数,将选择进行次要压缩的文件为 23/12/12.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">100 → 否,因为 sum(50, 23, 12, 12) * 1.0 &#x3D; 97.</span><br><span class="line">50 → 否,因为 sum(23, 12, 12) * 1.0 &#x3D; 47.</span><br><span class="line">23 → 是的,因为 sum(12, 12) * 1.0 &#x3D; 24.</span><br><span class="line">12 → 是,因为之前的文件已经被包含进来,并且因为这没有超过最大文件限制 5</span><br><span class="line">12 → 是,因为之前的文件已包含在内,并且因为这没有超过最大文件限制 5.</span><br></pre></td></tr></table></figure>

<h3 id="没有足够的文件来压缩"><a href="#没有足够的文件来压缩" class="headerlink" title="没有足够的文件来压缩"></a>没有足够的文件来压缩</h3><p>存在以下 StoreFiles:100/25/12/12 个字节(从旧到新).<br>使用上述参数,不会启动压缩.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">100 → 否,因为 sum(25, 12, 12) * 1.0 &#x3D; 47</span><br><span class="line">25 → 否,因为 sum(12, 12) * 1.0 &#x3D; 24</span><br><span class="line">12 → No. Candidate 因为 sum(12) * 1.0 &#x3D; 12,只有 2 个文件需要压缩,小于阈值 3</span><br><span class="line">12 → No. Candidate 因为之前的 StoreFile 是,但是没有足够的文件来压缩</span><br></pre></td></tr></table></figure>

<h3 id="限制要压缩的文件"><a href="#限制要压缩的文件" class="headerlink" title="限制要压缩的文件"></a>限制要压缩的文件</h3><p>存在以下 StoreFiles:各 7/6/5/4/3/2/1 个字节(从旧到新).<br>使用上述参数,将选择进行次要压缩的文件为 7/6/5/4/3.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">7 → 是的,因为 sum(6, 5, 4, 3, 2, 1) * 1.0 &#x3D; 21.此外,7 小于最小大小</span><br><span class="line">6 → 是的,因为 sum(5, 4, 3, 2, 1) * 1.0 &#x3D; 15.此外,6 小于最小大小.</span><br><span class="line">5 → 是的,因为 sum(4, 3, 2, 1) * 1.0 &#x3D; 10.此外,5 小于最小大小.</span><br><span class="line">4 → 是的,因为 sum(3, 2, 1) * 1.0 &#x3D; 6.此外,4 小于最小大小.</span><br><span class="line">3 → 是的,因为 sum(2, 1) * 1.0 &#x3D; 3.此外,3 小于最小大小.</span><br><span class="line">2 → No. Candidate 因为选择了上一个文件并且 2 小于最小大小,但是已经达到要压缩的最大文件数.</span><br><span class="line">1 → No. Candidate 因为选择了上一个文件并且 1 小于最小大小,但是已经达到要压缩的最大文件数.</span><br></pre></td></tr></table></figure>

<h2 id="条纹压实"><a href="#条纹压实" class="headerlink" title="条纹压实"></a>条纹压实</h2><p>Stripe 压缩是 HBase 0.98 中添加的一项实验性功能,旨在改进大区域或非均匀分布的行键的压缩.<br>为了实现更小/更细粒度的压缩,一个区域内的 StoreFiles 为该区域的几个行键子范围或&quot;条带&quot;单独维护.<br>条带对 HBase 的其余部分是透明的,因此对 HFile 或数据的其他操作无需修改即可工作.</p>
<p>条带压缩改变 HFile 布局,在区域内创建子区域.<br>这些子区域更容易压缩,并且应该导致更少的主要压缩.<br>这种方法减轻了较大区域的一些挑战.</p>
<p>Stripe 压缩与Compaction完全兼容,并与 ExploringCompactionPolicy 或 RatioBasedCompactionPolicy 结合使用.<br>可以为已有的表启用,以后如果禁用,表会继续正常运行.</p>
<h3 id="何时使用条纹压缩"><a href="#何时使用条纹压缩" class="headerlink" title="何时使用条纹压缩"></a>何时使用条纹压缩</h3><p>如果您有以下任一情况,请考虑使用条带压缩:</p>
<ol>
<li>大区域.<br>您可以获得较小区域的积极影响,而无需额外的 MemStore 开销和区域管理开销.</li>
<li>非统一键,例如键中的时间维度.<br>只有接收新密钥的条带需要压缩.<br>旧数据不会经常压缩,如果有的话</li>
</ol>
<h4 id="性能改进"><a href="#性能改进" class="headerlink" title="性能改进"></a>性能改进</h4><p>性能测试表明,读性能有所提升,读写性能波动性大大降低.<br>在大型非统一行键区域(例如哈希前缀时间戳键)上可以看到整体的长期性能改进.<br>这些性能提升在已经很大的表上最为显着.<br>性能改进可能会扩展到区域拆分.</p>
<h4 id="启用条带压缩"><a href="#启用条带压缩" class="headerlink" title="启用条带压缩"></a>启用条带压缩</h4><p>您可以为表或列族启用条带压缩,方法是将其设置<code>hbase.hstore.engine.class</code>为<code>org.apache.hadoop.hbase.regionserver.StripeStoreEngine</code>.<br>您还需要将<code>hbase.hstore.blockingStoreFiles</code>设置为一个较大的数字,例如 100(而不是默认值 10).</p>
<blockquote>
<p>启用条带压缩</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;orders_table&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;org.apache.hadoop.hbase.regionserver.StripeStoreEngine&#x27;, &#x27;hbase.hstore.blockingStoreFiles&#x27; =&gt; &#x27;100&#x27;&#125;</span><br><span class="line">alter &#x27;orders_table&#x27;, &#123;NAME =&gt; &#x27;blobs_cf&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;org.apache.hadoop.hbase.regionserver.StripeStoreEngine&#x27;, &#x27;hbase.hstore.blockingStoreFiles&#x27; =&gt; &#x27;100&#x27;&#125;&#125;</span><br><span class="line">create &#x27;orders_table&#x27;, &#x27;blobs_cf&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;org.apache.hadoop.hbase.regionserver.StripeStoreEngine&#x27;, &#x27;hbase.hstore.blockingStoreFiles&#x27; =&gt; &#x27;100&#x27;&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>禁用条带压缩</p>
</blockquote>
<p>将hbase.hstore.engine.class选项设置为 nil 或org.apache.hadoop.hbase.regionserver.DefaultStoreEngine. 任一选项都具有相同的效果.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;orders_table&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;rg.apache.hadoop.hbase.regionserver.DefaultStoreEngine&#x27;&#125;</span><br></pre></td></tr></table></figure>

<p>当您在以任何方式更改存储引擎后启用大表时,可能会在大多数区域执行主要压缩.<br>这在新表上不是必需的.</p>
<h4 id="配置条带压缩"><a href="#配置条带压缩" class="headerlink" title="配置条带压缩"></a>配置条带压缩</h4><p>条带压缩的每个设置都应该在表或列族级别配置.<br>如果使用 HBase shell,一般命令模式如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#39;orders_table&#39;, CONFIGURATION &#x3D;&gt; &#123;&#39;key&#39; &#x3D;&gt; &#39;value&#39;, ..., &#39;key&#39; &#x3D;&gt; &#39;value&#39;&#125;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="区域和条带大小"><a href="#区域和条带大小" class="headerlink" title="区域和条带大小"></a>区域和条带大小</h3><p>您可以根据区域大小配置条带大小.<br>默认情况下,您的新区域将从一个条纹开始.<br>在条带变得太大(16 x MemStore 刷新大小)后的下一次压缩中,它被分成两个条带.<br>条纹分裂随着区域的增长而继续,直到区域大到可以分裂为止.</p>
<p>您可以针对自己的数据改进此模式.<br>一个好的规则是针对至少 1 GB 的条带大小,以及大约 8-12 个条带用于统一行键.<br>例如,如果您的区域是 30 GB,则 12 x 2.5 GB 条带可能是一个很好的起点.</p>
<h3 id="条带大小设置"><a href="#条带大小设置" class="headerlink" title="条带大小设置"></a>条带大小设置</h3><h4 id="hbase-store-stripe-initialStripeCount"><a href="#hbase-store-stripe-initialStripeCount" class="headerlink" title="hbase.store.stripe.initialStripeCount"></a>hbase.store.stripe.initialStripeCount</h4><p>启用条带压缩时要创建的条带数.<br>您可以按如下方式使用它:</p>
<ol>
<li>对于相对统一的行键,如果您从上面知道大概的目标条带数,则可以通过从几个条带(2/5/10/... )开始来避免一些拆分开销.<br>如果早期数据不能代表整个行键分布,那么效率就不会那么高.</li>
<li>对于具有大量数据的现有表,此设置将有效地预拆分您的条带.</li>
<li>对于诸如散列前缀顺序键之类的键,每个区域有多个散列前缀,预拆分可能是有意义的.</li>
</ol>
<h4 id="hbase-store-stripe-sizeToSplit"><a href="#hbase-store-stripe-sizeToSplit" class="headerlink" title="hbase.store.stripe.sizeToSplit"></a>hbase.store.stripe.sizeToSplit</h4><p>条带在分裂前增长的最大尺寸.<br>根据上述大小考虑因素,将其与<code>hbase.store.stripe.splitPartCount</code>结合使用以控制目标条带大小 (sizeToSplit = splitPartsCount * target stripe size).</p>
<h4 id="hbase-store-stripe-splitPartCount"><a href="#hbase-store-stripe-splitPartCount" class="headerlink" title="hbase.store.stripe.splitPartCount"></a>hbase.store.stripe.splitPartCount</h4><p>拆分条带时要创建的新条带数.<br>默认值为 2,适用于大多数情况.<br>对于非统一行键,您可以尝试将数量增加到 3 或 4,以将到达的更新隔离到更窄的区域切片中,而不需要额外的拆分.</p>
<h3 id="MemStore-大小设置"><a href="#MemStore-大小设置" class="headerlink" title="MemStore 大小设置"></a>MemStore 大小设置</h3><p>默认情况下,flush 从一个 MemStore 中创建多个文件,根据现有的 stripe boundaries 和 row keys 进行 flush.<br>这种方法最大限度地减少了写入放大,但如果 MemStore 很小并且有很多条带,则可能不受欢迎,因为文件会太小.</p>
<p>在这种情况下,您可以设置hbase.store.stripe.compaction.flushToL0为true.<br>这将导致 MemStore 刷新创建单个文件.<br>当至少hbase.store.stripe.compaction.minFilesL0有这样的文件(默认情况下为 4 个)累积时,它们将被压缩为条带文件.</p>
<h3 id="正常压缩配置和条带压缩"><a href="#正常压缩配置和条带压缩" class="headerlink" title="正常压缩配置和条带压缩"></a>正常压缩配置和条带压缩</h3><p>适用于正常压缩的所有设置(请参阅压缩算法使用的参数)适用于条带压缩.<br>例外情况是最小和最大文件数,默认情况下将其设置为更高的值,因为条带中的文件更小.<br>要控制条带压缩的这些,请使用<code>hbase.store.stripe.compaction.minFiles</code> and <code>hbase.store.stripe.compaction.maxFiles</code>,而不是<code>hbase.hstore.compaction.min</code> and <code>hbase.hstore.compaction.max</code>.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hbase/" rel="tag"># hbase</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/08/03/hbase%E5%86%85%E5%AD%98%E8%A7%84%E5%88%92/" rel="prev" title="hbase内存规划">
                  <i class="fa fa-chevron-left"></i> hbase内存规划
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/03/hbase%20sequenceId/" rel="next" title="hbase sequenceId">
                  hbase sequenceId <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
