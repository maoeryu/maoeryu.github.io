<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="当 MemStore 达到给定大小 (hbase.hregion.memstore.flush.size) 时,它会将其内容刷新到 StoreFile.StoreFiles 的数量随着时间的推移而增加.压缩是一种操作,它通过将存储文件合并在一起来减少存储中的存储文件数量,以提高读取操作的性能.执行压缩可能会占用大量资源,并且会根据许多因素帮助或阻碍性能.">
<meta property="og:type" content="article">
<meta property="og:title" content="hbase region compaction">
<meta property="og:url" content="https://maoeryu.github.io/2022/08/03/hbase%20region%20compaction/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="当 MemStore 达到给定大小 (hbase.hregion.memstore.flush.size) 时,它会将其内容刷新到 StoreFile.StoreFiles 的数量随着时间的推移而增加.压缩是一种操作,它通过将存储文件合并在一起来减少存储中的存储文件数量,以提高读取操作的性能.执行压缩可能会占用大量资源,并且会根据许多因素帮助或阻碍性能.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-08-02T16:00:00.000Z">
<meta property="article:modified_time" content="2023-02-24T08:04:35.667Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="hbase">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://maoeryu.github.io/2022/08/03/hbase%20region%20compaction/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>hbase region compaction | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">基本原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E4%BD%9C%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">核心作用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E4%BD%9C%E7%94%A8"><span class="nav-number">2.1.</span> <span class="nav-text">副作用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="nav-number">3.</span> <span class="nav-text">基本流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A6%E5%8F%91%E6%97%B6%E6%9C%BA"><span class="nav-number">3.1.</span> <span class="nav-text">触发时机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MemStore-Flush"><span class="nav-number">3.1.1.</span> <span class="nav-text">MemStore Flush</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B%E5%91%A8%E6%9C%9F%E6%80%A7%E6%A3%80%E6%9F%A5"><span class="nav-number">3.1.2.</span> <span class="nav-text">后台线程周期性检查</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A-1"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="nav-number">3.1.3.</span> <span class="nav-text">手动触发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%85%E5%90%88%E5%B9%B6HFile%E9%9B%86%E5%90%88%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5"><span class="nav-number">3.2.</span> <span class="nav-text">待合并HFile集合选择策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RatioBasedCompactionPolicy"><span class="nav-number">3.2.1.</span> <span class="nav-text">RatioBasedCompactionPolicy</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A-2"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ExploringCompactionPolicy"><span class="nav-number">3.2.2.</span> <span class="nav-text">ExploringCompactionPolicy</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E5%BE%85%E5%90%88%E5%B9%B6%E6%96%87%E4%BB%B6%E7%9A%84%E6%8C%91%E9%80%89%E6%9D%A1%E4%BB%B6"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">修改待合并文件的挑选条件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A5%E7%BB%84%E5%90%88%E4%BD%9C%E4%B8%BA%E8%AE%A1%E7%AE%97%E5%8D%95%E5%85%83"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">以组合作为计算单元</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E9%80%89%E5%90%88%E9%80%82%E7%9A%84%E6%89%A7%E8%A1%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0"><span class="nav-number">3.3.</span> <span class="nav-text">挑选合适的执行线程池</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A-3"><span class="nav-number">3.3.1.</span> <span class="nav-text">参数解释</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HFile%E6%96%87%E4%BB%B6Compaction%E6%89%A7%E8%A1%8C"><span class="nav-number">3.4.</span> <span class="nav-text">HFile文件Compaction执行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96"><span class="nav-number">4.</span> <span class="nav-text">其他</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%88%A0%E9%99%A4"><span class="nav-number">4.1.</span> <span class="nav-text">压缩和删除</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E5%92%8C%E7%89%88%E6%9C%AC"><span class="nav-number">4.2.</span> <span class="nav-text">压缩和版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%8E%8B%E7%BC%A9%E4%BC%9A%E5%BD%B1%E5%93%8D%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C"><span class="nav-number">4.3.</span> <span class="nav-text">主要压缩会影响查询结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AA%E6%9C%89Major-Compaction%E5%8F%AF%E4%BB%A5%E7%9C%9F%E6%AD%A3%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE"><span class="nav-number">4.4.</span> <span class="nav-text">为什么只有Major Compaction可以真正删除数据?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BE%BE%E5%88%B0TTL%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E4%BB%A5%E8%A2%ABMinor-Compaction%E5%88%A0%E9%99%A4"><span class="nav-number">4.5.</span> <span class="nav-text">为什么达到TTL的数据可以被Minor Compaction删除?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%90%E5%88%B6%E5%8E%8B%E7%BC%A9%E7%9A%84%E9%80%9F%E5%BA%A6"><span class="nav-number">4.6.</span> <span class="nav-text">限制压缩的速度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B"><span class="nav-number">5.</span> <span class="nav-text">示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%A4%BA%E4%BE%8B"><span class="nav-number">5.1.</span> <span class="nav-text">基本示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B2%A1%E6%9C%89%E8%B6%B3%E5%A4%9F%E7%9A%84%E6%96%87%E4%BB%B6%E6%9D%A5%E5%8E%8B%E7%BC%A9"><span class="nav-number">5.2.</span> <span class="nav-text">没有足够的文件来压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%90%E5%88%B6%E8%A6%81%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%96%87%E4%BB%B6"><span class="nav-number">5.3.</span> <span class="nav-text">限制要压缩的文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%A1%E7%BA%B9%E5%8E%8B%E5%AE%9E"><span class="nav-number">6.</span> <span class="nav-text">条纹压实</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8%E6%9D%A1%E7%BA%B9%E5%8E%8B%E7%BC%A9"><span class="nav-number">6.1.</span> <span class="nav-text">何时使用条纹压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E6%94%B9%E8%BF%9B"><span class="nav-number">6.1.1.</span> <span class="nav-text">性能改进</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E7%94%A8%E6%9D%A1%E5%B8%A6%E5%8E%8B%E7%BC%A9"><span class="nav-number">6.1.2.</span> <span class="nav-text">启用条带压缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%9D%A1%E5%B8%A6%E5%8E%8B%E7%BC%A9"><span class="nav-number">6.1.3.</span> <span class="nav-text">配置条带压缩</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8C%BA%E5%9F%9F%E5%92%8C%E6%9D%A1%E5%B8%A6%E5%A4%A7%E5%B0%8F"><span class="nav-number">6.2.</span> <span class="nav-text">区域和条带大小</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9D%A1%E5%B8%A6%E5%A4%A7%E5%B0%8F%E8%AE%BE%E7%BD%AE"><span class="nav-number">6.3.</span> <span class="nav-text">条带大小设置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hbase-store-stripe-initialStripeCount"><span class="nav-number">6.3.1.</span> <span class="nav-text">hbase.store.stripe.initialStripeCount</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hbase-store-stripe-sizeToSplit"><span class="nav-number">6.3.2.</span> <span class="nav-text">hbase.store.stripe.sizeToSplit</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hbase-store-stripe-splitPartCount"><span class="nav-number">6.3.3.</span> <span class="nav-text">hbase.store.stripe.splitPartCount</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MemStore-%E5%A4%A7%E5%B0%8F%E8%AE%BE%E7%BD%AE"><span class="nav-number">6.4.</span> <span class="nav-text">MemStore 大小设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%B8%B8%E5%8E%8B%E7%BC%A9%E9%85%8D%E7%BD%AE%E5%92%8C%E6%9D%A1%E5%B8%A6%E5%8E%8B%E7%BC%A9"><span class="nav-number">6.5.</span> <span class="nav-text">正常压缩配置和条带压缩</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">221</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2022/08/03/hbase%20region%20compaction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hbase region compaction
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-08-03 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-03T00:00:00+08:00">2022-08-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-02-24 16:04:35" itemprop="dateModified" datetime="2023-02-24T16:04:35+08:00">2023-02-24</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>当 MemStore 达到给定大小 (hbase.hregion.memstore.flush.size) 时,它会将其内容刷新到 StoreFile.<br>StoreFiles 的数量随着时间的推移而增加.<br>压缩是一种操作,它通过将存储文件合并在一起来减少存储中的存储文件数量,以提高读取操作的性能.<br>执行压缩可能会占用大量资源,并且会根据许多因素帮助或阻碍性能.</p>
<span id="more"></span>
<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>Compaction 是从一个 Region 的一个 Store 中选择部分 HFile 文件进行合并,即Compaction是以Store为单位的.</p>
<blockquote>
<p>合并原理:<br>先从这些待合并的数据文件中依次读出 KeyValue,再由小到大排序后写入一个新的文件.<br>之后,这个新生成的文件就会取代之前已合并的所有文件对外提供服务.</p>
</blockquote>
<p>HBase 根据合并规模将 Compaction 分为两类:<font color="red">Minor Compaction</font> 和 <font color="red">Major Compaction</font>.</p>
<p>Minor Compaction:<br>选取部分小的/相邻的HFile,将它们合并成一个更大的HFile.<br>在这个过程中达到TTL的数据会被移除,但是被手动删除的数据不会被移除.<br>这种合并触发频率较高.</p>
<p>Major Compaction:<br><font color="red">将一个Store中所有的HFile合并成一个HFile</font>,<br>这个过程还会完全清理三类无意义数据:<font color="red">被删除的数据/TTL过期数据/版本号超过设定版本号的数据</font>.<br>这种合并触发频率较低,默认为<font color="red">7天一次</font>.</p>
<h2 id="核心作用"><a href="#核心作用" class="headerlink" title="核心作用"></a>核心作用</h2><p>在HBase的体系架构下,Compaction有以下核心作用:</p>
<ol>
<li>合并小文件,减少文件数,稳定随机读延迟.</li>
<li>提高数据的本地化率.</li>
<li>清除无效数据,减少数据存储量.</li>
</ol>
<p>随着HFile文件数不断增多,查询可能需要越来越多的IO操作,读取延迟必然会越来越大.</p>
<p>执行Compaction会使文件个数基本稳定,进而读取IO的次数会比较稳定,延迟就会稳定在一定范围.<br>从图上看,虽然数据读取延迟相比上图稳定了一些,但是读取响应时间有了很大的毛刺,这是因为Compaction在执行的时候占用系统资源导致业务读取性能受到一定波及.</p>
<p>Compaction 的一个重要作用是提高数据的本地化率.<br>本地化率越高,在 HDFS 上访问数据时延迟就越小.<br>相反,本地化率越低,访问数据就可能大概率需要通过网络访问,延迟必然会比较大.</p>
<p>Compaction 合并小文件的同时会将落在远程 DataNode 上的数据读取出来重新写入大文件,合并后的大文件在当前 DataNode 节点上有一个副本,因此可以提高数据的本地化率.<br>极端情况下,Major Compaction 可以将当前 Region 的本地化率提高到100%.<br>这也是最常用的一种提高数据本地化率的方法.</p>
<h3 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h3><p>Compaction 在执行过程中有个比较明显的副作用:<br>Compaction 操作重写文件会带来很大的带宽压力以及短时间 IO 压力.<br>这点比较容易理解,要将小文件的数据读出来需要 IO,很多小文件数据跨网络传输需要带宽,读出来之后又要写成一个大文件,因为是三副本写入,必然需要网络开销,当然写入 IO 开销也避免不了.<br>因此可以认为,Compaction 就是使用短时间的 IO 消耗以及带宽消耗换取后续查询的低延迟.</p>
<h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>HBase中Compaction只有在特定的触发条件才会执行,一旦触发,HBase会将该Compaction交由一个独立的线程处理,该线程首先会从对应Store中选择合适的HFile文件进行合并,这一步是整个Compaction的核心.<br>选出待合并的文件后,HBase会根据这些HFile文件总大小挑选对应的线程池处理,最后对这些文件执行具体的合并操作.</p>
<h3 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h3><p>HBase 中触发 Compaction 的时机有很多,最常见的时机有如下三种:MemStore Flush/后台线程周期性检查/手动触发.</p>
<h4 id="MemStore-Flush"><a href="#MemStore-Flush" class="headerlink" title="MemStore Flush"></a>MemStore Flush</h4><p>应该说 Compaction 操作的源头来自 flush 操作,MemStore Flush 会产生 HFile,文件越来越多就需要执行Compaction.<br>因此在每次执行完 flush 操作之后,都会对当前 Store 中的文件数进行判断,一旦 Store 中总文件数大于 <font color="blue">hbase.hstore.compactionThreshold</font>,就会触发 Compaction.<br>需要说明的是,Compaction 都是以 Store 为单位进行的,而在 flush 触发条件下,整个 Region 的所有 Store 都会执行 compact 检查,所以一个 Region 有可能会在短时间内执行多次 Compaction.</p>
<h5 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h5><p>hbase.hstore.compactionThreshold<br>默认值为3,如果在任何一个Store中存在超过这个数量的HFile,运行Compaction将所有HFile重写为单个HFile.<br>将该参数设置成较大的值会延迟Compaction,但是当Compaction运行时,则需要更长的时间,新版本参数为<code>hbase.hstore.compaction.min</code>.</p>
<h4 id="后台线程周期性检查"><a href="#后台线程周期性检查" class="headerlink" title="后台线程周期性检查"></a>后台线程周期性检查</h4><p>RegionServer 会在后台启动一个线程 <font color="blue">CompactionChecker</font>,定期触发检查对应 Store 是否需要执行 Compaction,检查周期为 <font color="blue">hbase.server.thread.wakefrequency * hbase.server.compactchecker.interval.multiplier</font>,大概2小时40分左右执行一次.</p>
<p>和 MemStore flush 不同的是,该线程优先检查 Store 中总文件数是否大于阈值 <code>hbase.hstore.compactionThreshold</code>,一旦大于阀值就会触发 Compaction.如果不大于阀值,接着检查是否满足 Major Compaction 条件.<br>简单来说,如果当前 Store 中 HFile 的最早更新时间早于某个值 mcTime,就会触发 Major Compaction.</p>
<p>mcTime 是一个浮动值,浮动区间默认为<code>[7-7×0.5,7+7×0.5]</code>,其中7为参数 <font color="blue">hbase.hregion.majorcompaction</font> 的值,0.5为参数 <font color="blue">hbase.hregion.majorcompaction.jitter</font> 的值,可见默认在7天左右就会执行一次 Major Compaction.</p>
<h5 id="参数解释-1"><a href="#参数解释-1" class="headerlink" title="参数解释"></a>参数解释</h5><p>hbase.server.thread.wakefrequency<br>默认值为10000ms,作为服务线程(如日志roller)的睡眠时间间隔.</p>
<p>hbase.server.compactchecker.interval.multiplier<br>默认值为1000,用于决定周期任务频率的值,以确定是否需要Compaction.<br>通常情况下,Compaction是在一些事件(如memstore刷新)之后执行的,但是如果Region在一段时间内没有收到很多写操作,或者由于不同的Compaction策略,可能需要定期检查它.</p>
<p>hbase.hregion.majorcompaction<br>默认值为604800000ms,即7天,表示两次Major Compaction之间的时间间隔.<br>设置为0可以禁用基于时间的自动Major Compaction,但手动触发和基于Store中HFile文件数量的Major Compaction仍将运行.</p>
<p>hbase.hregion.majorcompaction.jitter<br>默认值为0.5,这个值乘以<code>hbase.hregion.majorcompaction</code>使Compaction在给定的时间窗口中以某种随机的时间开始.<br>该参数的值越小,Major Compaction就会越接近<code>hbase.hregion.majorcompaction</code>区间.</p>
<h4 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h4><p>一般来讲,手动触发 Compaction 大多是为了执行 Major Compaction.</p>
<p>使用手动触发 Major Compaction 的原因通常有三个,</p>
<ol>
<li>很多业务担心自动 Major Compaction 影响读写性能,因此会选择低峰期手动触发.</li>
<li>在执行完 alter 操作之后希望立刻生效,手动触发 Major Compaction.</li>
<li>HBase 管理员发现硬盘容量不够时手动触发 Major Compaction,删除大量过期数据.</li>
</ol>
<h3 id="待合并HFile集合选择策略"><a href="#待合并HFile集合选择策略" class="headerlink" title="待合并HFile集合选择策略"></a>待合并HFile集合选择策略</h3><p>选择合适的文件进行合并是整个 Compaction 的核心,因为合并文件的大小及其当前承载的 IO 数直接决定了 Compaction 的效果以及对整个系统其他业务的影响程度.<br>理想的情况是,选择的待合并 HFile 文件集合承载了大量 IO 请求但是文件本身很小,这样Compaction 本身不会消耗太多 IO,而且合并完成之后对读的性能会有显著提升.<br>然而现实中可能大部分 HFile 文件都不会这样.</p>
<p>要选择待合并的HFile文件,首先会对该Store中所有HFile逐一进行排查,排除不满足条件的部分文件,排除条件如下:</p>
<ol>
<li>排除当前正在执行 Compaction 的文件以及比这些文件更加新的所有文件.</li>
<li>排除某些过大的文件,如果文件大于 <font color="blue">hbase.hstore.compaction.max.size</font>,则被排除,否则会产生大量IO消耗.</li>
</ol>
<blockquote>
<p>参数解释<br>hbase.hstore.compaction.max.size<br>默认值:Long.MAX_VALUE,以字节表示,大于这个大小的HFile文件将被排除在Compaction之外.<br>当Compaction发生得太频繁时,可以尝试提高这个值.</p>
</blockquote>
<p>经过排除后留下来的文件称为<font color="red">候选文件</font>,接下来 HBase <font color="red">再判断侯选文件是否满足 Major Compaction 条件,如果满足,就会选择全部文件进行合并</font>.<br>判断条件如下所列,只要满足其中一条就会执行 Major Compaction:</p>
<ol>
<li>用户强制执行 Major Compaction.</li>
<li>满足CompactionChecker条件二,且候选文件数小于 <code>hbase.hstore.compaction.max</code>.</li>
<li>Store 中含有 reference 文件,reference 文件是 region 分裂产生的临时文件,一般必须在 Compaction 过程中清理.</li>
</ol>
<blockquote>
<p>参数解释<br>hbase.hstore.compaction.max<br>默认值为10,执行单次Minor Compaction过程可以被选择的HFile的最大数量,而与符合条件的HFile的数量无关.<br>实际上,该参数的值控制完成一次Compaction所需的时间长度.<br>将其设置得更大意味着Compaction中包含更多的HFile文件.<br>对于大多数情况,默认值是合适的.</p>
</blockquote>
<p>如果满足Major Compaction条件,文件选择这一步就结束了,待合并HFile文件就是Store中所有HFile文件.<br>如果不满足Major Compaction条件,就必然为Minor Compaction.</p>
<p>HBase主要有两种Minor Compaction文件选择策略,一种是RatioBasedCompactionPolicy,另一种是 ExploringCompactionPolicy.<br>后者在前者的基础上做了进一步修正.</p>
<h4 id="RatioBasedCompactionPolicy"><a href="#RatioBasedCompactionPolicy" class="headerlink" title="RatioBasedCompactionPolicy"></a>RatioBasedCompactionPolicy</h4><p>从老到新逐一扫描所有候选文件,满足其中条件之一便停止扫描:</p>
<ol>
<li>当前文件大小 &lt; 比当前文件新的所有文件大小总和 * ratio.<br>其中ratio是一个可变的比例,在高峰期ratio为1.2,受参数<font color="red">hbase.hstore.compaction.ratio</font>控制,非高峰期ratio为5,受参数<font color="red">hbase.hstore.compaction.ratio.offpeak</font>控制,也就是非高峰期允许compact更大的文件.</li>
<li>当前所剩候选文件数 &lt;= hbase.hstore.compaction.min.</li>
</ol>
<h5 id="参数解释-2"><a href="#参数解释-2" class="headerlink" title="参数解释"></a>参数解释</h5><p>hbase.hstore.compaction.ratio<br>默认值为1.2F,对于Minor Compaction,这个比率用于确定给定的HFile文件大于等于<code>hbase.hstore.compaction.min.size</code>情况下是否适合进行Compaction.<br>它的作用是限制对较大的HFile的进行Compaction.<br>推荐取值范围为1.0和1.4之间的中等值.<br>对于大多数情况,默认值是合适的.</p>
<p>hbase.hstore.compaction.ratio.offpeak<br>默认值为5.0F,工作原理同<code>hbase.hstore.compaction.ratio</code>参数,但是该值用于非高峰时间段内的Mimor Compaction.<br>默认情况下非高峰时间段是关闭的,因此该参数的值不会生效.</p>
<p>hbase.offpeak.start.hour<br>默认值为-1,非高峰时间的开始,表示为0到23之间的整数.<br>设置为-1禁用非峰值,即默认禁用.</p>
<p>hbase.offpeak.end.hour<br>默认值为-1,非高峰时间的结束,表示为0到23之间的整数.<br>设置为-1禁用非峰值,即默认禁用.</p>
<p>hbase.hstore.compaction.min<br>默认为3,在运行Compaction之前必须符合Compaction条件的HFile文件的最小数量.<br>调优该参数的的目的是避免产生太多需要Compaction的小HFile文件.<br>将该值设置为2将导致每次在一个Store中有两个HFile文件时进行Minor Compaction,这可能不合适.<br>如果您将该值设置得过高,则需要相应地调整所有其他值.<br>对于大多数情况,默认值是合适的.<br>在HBase的早期版本中,该参数被命名为<code>hbase.hstore.compactionThreshold</code>.</p>
<p>hbase.hstore.compaction.min.size<br>默认值为134217728,即128M,小于此大小的HFile文件将始终适合进行Minor Compaction.<br>大于等于此大小的HFiles文件由<code>hbase.hstore.compact.ratio</code>评估,以确定它们是否符合条件.</p>
<p>停止扫描后,待合并文件就选择出来了,即当前扫描文件以及比它更新的所有文件.</p>
<p>实际情况下的RatioBasedCompactionPolicy算法效果很差,经常引发大面积的 Minor Compaction,而Minor Compaction过程中不能写入数据,经常因为Compaction而影响IO.</p>
<h4 id="ExploringCompactionPolicy"><a href="#ExploringCompactionPolicy" class="headerlink" title="ExploringCompactionPolicy"></a>ExploringCompactionPolicy</h4><p>该策略思路基本和 RatioBasedCompactionPolicy 相同,不同的是,Ratio策略在找到一个合适的文件集合之后就停止扫描了,而Exploring策略会记录所有合适的文件集合,并在这些文件集合中寻找最优解.<br>最优解可以理解为:待合并文件数最多或者待合并文件数相同的情况下文件较小,这样有利于减少Compaction带来的IO消耗.</p>
<h5 id="修改待合并文件的挑选条件"><a href="#修改待合并文件的挑选条件" class="headerlink" title="修改待合并文件的挑选条件"></a>修改待合并文件的挑选条件</h5><p>不再武断地认为,某个文件满足条件就把更加新的文件全部合并进去.<br>确切地说,现在的遍历不强调顺序性了,是把所有的文件都遍历一遍之后每一个文件都去考虑.<br>如果当前文件大小小于最小Compaction大小,则直接进入待合并列表.<br>最小合并大小的配置项:<code>hbase.hstore.compaction.min.size</code>.<br>如果没设定该配置项,则使用<code>hbase.hregion.memstore.flush.size</code>.</p>
<p>如果不小于最小Compaction大小,则根据&quot;<font color="red">该文件大小 &lt; (所有文件大小总和 - 该文件大小) * ratio</font>&quot;条件判断符合条件而进入待合并列表的文件.</p>
<h5 id="以组合作为计算单元"><a href="#以组合作为计算单元" class="headerlink" title="以组合作为计算单元"></a>以组合作为计算单元</h5><p>新的算法不再按文件为单元进行比较了,而是挑出多个文件组合.<br>挑选组合的条件是:<br>被挑选的文件必须能通过以上提到的筛选条件,并且组合内含有的文件数必须大于<code>hbase.hstore.compaction.min</code>,小于<code>hbase.hstore.compaction.max</code>.</p>
<p>文件太少了没必要合并,还浪费资源.文件太多了太消耗资源,怕机器受不了.</p>
<p>挑选完组合后,比较哪个文件组合包含的文件更多,就合并哪个组合.<br>如果出现平局,就挑选那个文件尺寸总和更小的组合.</p>
<h3 id="挑选合适的执行线程池"><a href="#挑选合适的执行线程池" class="headerlink" title="挑选合适的执行线程池"></a>挑选合适的执行线程池</h3><p>HBase实现中有一个专门的类<code>org.apache.hadoop.hbase.regionserver.CompactSplit</code>负责接收Compaction请求和Split请求,而且为了能够独立处理这些请求,这个类内部构造了三个线程池:<br>longCompactions/shortCompactions/splits.<br>splits线程池负责处理所有的split请求,longCompactions用来处理大型Compaction,shortCompactions负责处理小型Compaction.</p>
<p>这里需要明确:</p>
<ol>
<li>上述设计目的是能够将请求独立处理,提高系统的处理性能.</li>
<li>大型Compaction并不是Major Compaction,小型Compaction 也并不是MinorCompaction.</li>
<li>HBase 定义了一个阈值<code>hbase.regionserver.thread.compaction.throttle</code>,如果Compaction合并的总文件大小超过这个阈值就认为是大型Compaction,否则认为是小型Compaction.<br>大Compaction会分配给longCompactions线程池处理,小Compaction会分配给shortCompactions线程池处理.</li>
<li>longCompactions线程池和shortCompactions线程池默认都只有一个线程,用户可以通过参数<code>hbase.regionserver.thread.compaction.large</code> 和<code>hbase.regionserver.thread.compaction.small</code>进行配置.</li>
</ol>
<h4 id="参数解释-3"><a href="#参数解释-3" class="headerlink" title="参数解释"></a>参数解释</h4><p>hbase.regionserver.thread.compaction.throttle<br>默认值为2684354560,即2G,Compaction有两个不同的线程池,一个用于大型Compaction,另一个用于小型Compaction.<br>这有助于保持精简表(如hbase:meta)的快速Compaction.<br>如果Compaction大于此阈值,则将进入大型Compaction池.<br>在大多数情况下,默认值是合适的.<br>默认值是<code>2 * hbase.hstore.compaction.max * hbase.hregion.memstore.flush.size</code>.</p>
<h3 id="HFile文件Compaction执行"><a href="#HFile文件Compaction执行" class="headerlink" title="HFile文件Compaction执行"></a>HFile文件Compaction执行</h3><p>选出待合并的HFile集合,再选出合适的处理线程,接下来执行合并流程.</p>
<p>合并流程主要分为如下几步:</p>
<ol>
<li>分别读出待合并 HFile 文件的 KeyValue,进行归并排序处理,之后写到region目录下的.tmp目录下新创建HFile文件中.<br>以下两种数据不会被读取出来:</li>
</ol>
<ul>
<li>如果数据过期了(达到 TTL 所规定的时间),那么这些数据不会被读取出来.</li>
<li>如果是Major Compaction,那么数据带了墓碑标记也不会被读取出来.</li>
</ul>
<ol start="2">
<li>将<code>/&lt;Region&gt;/.tmp</code>目录下新创建的HFile文件移动到对应列族数据目录.</li>
<li>将Compaction的输入文件路径和输出文件路径封装为KV写入HLog日志,并打上 Compaction标记,最后强制执行sync.</li>
<li>将对应列族数据目录下的Compaction输入文件全部删除.</li>
</ol>
<p>上述4个步骤看起来简单,但实际是很严谨的,具有很强的容错性和幂等性:</p>
<ol>
<li>如果 RegionServer 在步骤2之前发生异常,本次 Compaction 会被认定为失败,如果继续进行同样的 Compaction,上次异常对接下来的 Compaction 不会有任何影响,也不会对读写有任何影响.<br>唯一的影响就是多了一份多余的数据.</li>
<li>如果 RegionServer 在步骤2之后/步骤3之前发生异常,同样,仅仅会多一份冗余数据.</li>
<li>如果 RegionServer 在步骤3之后/步骤4之前发生异常,RegionServer 在重新打开 Region 之后首先会从 HLog 中看到标有 Compaction 的日志,因为此时输入文件和输出文件已经持久化到 HDFS,因此只需要根据 HLog 移除 Compaction 输入文件即可.</li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="压缩和删除"><a href="#压缩和删除" class="headerlink" title="压缩和删除"></a>压缩和删除</h3><p>当 HBase 中发生显式删除时,实际上并没有删除数据.<br>相反,写了一个墓碑标记.<br>墓碑标记可防止数据随查询一起返回.<br>在主要压缩过程中,数据实际上被删除,逻辑删除标记从 StoreFile 中删除.<br>如果删除是由于 TTL 过期而发生的,则不会创建逻辑删除.<br>相反,过期数据会被过滤掉,不会写回压缩的 StoreFile.</p>
<h3 id="压缩和版本"><a href="#压缩和版本" class="headerlink" title="压缩和版本"></a>压缩和版本</h3><p>创建列族时,您可以指定要保留的最大版本数,方法是指定<code>HColumnDescriptor.setMaxVersions(int versions)</code>.默认值为3.<br>如果存在超过指定最大值的版本,则多余的版本将被过滤掉并且不会写回压缩的 StoreFile.</p>
<h3 id="主要压缩会影响查询结果"><a href="#主要压缩会影响查询结果" class="headerlink" title="主要压缩会影响查询结果"></a>主要压缩会影响查询结果</h3><p>在某些情况下,如果明确删除较新的版本,则可能会无意中恢复较旧的版本.<br>这种情况只有在压缩完成之前才有可能.</p>
<p>从理论上讲,主要压缩可以提高性能.<br>但是,在高负载系统上,主要压缩可能需要不适当数量的资源并对性能产生不利影响.<br>在默认配置中,主要压缩被自动安排为在 7 天内运行一次.<br>这有时不适合生产系统.<br>您可以手动管理主要压缩.</p>
<p>压缩不执行区域合并.</p>
<h3 id="为什么只有Major-Compaction可以真正删除数据"><a href="#为什么只有Major-Compaction可以真正删除数据" class="headerlink" title="为什么只有Major Compaction可以真正删除数据?"></a>为什么只有Major Compaction可以真正删除数据?</h3><p>其实HBase一直拖到Major Compaction的时候才真正把带墓碑标记的数据删掉,并不是因为性能要求,而是之前真的做不到.<br>HBase是建立在HDFS这种只有增加删除而没有修改的文件系统之上的,所以就连用户删除这个动作,在底层都是由新增实现的:</p>
<ol>
<li>用户增加一条数据就在 HFile 上增加一条 KeyValue,类型是 PUT.</li>
<li>用户删除一条数据还是在 HFile 上增加一条 KeyValue,类型是 DELETE,这就是墓碑标记.<br>所以墓碑标记没有什么神秘的,它也就只是另外一个 KeyValue,只不过 value 没有值,而类型是 DELETE.</li>
</ol>
<p>现在会遇到一个问题:<br>当用户删除数据的时候之前的数据已经被刷写到磁盘上的另外一个HFile了.<br>这种情况很常见,也就是说,墓碑标记和原始数据这两个KeyValue 压根就不在同一个HFile上.</p>
<p>在查询的时候Scan指针其实是把所有的HFile都看过了一遍,它知道了有这条数据,也知道它有墓碑标记,而在返回数据的时候选择不把数据返回给用户,这样在用户的Scan操作看来这条数据就是被删掉了.<br>如果带上RAW=&gt;true参数来Scan,就可以查询到这条被打上墓碑标记的数据.</p>
<h3 id="为什么达到TTL的数据可以被Minor-Compaction删除"><a href="#为什么达到TTL的数据可以被Minor-Compaction删除" class="headerlink" title="为什么达到TTL的数据可以被Minor Compaction删除?"></a>为什么达到TTL的数据可以被Minor Compaction删除?</h3><p>这是因为当数据达到TTL的时候,并不需要额外的一个KeyValue来记录.<br>Compaction时创建的Scan在查询数据的时候,根据&quot;当前时间now - cell的timestamp &gt; TTL&quot;公式来判断cell是否过期.</p>
<p>如果过期了就不返回这条数据.<br>这样当Compaction完成后,过期的数据因为没有被写入新文件,自然就消失了.</p>
<h3 id="限制压缩的速度"><a href="#限制压缩的速度" class="headerlink" title="限制压缩的速度"></a>限制压缩的速度</h3><p>通过配置<code>hbase.regionserver.throughput.controller</code>及其相关设置来限制 HBase 压缩运行的速度.<br>默认控制器是<code>org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController</code>,它使用以下算法:</p>
<ol>
<li>如果压实压力大于 1.0,则没有速度限制.</li>
<li>在非高峰时段,使用固定的吞吐量限制,配置使用<code>hbase.hstore.compaction.throughput.offpeak</code>,<code>hbase.offpeak.start.hour</code>, 和<code>hbase.offpeak.end.hour</code>.</li>
<li>在正常时间,最大吞吐量在<code>hbase.hstore.compaction.throughput.higher.bound</code>和<code>hbase.hstore.compaction.throughput.lower.bound</code>(分别默认为 20 MB/秒和 10 MB/秒),使用以下公式,其中压实压力介于 0.0 和 1.0 之间.<br>compactionPressure是指需要压缩的存储文件的数量.<br><code>lower + (higer - lower) * compactionPressure</code></li>
</ol>
<p>要禁用压实速度限制,请设置<code>hbase.regionserver.throughput.controller</code>到<code>org.apache.hadoop.hbase.regionserver.compactions.NoLimitCompactionThroughputController</code>.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.throughput.controller<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hstore.compaction.throughput.higher.bound<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>20971520<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The default is 20 MB/sec<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hstore.compaction.throughput.lower.bound<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The default is 10 MB/sec<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hstore.compaction.throughput.offpeak<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>9223372036854775807<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The default is Long.MAX_VALUE, which effectively means no limitation<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.offpeak.start.hour<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>20<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>When to begin using off-peak compaction settings, expressed as an integer between 0 and 23.<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.offpeak.end.hour<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>6<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>When to stop using off-peak compaction settings, expressed as an integer between 0 and 23.<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hstore.compaction.throughput.tune.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>次要压缩文件选择.<br>配置如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hbase.hstore.compaction.ratio &#x3D; 1.0f</span><br><span class="line">hbase.hstore.compaction.min &#x3D; 3 (files)</span><br><span class="line">hbase.hstore.compaction.max &#x3D; 5 (files)</span><br><span class="line">hbase.hstore.compaction.min.size &#x3D; 10 (bytes)</span><br><span class="line">hbase.hstore.compaction.max.size &#x3D; 1000 (bytes)</span><br></pre></td></tr></table></figure>

<h3 id="基本示例"><a href="#基本示例" class="headerlink" title="基本示例"></a>基本示例</h3><p>存在以下 StoreFiles:100/50/23/12/12 个字节(从旧到新).<br>使用上述参数,将选择进行次要压缩的文件为 23/12/12.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">100 → 否,因为 sum(50, 23, 12, 12) * 1.0 &#x3D; 97.</span><br><span class="line">50 → 否,因为 sum(23, 12, 12) * 1.0 &#x3D; 47.</span><br><span class="line">23 → 是的,因为 sum(12, 12) * 1.0 &#x3D; 24.</span><br><span class="line">12 → 是,因为之前的文件已经被包含进来,并且因为这没有超过最大文件限制 5</span><br><span class="line">12 → 是,因为之前的文件已包含在内,并且因为这没有超过最大文件限制 5.</span><br></pre></td></tr></table></figure>

<h3 id="没有足够的文件来压缩"><a href="#没有足够的文件来压缩" class="headerlink" title="没有足够的文件来压缩"></a>没有足够的文件来压缩</h3><p>存在以下 StoreFiles:100/25/12/12 个字节(从旧到新).<br>使用上述参数,不会启动压缩.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">100 → 否,因为 sum(25, 12, 12) * 1.0 &#x3D; 47</span><br><span class="line">25 → 否,因为 sum(12, 12) * 1.0 &#x3D; 24</span><br><span class="line">12 → No. Candidate 因为 sum(12) * 1.0 &#x3D; 12,只有 2 个文件需要压缩,小于阈值 3</span><br><span class="line">12 → No. Candidate 因为之前的 StoreFile 是,但是没有足够的文件来压缩</span><br></pre></td></tr></table></figure>

<h3 id="限制要压缩的文件"><a href="#限制要压缩的文件" class="headerlink" title="限制要压缩的文件"></a>限制要压缩的文件</h3><p>存在以下 StoreFiles:各 7/6/5/4/3/2/1 个字节(从旧到新).<br>使用上述参数,将选择进行次要压缩的文件为 7/6/5/4/3.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">7 → 是的,因为 sum(6, 5, 4, 3, 2, 1) * 1.0 &#x3D; 21.此外,7 小于最小大小</span><br><span class="line">6 → 是的,因为 sum(5, 4, 3, 2, 1) * 1.0 &#x3D; 15.此外,6 小于最小大小.</span><br><span class="line">5 → 是的,因为 sum(4, 3, 2, 1) * 1.0 &#x3D; 10.此外,5 小于最小大小.</span><br><span class="line">4 → 是的,因为 sum(3, 2, 1) * 1.0 &#x3D; 6.此外,4 小于最小大小.</span><br><span class="line">3 → 是的,因为 sum(2, 1) * 1.0 &#x3D; 3.此外,3 小于最小大小.</span><br><span class="line">2 → No. Candidate 因为选择了上一个文件并且 2 小于最小大小,但是已经达到要压缩的最大文件数.</span><br><span class="line">1 → No. Candidate 因为选择了上一个文件并且 1 小于最小大小,但是已经达到要压缩的最大文件数.</span><br></pre></td></tr></table></figure>

<h2 id="条纹压实"><a href="#条纹压实" class="headerlink" title="条纹压实"></a>条纹压实</h2><p>Stripe 压缩是 HBase 0.98 中添加的一项实验性功能,旨在改进大区域或非均匀分布的行键的压缩.<br>为了实现更小/更细粒度的压缩,一个区域内的 StoreFiles 为该区域的几个行键子范围或&quot;条带&quot;单独维护.<br>条带对 HBase 的其余部分是透明的,因此对 HFile 或数据的其他操作无需修改即可工作.</p>
<p>条带压缩改变 HFile 布局,在区域内创建子区域.<br>这些子区域更容易压缩,并且应该导致更少的主要压缩.<br>这种方法减轻了较大区域的一些挑战.</p>
<p>Stripe 压缩与Compaction完全兼容,并与 ExploringCompactionPolicy 或 RatioBasedCompactionPolicy 结合使用.<br>可以为已有的表启用,以后如果禁用,表会继续正常运行.</p>
<h3 id="何时使用条纹压缩"><a href="#何时使用条纹压缩" class="headerlink" title="何时使用条纹压缩"></a>何时使用条纹压缩</h3><p>如果您有以下任一情况,请考虑使用条带压缩:</p>
<ol>
<li>大区域.<br>您可以获得较小区域的积极影响,而无需额外的 MemStore 开销和区域管理开销.</li>
<li>非统一键,例如键中的时间维度.<br>只有接收新密钥的条带需要压缩.<br>旧数据不会经常压缩,如果有的话</li>
</ol>
<h4 id="性能改进"><a href="#性能改进" class="headerlink" title="性能改进"></a>性能改进</h4><p>性能测试表明,读性能有所提升,读写性能波动性大大降低.<br>在大型非统一行键区域(例如哈希前缀时间戳键)上可以看到整体的长期性能改进.<br>这些性能提升在已经很大的表上最为显着.<br>性能改进可能会扩展到区域拆分.</p>
<h4 id="启用条带压缩"><a href="#启用条带压缩" class="headerlink" title="启用条带压缩"></a>启用条带压缩</h4><p>您可以为表或列族启用条带压缩,方法是将其设置<code>hbase.hstore.engine.class</code>为<code>org.apache.hadoop.hbase.regionserver.StripeStoreEngine</code>.<br>您还需要将<code>hbase.hstore.blockingStoreFiles</code>设置为一个较大的数字,例如 100(而不是默认值 10).</p>
<blockquote>
<p>启用条带压缩</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;orders_table&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;org.apache.hadoop.hbase.regionserver.StripeStoreEngine&#x27;, &#x27;hbase.hstore.blockingStoreFiles&#x27; =&gt; &#x27;100&#x27;&#125;</span><br><span class="line">alter &#x27;orders_table&#x27;, &#123;NAME =&gt; &#x27;blobs_cf&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;org.apache.hadoop.hbase.regionserver.StripeStoreEngine&#x27;, &#x27;hbase.hstore.blockingStoreFiles&#x27; =&gt; &#x27;100&#x27;&#125;&#125;</span><br><span class="line">create &#x27;orders_table&#x27;, &#x27;blobs_cf&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;org.apache.hadoop.hbase.regionserver.StripeStoreEngine&#x27;, &#x27;hbase.hstore.blockingStoreFiles&#x27; =&gt; &#x27;100&#x27;&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>禁用条带压缩</p>
</blockquote>
<p>将hbase.hstore.engine.class选项设置为 nil 或org.apache.hadoop.hbase.regionserver.DefaultStoreEngine. 任一选项都具有相同的效果.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;orders_table&#x27;, CONFIGURATION =&gt; &#123;&#x27;hbase.hstore.engine.class&#x27; =&gt; &#x27;rg.apache.hadoop.hbase.regionserver.DefaultStoreEngine&#x27;&#125;</span><br></pre></td></tr></table></figure>

<p>当您在以任何方式更改存储引擎后启用大表时,可能会在大多数区域执行主要压缩.<br>这在新表上不是必需的.</p>
<h4 id="配置条带压缩"><a href="#配置条带压缩" class="headerlink" title="配置条带压缩"></a>配置条带压缩</h4><p>条带压缩的每个设置都应该在表或列族级别配置.<br>如果使用 HBase shell,一般命令模式如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#39;orders_table&#39;, CONFIGURATION &#x3D;&gt; &#123;&#39;key&#39; &#x3D;&gt; &#39;value&#39;, ..., &#39;key&#39; &#x3D;&gt; &#39;value&#39;&#125;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="区域和条带大小"><a href="#区域和条带大小" class="headerlink" title="区域和条带大小"></a>区域和条带大小</h3><p>您可以根据区域大小配置条带大小.<br>默认情况下,您的新区域将从一个条纹开始.<br>在条带变得太大(16 x MemStore 刷新大小)后的下一次压缩中,它被分成两个条带.<br>条纹分裂随着区域的增长而继续,直到区域大到可以分裂为止.</p>
<p>您可以针对自己的数据改进此模式.<br>一个好的规则是针对至少 1 GB 的条带大小,以及大约 8-12 个条带用于统一行键.<br>例如,如果您的区域是 30 GB,则 12 x 2.5 GB 条带可能是一个很好的起点.</p>
<h3 id="条带大小设置"><a href="#条带大小设置" class="headerlink" title="条带大小设置"></a>条带大小设置</h3><h4 id="hbase-store-stripe-initialStripeCount"><a href="#hbase-store-stripe-initialStripeCount" class="headerlink" title="hbase.store.stripe.initialStripeCount"></a>hbase.store.stripe.initialStripeCount</h4><p>启用条带压缩时要创建的条带数.<br>您可以按如下方式使用它:</p>
<ol>
<li>对于相对统一的行键,如果您从上面知道大概的目标条带数,则可以通过从几个条带(2/5/10/... )开始来避免一些拆分开销.<br>如果早期数据不能代表整个行键分布,那么效率就不会那么高.</li>
<li>对于具有大量数据的现有表,此设置将有效地预拆分您的条带.</li>
<li>对于诸如散列前缀顺序键之类的键,每个区域有多个散列前缀,预拆分可能是有意义的.</li>
</ol>
<h4 id="hbase-store-stripe-sizeToSplit"><a href="#hbase-store-stripe-sizeToSplit" class="headerlink" title="hbase.store.stripe.sizeToSplit"></a>hbase.store.stripe.sizeToSplit</h4><p>条带在分裂前增长的最大尺寸.<br>根据上述大小考虑因素,将其与<code>hbase.store.stripe.splitPartCount</code>结合使用以控制目标条带大小 (sizeToSplit = splitPartsCount * target stripe size).</p>
<h4 id="hbase-store-stripe-splitPartCount"><a href="#hbase-store-stripe-splitPartCount" class="headerlink" title="hbase.store.stripe.splitPartCount"></a>hbase.store.stripe.splitPartCount</h4><p>拆分条带时要创建的新条带数.<br>默认值为 2,适用于大多数情况.<br>对于非统一行键,您可以尝试将数量增加到 3 或 4,以将到达的更新隔离到更窄的区域切片中,而不需要额外的拆分.</p>
<h3 id="MemStore-大小设置"><a href="#MemStore-大小设置" class="headerlink" title="MemStore 大小设置"></a>MemStore 大小设置</h3><p>默认情况下,flush 从一个 MemStore 中创建多个文件,根据现有的 stripe boundaries 和 row keys 进行 flush.<br>这种方法最大限度地减少了写入放大,但如果 MemStore 很小并且有很多条带,则可能不受欢迎,因为文件会太小.</p>
<p>在这种情况下,您可以设置hbase.store.stripe.compaction.flushToL0为true.<br>这将导致 MemStore 刷新创建单个文件.<br>当至少hbase.store.stripe.compaction.minFilesL0有这样的文件(默认情况下为 4 个)累积时,它们将被压缩为条带文件.</p>
<h3 id="正常压缩配置和条带压缩"><a href="#正常压缩配置和条带压缩" class="headerlink" title="正常压缩配置和条带压缩"></a>正常压缩配置和条带压缩</h3><p>适用于正常压缩的所有设置(请参阅压缩算法使用的参数)适用于条带压缩.<br>例外情况是最小和最大文件数,默认情况下将其设置为更高的值,因为条带中的文件更小.<br>要控制条带压缩的这些,请使用<code>hbase.store.stripe.compaction.minFiles</code> and <code>hbase.store.stripe.compaction.maxFiles</code>,而不是<code>hbase.hstore.compaction.min</code> and <code>hbase.hstore.compaction.max</code>.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hbase/" rel="tag"># hbase</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/08/03/hbase%20sequenceId/" rel="prev" title="hbase sequenceId">
                  <i class="fa fa-chevron-left"></i> hbase sequenceId
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/03/hbase%20jmx%E5%B8%B8%E7%94%A8%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/" rel="next" title="hbase jmx常用监控指标">
                  hbase jmx常用监控指标 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
