<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="在定义数据处理管道时,Table API 和 DataStream API 同样重要. DataStream API 在一个相对较低级别的命令式编程 API 中提供了流处理的原语(即时间&#x2F;状态和数据流管理).Table API 抽象了许多内部结构,并提供了结构化和声明性的 API. 两种 API 都可以处理有界和无界流. 处理历史数据时需要管理有界流.无限流发生在可能首先用历史数据初始化的实时处理">
<meta property="og:type" content="article">
<meta property="og:title" content="flink datastream-table api集成">
<meta property="og:url" content="https://maoeryu.github.io/2022/08/22/flink%20datastream-table%20api%E9%9B%86%E6%88%90/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="在定义数据处理管道时,Table API 和 DataStream API 同样重要. DataStream API 在一个相对较低级别的命令式编程 API 中提供了流处理的原语(即时间&#x2F;状态和数据流管理).Table API 抽象了许多内部结构,并提供了结构化和声明性的 API. 两种 API 都可以处理有界和无界流. 处理历史数据时需要管理有界流.无限流发生在可能首先用历史数据初始化的实时处理">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://maoeryu.github.io/images/flgl207.png">
<meta property="article:published_time" content="2022-08-21T16:00:00.000Z">
<meta property="article:modified_time" content="2022-12-02T06:12:19.084Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="flink">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://maoeryu.github.io/images/flgl207.png">


<link rel="canonical" href="https://maoeryu.github.io/2022/08/22/flink%20datastream-table%20api%E9%9B%86%E6%88%90/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>flink datastream-table api集成 | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#DataStream-Table%E8%BD%AC%E6%8D%A2"><span class="nav-number">1.</span> <span class="nav-text">DataStream&#x2F;Table转换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BE%9D%E8%B5%96%E9%A1%B9-%E5%AF%BC%E5%85%A5"><span class="nav-number">1.1.</span> <span class="nav-text">依赖项&#x2F;导入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE"><span class="nav-number">1.2.</span> <span class="nav-text">配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E8%A1%8C%E4%B8%BA"><span class="nav-number">1.3.</span> <span class="nav-text">执行行为</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DataStream-API"><span class="nav-number">1.3.1.</span> <span class="nav-text">DataStream API</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Table-API"><span class="nav-number">1.3.2.</span> <span class="nav-text">Table API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%B9%E5%A4%84%E7%90%86%E8%BF%90%E8%A1%8C%E6%97%B6%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.</span> <span class="nav-text">批处理运行时模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%98%E6%9B%B4%E6%97%A5%E5%BF%97%E7%BB%9F%E4%B8%80"><span class="nav-number">2.1.</span> <span class="nav-text">变更日志统一</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%84%E7%90%86-Insert-Only-%E6%B5%81"><span class="nav-number">3.</span> <span class="nav-text">处理(Insert-Only)流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#fromDataStream%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.1.</span> <span class="nav-text">fromDataStream示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#createTemporaryView%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.2.</span> <span class="nav-text">createTemporaryView示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#toDataStream%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.3.</span> <span class="nav-text">toDataStream示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%84%E7%90%86%E5%8F%98%E6%9B%B4%E6%97%A5%E5%BF%97%E6%B5%81"><span class="nav-number">4.</span> <span class="nav-text">处理变更日志流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#fromChangelogStream%E7%A4%BA%E4%BE%8B"><span class="nav-number">4.1.</span> <span class="nav-text">fromChangelogStream示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#toChangelogStream%E7%A4%BA%E4%BE%8B"><span class="nav-number">4.2.</span> <span class="nav-text">toChangelogStream示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%86-Table-API-%E7%AE%A1%E9%81%93%E6%B7%BB%E5%8A%A0%E5%88%B0-DataStream-API"><span class="nav-number">5.</span> <span class="nav-text">将 Table API 管道添加到 DataStream API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scala-%E4%B8%AD%E7%9A%84%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2"><span class="nav-number">6.</span> <span class="nav-text">Scala 中的隐式转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TypeInformation-DataType-%E4%B9%8B%E9%97%B4%E7%9A%84%E6%98%A0%E5%B0%84"><span class="nav-number">7.</span> <span class="nav-text">TypeInformation&#x2F;DataType 之间的映射</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TypeInformation-%E5%88%B0-DataType"><span class="nav-number">7.1.</span> <span class="nav-text">TypeInformation 到 DataType</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DataType-%E5%88%B0-TypeInformation"><span class="nav-number">7.2.</span> <span class="nav-text">DataType 到 TypeInformation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A7%E7%89%88%E8%BD%AC%E6%8D%A2"><span class="nav-number">8.</span> <span class="nav-text">旧版转换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%86-DataStream-%E8%BD%AC%E6%8D%A2%E6%88%90%E8%A1%A8"><span class="nav-number">8.1.</span> <span class="nav-text">将 DataStream 转换成表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%86%E8%A1%A8%E8%BD%AC%E6%8D%A2%E6%88%90-DataStream"><span class="nav-number">8.2.</span> <span class="nav-text">将表转换成 DataStream</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%86%E8%A1%A8%E8%BD%AC%E6%8D%A2%E6%88%90-DataStream-1"><span class="nav-number">8.2.1.</span> <span class="nav-text">将表转换成 DataStream</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%88%B0-Table-Schema-%E7%9A%84%E6%98%A0%E5%B0%84"><span class="nav-number">8.3.</span> <span class="nav-text">数据类型到 Table Schema 的映射</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E6%98%A0%E5%B0%84"><span class="nav-number">8.3.1.</span> <span class="nav-text">基于位置映射</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%90%8D%E7%A7%B0%E7%9A%84%E6%98%A0%E5%B0%84"><span class="nav-number">8.3.2.</span> <span class="nav-text">基于名称的映射</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E7%B1%BB%E5%9E%8B"><span class="nav-number">8.3.3.</span> <span class="nav-text">原子类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tuple%E7%B1%BB%E5%9E%8B-Scala-Java-%E5%92%8C-Python-%E5%92%8C-Case-Class%E7%B1%BB%E5%9E%8B-%E4%BB%85-Scala"><span class="nav-number">8.3.4.</span> <span class="nav-text">Tuple类型(Scala , Java 和 Python)和 Case Class类型(仅 Scala)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#POJO-%E7%B1%BB%E5%9E%8B-Java-%E5%92%8C-Scala"><span class="nav-number">8.3.5.</span> <span class="nav-text">POJO 类型 (Java 和 Scala)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Row%E7%B1%BB%E5%9E%8B"><span class="nav-number">8.3.6.</span> <span class="nav-text">Row类型</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">221</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2022/08/22/flink%20datastream-table%20api%E9%9B%86%E6%88%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          flink datastream-table api集成
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-08-22 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-22T00:00:00+08:00">2022-08-22</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-12-02 14:12:19" itemprop="dateModified" datetime="2022-12-02T14:12:19+08:00">2022-12-02</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%8F%E5%90%8C%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">协同框架</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>在定义数据处理管道时,Table API 和 DataStream API 同样重要.</p>
<p>DataStream API 在一个相对较低级别的命令式编程 API 中提供了流处理的原语(即时间/状态和数据流管理).<br>Table API 抽象了许多内部结构,并提供了结构化和声明性的 API.</p>
<p>两种 API 都可以处理有界和无界流.</p>
<p>处理历史数据时需要管理有界流.<br>无限流发生在可能首先用历史数据初始化的实时处理场景中.</p>
<p>为了高效执行,两个 API 都以优化的批处理执行模式提供处理有界流.<br>但是,由于批处理只是流的一种特殊情况,因此也可以在常规流执行模式下运行有界流的管道.</p>
<p>一个 API 中的管道可以端到端定义,而不依赖于另一个 API.<br>但是,出于各种原因,混合使用这两种 API 可能会很有用:</p>
<ol>
<li>在 DataStream API 中实现主管道之前,使用表生态系统轻松访问目录或连接到外部系统.</li>
<li>在 DataStream API 中实现主管道之前,访问一些用于无状态数据规范化和清理的 SQL 函数.</li>
<li>如果 Table API 中不存在更底层的操作(例如自定义计时器处理),请不时切换到 DataStream API.</li>
</ol>
<p>Flink 提供了特殊的桥接功能,使与 DataStream API 的集成尽可能顺畅.</p>
<blockquote>
<p>在 DataStream 和 Table API 之间切换会增加一些转换开销.<br>例如,RowData部分处理二进制数据的表运行时的内部数据结构(即)需要转换为对用户更友好的数据结构(即Row).<br>通常,可以忽略此开销.</p>
</blockquote>
<span id="more"></span>
<h2 id="DataStream-Table转换"><a href="#DataStream-Table转换" class="headerlink" title="DataStream/Table转换"></a>DataStream/Table转换</h2><p>Flink 提供了一个专门StreamTableEnvironment用于与 DataStream 集成的 API.<br>TableEnvironment这些环境使用其他方法扩展常规,StreamExecutionEnvironment并将 DataStream API 中使用的作为参数.</p>
<p>以下代码显示了如何在两个 API 之间来回切换的示例.<br>Table的列名和类型自动派生自TypeInformation的DataStream.<br>由于 DataStream API 本身不支持变更日志处理,因此代码在流到表和表到流的转换过程中假定仅附加/仅插入语义.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create environments of both APIs</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a DataStream</span></span><br><span class="line">DataStream&lt;String&gt; dataStream = env.fromElements(<span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;John&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the insert-only DataStream as a Table</span></span><br><span class="line">Table inputTable = tableEnv.fromDataStream(dataStream);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the Table object as a view and query it</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;InputTable&quot;</span>, inputTable);</span><br><span class="line">Table resultTable = tableEnv.sqlQuery(<span class="string">&quot;SELECT UPPER(f0) FROM InputTable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the insert-only Table as a DataStream again</span></span><br><span class="line">DataStream&lt;Row&gt; resultStream = tableEnv.toDataStream(resultTable);</span><br><span class="line"></span><br><span class="line"><span class="comment">// add a printing sink and execute in DataStream API</span></span><br><span class="line">resultStream.print();</span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// +I[Alice]</span></span><br><span class="line"><span class="comment">// +I[Bob]</span></span><br><span class="line"><span class="comment">// +I[John]</span></span><br></pre></td></tr></table></figure>

<p>fromDataStream和的完整语义toDataStream可以在下面的专门部分中找到.<br>特别是,本节讨论了如何使用更复杂和嵌套的类型来影响模式派生.<br>它还涵盖了使用事件时间和水印.</p>
<p>根据查询的类型,在许多情况下,生成的动态表是一个管道,它不仅在将转换Table为 a时产生仅插入更改,DataStream而且还会产生撤回和其他类型的更新.<br>在表到流的转换过程中,这可能会导致类似于以下的异常:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Table sink &#39;Unregistered_DataStream_Sink_1&#39; doesn&#39;t support consuming update changes [...].</span><br></pre></td></tr></table></figure>

<p>在这种情况下,需要再次修改查询或切换到toChangelogStream.</p>
<p>以下示例显示了如何转换更新表.<br>每个结果行都代表更改日志中的一个条目,该条目带有一个可以通过调用row.getKind()它来查询的更改标志.<br>在示例中,第二个分数在(-U)之前Alice创建更新,在(+U) 更改之后创建更新.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create environments of both APIs</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a DataStream</span></span><br><span class="line">DataStream&lt;Row&gt; dataStream = env.fromElements(</span><br><span class="line">    Row.of(<span class="string">&quot;Alice&quot;</span>, <span class="number">12</span>),</span><br><span class="line">    Row.of(<span class="string">&quot;Bob&quot;</span>, <span class="number">10</span>),</span><br><span class="line">    Row.of(<span class="string">&quot;Alice&quot;</span>, <span class="number">100</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the insert-only DataStream as a Table</span></span><br><span class="line">Table inputTable = tableEnv.fromDataStream(dataStream).as(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;score&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the Table object as a view and query it</span></span><br><span class="line"><span class="comment">// the query contains an aggregation that produces updates</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;InputTable&quot;</span>, inputTable);</span><br><span class="line">Table resultTable = tableEnv.sqlQuery(</span><br><span class="line">    <span class="string">&quot;SELECT name, SUM(score) FROM InputTable GROUP BY name&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the updating Table as a changelog DataStream</span></span><br><span class="line">DataStream&lt;Row&gt; resultStream = tableEnv.toChangelogStream(resultTable);</span><br><span class="line"></span><br><span class="line"><span class="comment">// add a printing sink and execute in DataStream API</span></span><br><span class="line">resultStream.print();</span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// +I[Alice, 12]</span></span><br><span class="line"><span class="comment">// +I[Bob, 10]</span></span><br><span class="line"><span class="comment">// -U[Alice, 12]</span></span><br><span class="line"><span class="comment">// +U[Alice, 112]</span></span><br></pre></td></tr></table></figure>

<p>fromChangelogStream和的完整语义toChangelogStream可以在下面的专门部分中找到.<br>特别是,本节讨论了如何使用更复杂和嵌套的类型来影响模式派生.<br>它涵盖了使用事件时间和水印.<br>它讨论了如何为输入和输出流声明主键和更改日志模式.</p>
<p>上面的示例显示了如何通过为每个传入记录连续发出逐行更新来增量计算最终结果.<br>然而,在输入流是有限的(即有界的)的情况下,可以通过利用批处理原理更有效地计算结果.</p>
<p>在批处理中,运算符可以在连续阶段执行,在发出结果之前消耗整个输入表.<br>例如,连接运算符可以在执行实际连接之前对两个有界输入进行排序(即排序合并连接算法),或者在使用另一个输入之前从一个输入构建一个哈希表(即哈希连接算法的构建/探测阶段).</p>
<p>DataStream API 和 Table API 都提供了专门的批处理运行时模式.</p>
<p>以下示例说明了统一管道只需切换一个标志即可处理批处理和流数据.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.RuntimeExecutionMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">// setup DataStream API</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">// set the batch runtime mode</span></span><br><span class="line">env.setRuntimeMode(RuntimeExecutionMode.BATCH);</span><br><span class="line"></span><br><span class="line"><span class="comment">// uncomment this for streaming mode</span></span><br><span class="line"><span class="comment">// env.setRuntimeMode(RuntimeExecutionMode.STREAMING);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// setup Table API</span></span><br><span class="line"><span class="comment">// the table environment adopts the runtime mode during initialization</span></span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// define the same pipeline as above</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// prints in BATCH mode:</span></span><br><span class="line"><span class="comment">// +I[Bob, 10]</span></span><br><span class="line"><span class="comment">// +I[Alice, 112]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// prints in STREAMING mode:</span></span><br><span class="line"><span class="comment">// +I[Alice, 12]</span></span><br><span class="line"><span class="comment">// +I[Bob, 10]</span></span><br><span class="line"><span class="comment">// -U[Alice, 12]</span></span><br><span class="line"><span class="comment">// +U[Alice, 112]</span></span><br></pre></td></tr></table></figure>

<p>一旦将变更日志应用到外部系统(例如键值存储),可以看到两种模式都能够生成完全相同的输出表.<br>通过在发出结果之前消耗所有输入数据,批处理模式的更改日志仅包含仅插入更改.<br>另请参阅下面的专用批处理模式部分以获取更多信息.</p>
<h3 id="依赖项-导入"><a href="#依赖项-导入" class="headerlink" title="依赖项/导入"></a>依赖项/导入</h3><p>将 Table API 与 DataStream API 结合的项目需要添加以下桥接模块之一.<br>flink-table-api-java它们包括对orflink-table-api-scala和相应语言特定的 DataStream API 模块的传递依赖.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-java-bridge_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>使用 DataStream API 和 Table API 的 Java 或 Scala 版本声明公共管道需要以下导入.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// imports for Java DataStream API</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// imports for Table API with bridging to Java DataStream API</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.*;</span><br></pre></td></tr></table></figure>

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>将TableEnvironment采用传递的所有配置选项StreamExecutionEnvironment.<br>但是,不能保证对配置的进一步更改StreamExecutionEnvironment 会传播到StreamTableEnvironment其实例化之后.<br>从 Table API 到 DataStream API 的选项传播发生在规划期间.</p>
<p>我们建议在切换到 Table API 之前尽早在 DataStream API 中设置所有配置选项.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.time.ZoneId;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.CheckpointingMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create Java DataStream API</span></span><br><span class="line"></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">// set various configuration early</span></span><br><span class="line"></span><br><span class="line">env.setMaxParallelism(<span class="number">256</span>);</span><br><span class="line"></span><br><span class="line">env.getConfig().addDefaultKryoSerializer(MyCustomType.class, CustomKryoSerializer.class);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line"></span><br><span class="line"><span class="comment">// then switch to Java Table API</span></span><br><span class="line"></span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// set configuration early</span></span><br><span class="line"></span><br><span class="line">tableEnv.getConfig().setLocalTimeZone(ZoneId.of(<span class="string">&quot;Europe/Berlin&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// start defining your pipelines in both APIs...</span></span><br></pre></td></tr></table></figure>

<h3 id="执行行为"><a href="#执行行为" class="headerlink" title="执行行为"></a>执行行为</h3><p>这两个 API 都提供了执行管道的方法.<br>换句话说:如果需要,他们会编译一个作业图,该作业图将提交到集群并触发执行.<br>结果将流式传输到声明的接收器.</p>
<p>execute通常,两个 API 都使用方法名称中的术语来标记此类行为.<br>但是,Table API 和 DataStream API 的执行行为略有不同.</p>
<h4 id="DataStream-API"><a href="#DataStream-API" class="headerlink" title="DataStream API"></a>DataStream API</h4><p>DataStream API StreamExecutionEnvironment使用<strong>构建器模式</strong>来构建复杂的管道.<br>管道可能会分成多个分支,这些分支可能会或可能不会以接收器结束.<br>环境缓冲所有这些定义的分支,直到提交作业.</p>
<p>StreamExecutionEnvironment.execute()提交整个构建的管道并随后清除构建器.<br>换句话说:不再声明源和接收器,并且可以将新管道添加到构建器中.<br>因此,每个 DataStream 程序通常都以调用StreamExecutionEnvironment.execute(). 或者,DataStream.executeAndCollect()隐式定义一个接收器,用于将结果流式传输到本地客户端.</p>
<h4 id="Table-API"><a href="#Table-API" class="headerlink" title="Table API"></a>Table API</h4><p>StatementSet在 Table API 中,仅在每个分支必须声明最终接收器的情况下才支持分支管道.<br>两者TableEnvironment都StreamTableEnvironment没有提供专用的通用execute()方法.<br>相反,它们提供了提交单个源到接收器管道或语句集的方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// execute with explicit sink</span></span><br><span class="line">tableEnv.from(<span class="string">&quot;InputTable&quot;</span>).insertInto(<span class="string">&quot;OutputTable&quot;</span>).execute();</span><br><span class="line"></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;INSERT INTO OutputTable SELECT * FROM InputTable&quot;</span>);</span><br><span class="line"></span><br><span class="line">tableEnv.createStatementSet()</span><br><span class="line">    .add(tableEnv.from(<span class="string">&quot;InputTable&quot;</span>).insertInto(<span class="string">&quot;OutputTable&quot;</span>))</span><br><span class="line">    .add(tableEnv.from(<span class="string">&quot;InputTable&quot;</span>).insertInto(<span class="string">&quot;OutputTable2&quot;</span>))</span><br><span class="line">    .execute();</span><br><span class="line"></span><br><span class="line">tableEnv.createStatementSet()</span><br><span class="line">    .addInsertSql(<span class="string">&quot;INSERT INTO OutputTable SELECT * FROM InputTable&quot;</span>)</span><br><span class="line">    .addInsertSql(<span class="string">&quot;INSERT INTO OutputTable2 SELECT * FROM InputTable&quot;</span>)</span><br><span class="line">    .execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// execute with implicit local sink</span></span><br><span class="line"></span><br><span class="line">tableEnv.from(<span class="string">&quot;InputTable&quot;</span>).execute().print();</span><br><span class="line"></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SELECT * FROM InputTable&quot;</span>).print();</span><br></pre></td></tr></table></figure>

<p>为了结合这两种执行行为,每次调用StreamTableEnvironment.toDataStream 或StreamTableEnvironment.toChangelogStream将具体化(即编译)Table API 子管道并将其插入到 DataStream API 管道构建器中.<br>这意味着StreamExecutionEnvironment.execute() 或DataStream.executeAndCollect必须在之后调用.<br>Table API 中的执行不会触发这些&quot;外部部分&quot;.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// (1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// adds a branch with a printing sink to the StreamExecutionEnvironment</span></span><br><span class="line">tableEnv.toDataStream(table).print();</span><br><span class="line"></span><br><span class="line"><span class="comment">// (2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// executes a Table API end-to-end pipeline as a Flink job and prints locally,</span></span><br><span class="line"><span class="comment">// thus (1) has still not been executed</span></span><br><span class="line">table.execute().print();</span><br><span class="line"></span><br><span class="line"><span class="comment">// executes the DataStream API pipeline with the sink defined in (1) as a</span></span><br><span class="line"><span class="comment">// Flink job, (2) was already running before</span></span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

<h2 id="批处理运行时模式"><a href="#批处理运行时模式" class="headerlink" title="批处理运行时模式"></a>批处理运行时模式</h2><p>批处理运行时模式是有界Flink 程序的专用执行模式.</p>
<p>一般来说,有界性是数据源的一个属性,它告诉我们来自该源的所有记录在执行之前是否已知,或者是否会无限期地显示新数据.<br>反过来,如果一个工作的所有来源都是有界的,那么它是有界的,否则是无界的.</p>
<p>另一方面,流式运行时模式可用于有界和无界作业.</p>
<p>Table API &amp; SQL 规划器为这两种模式中的任何一种都提供了一组专门的优化器规则和运行时运算符.</p>
<p>目前,运行时模式不是从源自动派生的,因此,它必须显式设置或StreamExecutionEnvironment在实例化 a 时采用StreamTableEnvironment:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.RuntimeExecutionMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"></span><br><span class="line"><span class="comment">// adopt mode from StreamExecutionEnvironment</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRuntimeMode(RuntimeExecutionMode.BATCH);</span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// or</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// set mode explicitly for StreamTableEnvironment</span></span><br><span class="line"><span class="comment">// it will be propagated to StreamExecutionEnvironment during planning</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, EnvironmentSettings.inBatchMode());</span><br></pre></td></tr></table></figure>

<p>在将运行时模式设置为 之前,必须满足以下先决条件BATCH:</p>
<ol>
<li>所有来源都必须声明自己是有界的.</li>
<li>目前,表源必须发出仅插入更改.</li>
<li>运算符需要足够量的堆外内存 来进行排序和其他中间结果.</li>
<li>所有表操作都必须在批处理模式下可用.<br>目前,其中一些仅在流模式下可用.</li>
</ol>
<p>批处理执行具有以下含义(除其他外):</p>
<ol>
<li>渐进式水印既不会生成也不会在运算符中使用.<br>但是,源在关闭之前会发出最大水印.</li>
<li>根据execution.batch-shuffle-mode.<br>与在流模式下执行相同的管道相比,这也意味着可能需要更少的资源.</li>
<li>检查点被禁用.<br>插入了人工状态后端.</li>
<li>表操作不会产生增量更新,而只会产生一个完整的最终结果,该结果会转换为仅插入的变更日志流.</li>
</ol>
<p>由于批处理可以被视为流处理的一种特殊情况,我们建议首先实现流式管道,因为它是有界和无界数据的最通用实现.</p>
<p>理论上,流式管道可以执行所有运算符.<br>但是,在实践中,某些操作可能没有多大意义,因为它们会导致状态不断增长,因此不受支持.<br>全局排序是一个仅在批处理模式下可用的示例.<br>简而言之:应该可以在批处理模式下运行工作流管道,但反之亦然.</p>
<p>下面的示例展示了如何使用DataGen 表源来玩转批处理模式.<br>许多来源提供隐含地使连接器有界的选项,例如,通过定义终止偏移量或时间戳.<br>number-of-rows 在我们的示例中,我们使用该选项限制行数.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.TableDescriptor;</span><br><span class="line"></span><br><span class="line">Table table =</span><br><span class="line">    tableEnv.from(</span><br><span class="line">        TableDescriptor.forConnector(<span class="string">&quot;datagen&quot;</span>)</span><br><span class="line">            .option(<span class="string">&quot;number-of-rows&quot;</span>, <span class="string">&quot;10&quot;</span>) <span class="comment">// make the source bounded</span></span><br><span class="line">            .schema(</span><br><span class="line">                Schema.newBuilder()</span><br><span class="line">                    .column(<span class="string">&quot;uid&quot;</span>, DataTypes.TINYINT())</span><br><span class="line">                    .column(<span class="string">&quot;payload&quot;</span>, DataTypes.STRING())</span><br><span class="line">                    .build())</span><br><span class="line">            .build());</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert the Table to a DataStream and further transform the pipeline</span></span><br><span class="line">tableEnv.toDataStream(table)</span><br><span class="line">    .keyBy(r -&gt; r.&lt;Byte&gt;getFieldAs(<span class="string">&quot;uid&quot;</span>))</span><br><span class="line">    .map(r -&gt; <span class="string">&quot;My custom operator: &quot;</span> + r.&lt;String&gt;getFieldAs(<span class="string">&quot;payload&quot;</span>))</span><br><span class="line">    .executeAndCollect()</span><br><span class="line">    .forEachRemaining(System.out::println);</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// My custom operator: 9660912d30a43c7b035e15bd...</span></span><br><span class="line"><span class="comment">// My custom operator: 29f5f706d2144f4a4f9f52a0...</span></span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure>

<h3 id="变更日志统一"><a href="#变更日志统一" class="headerlink" title="变更日志统一"></a>变更日志统一</h3><p>在大多数情况下,当从流模式切换到批处理模式时,管道定义本身可以在 Table API 和 DataStream API 中保持不变,反之亦然.<br>但是,如前所述,由于避免了批处理模式下的增量操作,生成的变更日志流可能会有所不同.</p>
<p>依赖于事件时间并利用水印作为完整性标记的基于时间的操作能够生成独立于运行时模式的仅插入更改日志流.</p>
<p>以下 Java 示例说明了一个 Flink 程序,它不仅在 API 级别上统一,而且在生成的变更日志流中也统一了.<br>该示例使用基于两个表 ( ) 中时间属性的间隔连接在 SQL (UserTable和) 中连接两个表.<br>它使用 DataStream API 来实现一个自定义运算符,该运算符使用一个和值状态对用户名进行重复数据删除.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.RuntimeExecutionMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueState;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.Types;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.KeyedProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="comment">// setup DataStream API</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">// use BATCH or STREAMING mode</span></span><br><span class="line">env.setRuntimeMode(RuntimeExecutionMode.BATCH);</span><br><span class="line"></span><br><span class="line"><span class="comment">// setup Table API</span></span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a user stream</span></span><br><span class="line">DataStream&lt;Row&gt; userStream = env</span><br><span class="line">    .fromElements(</span><br><span class="line">        Row.of(LocalDateTime.parse(<span class="string">&quot;2021-08-21T13:00:00&quot;</span>), <span class="number">1</span>, <span class="string">&quot;Alice&quot;</span>),</span><br><span class="line">        Row.of(LocalDateTime.parse(<span class="string">&quot;2021-08-21T13:05:00&quot;</span>), <span class="number">2</span>, <span class="string">&quot;Bob&quot;</span>),</span><br><span class="line">        Row.of(LocalDateTime.parse(<span class="string">&quot;2021-08-21T13:10:00&quot;</span>), <span class="number">2</span>, <span class="string">&quot;Bob&quot;</span>))</span><br><span class="line">    .returns(</span><br><span class="line">        Types.ROW_NAMED(</span><br><span class="line">            <span class="keyword">new</span> String[] &#123;<span class="string">&quot;ts&quot;</span>, <span class="string">&quot;uid&quot;</span>, <span class="string">&quot;name&quot;</span>&#125;,</span><br><span class="line">            Types.LOCAL_DATE_TIME, Types.INT, Types.STRING));</span><br><span class="line"></span><br><span class="line"><span class="comment">// create an order stream</span></span><br><span class="line">DataStream&lt;Row&gt; orderStream = env</span><br><span class="line">    .fromElements(</span><br><span class="line">        Row.of(LocalDateTime.parse(<span class="string">&quot;2021-08-21T13:02:00&quot;</span>), <span class="number">1</span>, <span class="number">122</span>),</span><br><span class="line">        Row.of(LocalDateTime.parse(<span class="string">&quot;2021-08-21T13:07:00&quot;</span>), <span class="number">2</span>, <span class="number">239</span>),</span><br><span class="line">        Row.of(LocalDateTime.parse(<span class="string">&quot;2021-08-21T13:11:00&quot;</span>), <span class="number">2</span>, <span class="number">999</span>))</span><br><span class="line">    .returns(</span><br><span class="line">        Types.ROW_NAMED(</span><br><span class="line">            <span class="keyword">new</span> String[] &#123;<span class="string">&quot;ts&quot;</span>, <span class="string">&quot;uid&quot;</span>, <span class="string">&quot;amount&quot;</span>&#125;,</span><br><span class="line">            Types.LOCAL_DATE_TIME, Types.INT, Types.INT));</span><br><span class="line"></span><br><span class="line"><span class="comment">// create corresponding tables</span></span><br><span class="line">tableEnv.createTemporaryView(</span><br><span class="line">    <span class="string">&quot;UserTable&quot;</span>,</span><br><span class="line">    userStream,</span><br><span class="line">    Schema.newBuilder()</span><br><span class="line">        .column(<span class="string">&quot;ts&quot;</span>, DataTypes.TIMESTAMP(<span class="number">3</span>))</span><br><span class="line">        .column(<span class="string">&quot;uid&quot;</span>, DataTypes.INT())</span><br><span class="line">        .column(<span class="string">&quot;name&quot;</span>, DataTypes.STRING())</span><br><span class="line">        .watermark(<span class="string">&quot;ts&quot;</span>, <span class="string">&quot;ts - INTERVAL &#x27;1&#x27; SECOND&quot;</span>)</span><br><span class="line">        .build());</span><br><span class="line"></span><br><span class="line">tableEnv.createTemporaryView(</span><br><span class="line">    <span class="string">&quot;OrderTable&quot;</span>,</span><br><span class="line">    orderStream,</span><br><span class="line">    Schema.newBuilder()</span><br><span class="line">        .column(<span class="string">&quot;ts&quot;</span>, DataTypes.TIMESTAMP(<span class="number">3</span>))</span><br><span class="line">        .column(<span class="string">&quot;uid&quot;</span>, DataTypes.INT())</span><br><span class="line">        .column(<span class="string">&quot;amount&quot;</span>, DataTypes.INT())</span><br><span class="line">        .watermark(<span class="string">&quot;ts&quot;</span>, <span class="string">&quot;ts - INTERVAL &#x27;1&#x27; SECOND&quot;</span>)</span><br><span class="line">        .build());</span><br><span class="line"></span><br><span class="line"><span class="comment">// perform interval join</span></span><br><span class="line">Table joinedTable =</span><br><span class="line">    tableEnv.sqlQuery(</span><br><span class="line">        <span class="string">&quot;SELECT U.name, O.amount &quot;</span> +</span><br><span class="line">        <span class="string">&quot;FROM UserTable U, OrderTable O &quot;</span> +</span><br><span class="line">        <span class="string">&quot;WHERE U.uid = O.uid AND O.ts BETWEEN U.ts AND U.ts + INTERVAL &#x27;5&#x27; MINUTES&quot;</span>);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Row&gt; joinedStream = tableEnv.toDataStream(joinedTable);</span><br><span class="line"></span><br><span class="line">joinedStream.print();</span><br><span class="line"></span><br><span class="line"><span class="comment">// implement a custom operator using ProcessFunction and value state</span></span><br><span class="line">joinedStream</span><br><span class="line">    .keyBy(r -&gt; r.&lt;String&gt;getFieldAs(<span class="string">&quot;name&quot;</span>))</span><br><span class="line">    .process(</span><br><span class="line">        <span class="keyword">new</span> KeyedProcessFunction&lt;String, Row, String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">          ValueState&lt;String&gt; seen;</span><br><span class="line"></span><br><span class="line">          <span class="meta">@Override</span></span><br><span class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> </span>&#123;</span><br><span class="line">              seen = getRuntimeContext().getState(</span><br><span class="line">                  <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;seen&quot;</span>, String.class));</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="meta">@Override</span></span><br><span class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Row row, Context ctx, Collector&lt;String&gt; out)</span></span></span><br><span class="line"><span class="function">                  <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">              String name = row.getFieldAs(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">              <span class="keyword">if</span> (seen.value() == <span class="keyword">null</span>) &#123;</span><br><span class="line">                  seen.update(name);</span><br><span class="line">                  out.collect(name);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    .print();</span><br><span class="line"></span><br><span class="line"><span class="comment">// execute unified pipeline</span></span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints (in both BATCH and STREAMING mode):</span></span><br><span class="line"><span class="comment">// +I[Bob, 239]</span></span><br><span class="line"><span class="comment">// +I[Alice, 122]</span></span><br><span class="line"><span class="comment">// +I[Bob, 999]</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Bob</span></span><br><span class="line"><span class="comment">// Alice</span></span><br></pre></td></tr></table></figure>

<h2 id="处理-Insert-Only-流"><a href="#处理-Insert-Only-流" class="headerlink" title="处理(Insert-Only)流"></a>处理(Insert-Only)流</h2><p>StreamTableEnvironment提供以下方法来转换和转换 DataStream API:</p>
<ol>
<li>fromDataStream(DataStream)<br>将仅插入更改和任意类型的流解释为表.<br>默认情况下不传播事件时间和水印.</li>
<li>fromDataStream(DataStream, Schema)<br>将仅插入更改和任意类型的流解释为表.<br>可选模式允许丰富列数据类型并添加时间属性/水印策略/其他计算列或主键.</li>
<li>createTemporaryView(String, DataStream)<br>以名称注册流以在 SQL 中访问它.<br>它是createTemporaryView(String, fromDataStream(DataStream)).</li>
<li>createTemporaryView(String, DataStream, Schema)<br>以名称注册流以在 SQL 中访问它.<br>它是createTemporaryView(String, fromDataStream(DataStream, Schema)).</li>
<li>toDataStream(Table)<br>将表转换为仅插入更改的流.<br>默认流记录类型是org.apache.flink.types.Row. 单个行时间属性列被写回到 DataStream API 的记录中.<br>水印也被传播.</li>
<li>toDataStream(Table, AbstractDataType)<br>将表转换为仅插入更改的流.<br>此方法接受一种数据类型来表达所需的流记录类型.<br>规划器可能会插入隐式强制转换和重新排序列以将列映射到(可能是嵌套的)数据类型的字段.</li>
<li>toDataStream(Table, Class)<br>toDataStream(Table, DataTypes.of(Class)) 快速创建所需数据类型的快捷方式.</li>
</ol>
<p>从 Table API 的角度来看,与 DataStream API 之间的转换类似于读取或写入已使用 SQL中的CREATE TABLE DDL定义的虚拟表连接器.</p>
<p>虚拟CREATE TABLE name (schema) WITH (options)语句中的模式部分可以从 DataStream 的类型信息中自动派生/丰富或完全使用 org.apache.flink.table.api.Schema.</p>
<p>虚拟 DataStream 表连接器为每一行公开以下元数据:</p>
<img src="/images/flgl207.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>虚拟 DataStream 表源实现SupportsSourceWatermark 并因此允许调用SOURCE_WATERMARK()内置函数作为水印策略以采用来自 DataStream API 的水印.</p>
<h3 id="fromDataStream示例"><a href="#fromDataStream示例" class="headerlink" title="fromDataStream示例"></a>fromDataStream示例</h3><p>下面的代码展示了如何fromDataStream用于不同的场景.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> java.time.Instant;</span><br><span class="line"></span><br><span class="line"><span class="comment">// some example POJO</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> String name;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> Integer score;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> Instant event_time;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// default constructor for DataStream API</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// fully assigning constructor for Table API</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(String name, Integer score, Instant event_time)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.score = score;</span><br><span class="line">    <span class="keyword">this</span>.event_time = event_time;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a DataStream</span></span><br><span class="line">DataStream&lt;User&gt; dataStream =</span><br><span class="line">    env.fromElements(</span><br><span class="line">        <span class="keyword">new</span> User(<span class="string">&quot;Alice&quot;</span>, <span class="number">4</span>, Instant.ofEpochMilli(<span class="number">1000</span>)),</span><br><span class="line">        <span class="keyword">new</span> User(<span class="string">&quot;Bob&quot;</span>, <span class="number">6</span>, Instant.ofEpochMilli(<span class="number">1001</span>)),</span><br><span class="line">        <span class="keyword">new</span> User(<span class="string">&quot;Alice&quot;</span>, <span class="number">10</span>, Instant.ofEpochMilli(<span class="number">1002</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 1 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// derive all physical columns automatically</span></span><br><span class="line"></span><br><span class="line">Table table = tableEnv.fromDataStream(dataStream);</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `name` STRING,</span></span><br><span class="line"><span class="comment">//  `score` INT,</span></span><br><span class="line"><span class="comment">//  `event_time` TIMESTAMP_LTZ(9)</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 2 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// derive all physical columns automatically</span></span><br><span class="line"><span class="comment">// but add computed columns (in this case for creating a proctime attribute column)</span></span><br><span class="line"></span><br><span class="line">Table table = tableEnv.fromDataStream(</span><br><span class="line">    dataStream,</span><br><span class="line">    Schema.newBuilder()</span><br><span class="line">        .columnByExpression(<span class="string">&quot;proc_time&quot;</span>, <span class="string">&quot;PROCTIME()&quot;</span>)</span><br><span class="line">        .build());</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `name` STRING,</span></span><br><span class="line"><span class="comment">//  `score` INT NOT NULL,</span></span><br><span class="line"><span class="comment">//  `event_time` TIMESTAMP_LTZ(9),</span></span><br><span class="line"><span class="comment">//  `proc_time` TIMESTAMP_LTZ(3) NOT NULL *PROCTIME* AS PROCTIME()</span></span><br><span class="line"><span class="comment">//)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 3 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// derive all physical columns automatically</span></span><br><span class="line"><span class="comment">// but add computed columns (in this case for creating a rowtime attribute column)</span></span><br><span class="line"><span class="comment">// and a custom watermark strategy</span></span><br><span class="line"></span><br><span class="line">Table table =</span><br><span class="line">    tableEnv.fromDataStream(</span><br><span class="line">        dataStream,</span><br><span class="line">        Schema.newBuilder()</span><br><span class="line">            .columnByExpression(<span class="string">&quot;rowtime&quot;</span>, <span class="string">&quot;CAST(event_time AS TIMESTAMP_LTZ(3))&quot;</span>)</span><br><span class="line">            .watermark(<span class="string">&quot;rowtime&quot;</span>, <span class="string">&quot;rowtime - INTERVAL &#x27;10&#x27; SECOND&quot;</span>)</span><br><span class="line">            .build());</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `name` STRING,</span></span><br><span class="line"><span class="comment">//  `score` INT,</span></span><br><span class="line"><span class="comment">//  `event_time` TIMESTAMP_LTZ(9),</span></span><br><span class="line"><span class="comment">//  `rowtime` TIMESTAMP_LTZ(3) *ROWTIME* AS CAST(event_time AS TIMESTAMP_LTZ(3)),</span></span><br><span class="line"><span class="comment">//  WATERMARK FOR `rowtime`: TIMESTAMP_LTZ(3) AS rowtime - INTERVAL &#x27;10&#x27; SECOND</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 4 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// derive all physical columns automatically</span></span><br><span class="line"><span class="comment">// but access the stream record&#x27;s timestamp for creating a rowtime attribute column</span></span><br><span class="line"><span class="comment">// also rely on the watermarks generated in the DataStream API</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// we assume that a watermark strategy has been defined for `dataStream` before</span></span><br><span class="line"><span class="comment">// (not part of this example)</span></span><br><span class="line">Table table =</span><br><span class="line">    tableEnv.fromDataStream(</span><br><span class="line">        dataStream,</span><br><span class="line">        Schema.newBuilder()</span><br><span class="line">            .columnByMetadata(<span class="string">&quot;rowtime&quot;</span>, <span class="string">&quot;TIMESTAMP_LTZ(3)&quot;</span>)</span><br><span class="line">            .watermark(<span class="string">&quot;rowtime&quot;</span>, <span class="string">&quot;SOURCE_WATERMARK()&quot;</span>)</span><br><span class="line">            .build());</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `name` STRING,</span></span><br><span class="line"><span class="comment">//  `score` INT,</span></span><br><span class="line"><span class="comment">//  `event_time` TIMESTAMP_LTZ(9),</span></span><br><span class="line"><span class="comment">//  `rowtime` TIMESTAMP_LTZ(3) *ROWTIME* METADATA,</span></span><br><span class="line"><span class="comment">//  WATERMARK FOR `rowtime`: TIMESTAMP_LTZ(3) AS SOURCE_WATERMARK()</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 5 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// define physical columns manually</span></span><br><span class="line"><span class="comment">// in this example,</span></span><br><span class="line"><span class="comment">//   - we can reduce the default precision of timestamps from 9 to 3</span></span><br><span class="line"><span class="comment">//   - we also project the columns and put `event_time` to the beginning</span></span><br><span class="line"></span><br><span class="line">Table table =</span><br><span class="line">    tableEnv.fromDataStream(</span><br><span class="line">        dataStream,</span><br><span class="line">        Schema.newBuilder()</span><br><span class="line">            .column(<span class="string">&quot;event_time&quot;</span>, <span class="string">&quot;TIMESTAMP_LTZ(3)&quot;</span>)</span><br><span class="line">            .column(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;STRING&quot;</span>)</span><br><span class="line">            .column(<span class="string">&quot;score&quot;</span>, <span class="string">&quot;INT&quot;</span>)</span><br><span class="line">            .watermark(<span class="string">&quot;event_time&quot;</span>, <span class="string">&quot;SOURCE_WATERMARK()&quot;</span>)</span><br><span class="line">            .build());</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `event_time` TIMESTAMP_LTZ(3) *ROWTIME*,</span></span><br><span class="line"><span class="comment">//  `name` VARCHAR(200),</span></span><br><span class="line"><span class="comment">//  `score` INT</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"><span class="comment">// note: the watermark strategy is not shown due to the inserted column reordering projection</span></span><br></pre></td></tr></table></figure>

<p>示例 1 说明了一个不需要基于时间的操作的简单用例.</p>
<p>示例 4 是最常见的用例,当基于时间的操作(例如窗口或间隔连接)应成为管道的一部分时.<br>示例 2 是这些基于时间的操作应该在处理时间内工作的最常见用例.</p>
<p>示例 5 完全依赖于用户的声明.<br>这对于用适当的数据类型替换来自 DataStream API(将RAW在 Table API 中)的泛型类型很有用.</p>
<p>由于DataType比TypeInformation更丰富,我们可以轻松启用不可变 POJO 和其他复杂的数据结构.<br>以下 Java 示例显示了可能的情况.<br>另请查看 DataStream API 的 Data Types &amp; Serialization页面以获取有关那里支持的类型的更多信息.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the DataStream API does not support immutable POJOs yet,</span></span><br><span class="line"><span class="comment">// the class will result in a generic type that is a RAW type in Table API by default</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> Integer score;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(String name, Integer score)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.score = score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a DataStream</span></span><br><span class="line">DataStream&lt;User&gt; dataStream = env.fromElements(</span><br><span class="line">    <span class="keyword">new</span> User(<span class="string">&quot;Alice&quot;</span>, <span class="number">4</span>),</span><br><span class="line">    <span class="keyword">new</span> User(<span class="string">&quot;Bob&quot;</span>, <span class="number">6</span>),</span><br><span class="line">    <span class="keyword">new</span> User(<span class="string">&quot;Alice&quot;</span>, <span class="number">10</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// since fields of a RAW type cannot be accessed, every stream record is treated as an atomic type</span></span><br><span class="line"><span class="comment">// leading to a table with a single column `f0`</span></span><br><span class="line"></span><br><span class="line">Table table = tableEnv.fromDataStream(dataStream);</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `f0` RAW(&#x27;User&#x27;, &#x27;...&#x27;)</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// instead, declare a more useful data type for columns using the Table API&#x27;s type system</span></span><br><span class="line"><span class="comment">// in a custom schema and rename the columns in a following `as` projection</span></span><br><span class="line"></span><br><span class="line">Table table = tableEnv</span><br><span class="line">    .fromDataStream(</span><br><span class="line">        dataStream,</span><br><span class="line">        Schema.newBuilder()</span><br><span class="line">            .column(<span class="string">&quot;f0&quot;</span>, DataTypes.of(User.class))</span><br><span class="line">            .build())</span><br><span class="line">    .as(<span class="string">&quot;user&quot;</span>);</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `user` *User&lt;`name` STRING,`score` INT&gt;*</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// data types can be extracted reflectively as above or explicitly defined</span></span><br><span class="line"></span><br><span class="line">Table table3 = tableEnv</span><br><span class="line">    .fromDataStream(</span><br><span class="line">        dataStream,</span><br><span class="line">        Schema.newBuilder()</span><br><span class="line">            .column(</span><br><span class="line">                <span class="string">&quot;f0&quot;</span>,</span><br><span class="line">                DataTypes.STRUCTURED(</span><br><span class="line">                    User.class,</span><br><span class="line">                    DataTypes.FIELD(<span class="string">&quot;name&quot;</span>, DataTypes.STRING()),</span><br><span class="line">                    DataTypes.FIELD(<span class="string">&quot;score&quot;</span>, DataTypes.INT())))</span><br><span class="line">            .build())</span><br><span class="line">    .as(<span class="string">&quot;user&quot;</span>);</span><br><span class="line">table.printSchema();</span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `user` *User&lt;`name` STRING,`score` INT&gt;*</span></span><br><span class="line"><span class="comment">// )</span></span><br></pre></td></tr></table></figure>

<h3 id="createTemporaryView示例"><a href="#createTemporaryView示例" class="headerlink" title="createTemporaryView示例"></a>createTemporaryView示例</h3><p>DataStream可以直接注册为视图(可能通过模式丰富).</p>
<p>从DataStream创建的视图只能注册为临时视图.<br>由于它们的 inline/anonymous 性质,无法将它们注册到永久目录中.</p>
<p>下面的代码展示了如何createTemporaryView用于不同的场景.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create some DataStream</span></span><br><span class="line">DataStream&lt;Tuple2&lt;Long, String&gt;&gt; dataStream = env.fromElements(</span><br><span class="line">    Tuple2.of(<span class="number">12L</span>, <span class="string">&quot;Alice&quot;</span>),</span><br><span class="line">    Tuple2.of(<span class="number">0L</span>, <span class="string">&quot;Bob&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 1 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// register the DataStream as view &quot;MyView&quot; in the current session</span></span><br><span class="line"><span class="comment">// all columns are derived automatically</span></span><br><span class="line"></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;MyView&quot;</span>, dataStream);</span><br><span class="line"></span><br><span class="line">tableEnv.from(<span class="string">&quot;MyView&quot;</span>).printSchema();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `f0` BIGINT NOT NULL,</span></span><br><span class="line"><span class="comment">//  `f1` STRING</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 2 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// register the DataStream as view &quot;MyView&quot; in the current session,</span></span><br><span class="line"><span class="comment">// provide a schema to adjust the columns similar to `fromDataStream`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// in this example, the derived NOT NULL information has been removed</span></span><br><span class="line"></span><br><span class="line">tableEnv.createTemporaryView(</span><br><span class="line">    <span class="string">&quot;MyView&quot;</span>,</span><br><span class="line">    dataStream,</span><br><span class="line">    Schema.newBuilder()</span><br><span class="line">        .column(<span class="string">&quot;f0&quot;</span>, <span class="string">&quot;BIGINT&quot;</span>)</span><br><span class="line">        .column(<span class="string">&quot;f1&quot;</span>, <span class="string">&quot;STRING&quot;</span>)</span><br><span class="line">        .build());</span><br><span class="line"></span><br><span class="line">tableEnv.from(<span class="string">&quot;MyView&quot;</span>).printSchema();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `f0` BIGINT,</span></span><br><span class="line"><span class="comment">//  `f1` STRING</span></span><br><span class="line"><span class="comment">// )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 3 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// use the Table API before creating the view if it is only about renaming columns</span></span><br><span class="line"></span><br><span class="line">tableEnv.createTemporaryView(</span><br><span class="line">    <span class="string">&quot;MyView&quot;</span>,</span><br><span class="line">    tableEnv.fromDataStream(dataStream).as(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>));</span><br><span class="line"></span><br><span class="line">tableEnv.from(<span class="string">&quot;MyView&quot;</span>).printSchema();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// (</span></span><br><span class="line"><span class="comment">//  `id` BIGINT NOT NULL,</span></span><br><span class="line"><span class="comment">//  `name` STRING</span></span><br><span class="line"><span class="comment">// )</span></span><br></pre></td></tr></table></figure>

<h3 id="toDataStream示例"><a href="#toDataStream示例" class="headerlink" title="toDataStream示例"></a>toDataStream示例</h3><p>下面的代码展示了如何toDataStream用于不同的场景.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"><span class="keyword">import</span> java.time.Instant;</span><br><span class="line"></span><br><span class="line"><span class="comment">// POJO with mutable fields</span></span><br><span class="line"><span class="comment">// since no fully assigning constructor is defined, the field order</span></span><br><span class="line"><span class="comment">// is alphabetical [event_time, name, score]</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Integer score;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Instant event_time;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tableEnv.executeSql(</span><br><span class="line">    <span class="string">&quot;CREATE TABLE GeneratedTable &quot;</span></span><br><span class="line">    + <span class="string">&quot;(&quot;</span></span><br><span class="line">    + <span class="string">&quot;  name STRING,&quot;</span></span><br><span class="line">    + <span class="string">&quot;  score INT,&quot;</span></span><br><span class="line">    + <span class="string">&quot;  event_time TIMESTAMP_LTZ(3),&quot;</span></span><br><span class="line">    + <span class="string">&quot;  WATERMARK FOR event_time AS event_time - INTERVAL &#x27;10&#x27; SECOND&quot;</span></span><br><span class="line">    + <span class="string">&quot;)&quot;</span></span><br><span class="line">    + <span class="string">&quot;WITH (&#x27;connector&#x27;=&#x27;datagen&#x27;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">Table table = tableEnv.from(<span class="string">&quot;GeneratedTable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 1 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// use the default conversion to instances of Row</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// since `event_time` is a single rowtime attribute, it is inserted into the DataStream</span></span><br><span class="line"><span class="comment">// metadata and watermarks are propagated</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Row&gt; dataStream = tableEnv.toDataStream(table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 2 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// a data type is extracted from class `User`,</span></span><br><span class="line"><span class="comment">// the planner reorders fields and inserts implicit casts where possible to convert internal</span></span><br><span class="line"><span class="comment">// data structures to the desired structured type</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// since `event_time` is a single rowtime attribute, it is inserted into the DataStream</span></span><br><span class="line"><span class="comment">// metadata and watermarks are propagated</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;User&gt; dataStream = tableEnv.toDataStream(table, User.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// data types can be extracted reflectively as above or explicitly defined</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;User&gt; dataStream =</span><br><span class="line">    tableEnv.toDataStream(</span><br><span class="line">        table,</span><br><span class="line">        DataTypes.STRUCTURED(</span><br><span class="line">            User.class,</span><br><span class="line">            DataTypes.FIELD(<span class="string">&quot;name&quot;</span>, DataTypes.STRING()),</span><br><span class="line">            DataTypes.FIELD(<span class="string">&quot;score&quot;</span>, DataTypes.INT()),</span><br><span class="line">            DataTypes.FIELD(<span class="string">&quot;event_time&quot;</span>, DataTypes.TIMESTAMP_LTZ(<span class="number">3</span>))));</span><br></pre></td></tr></table></figure>

<p>请注意,toDataStream仅支持非更新表.<br>通常,基于时间的操作(例如windows/interval joins/MATCH_RECOGNIZE子句)非常适合 insert-only管道,以及投影和过滤器等简单操作.</p>
<p>具有产生更新操作的管道可以使用toChangelogStream.</p>
<h2 id="处理变更日志流"><a href="#处理变更日志流" class="headerlink" title="处理变更日志流"></a>处理变更日志流</h2><p>在内部,Flink 的表运行时是一个变更日志处理器.<br>概念页面描述了 动态表和流如何 相互关联.</p>
<p>AStreamTableEnvironment提供以下方法来公开这些变更数据捕获(CDC) 功能:</p>
<ol>
<li>fromChangelogStream(DataStream)<br>将变更日志条目流解释为表格.<br>流记录类型必须是org.apache.flink.types.Row,因为它的RowKind标志是在运行时评估的.<br>默认情况下不传播事件时间和水印.<br>此方法需要一个包含各种更改(在org.apache.flink.types.RowKind中枚举)作为默认值的更改日志ChangelogMode.</li>
<li>fromChangelogStream(DataStream, Schema)<br>允许为DataStream类似于fromDataStream(DataStream, Schema).<br>否则语义等于fromChangelogStream(DataStream).</li>
<li>fromChangelogStream(DataStream, Schema, ChangelogMode)<br>完全控制如何将流解释为变更日志.<br>传递ChangelogMode帮助计划者区分insert-only/ upsert或retract行为.</li>
<li>toChangelogStream(Table)<br>fromChangelogStream(DataStream)的反向操作.<br>它在运行时生成带有实例的流org.apache.flink.types.Row并为每条记录设置RowKind标志.<br>该方法支持各种更新表.<br>如果输入表包含单个行时间列,它将被传播到流记录的时间戳中.<br>水印也将被传播.</li>
<li>toChangelogStream(Table, Schema)<br>fromChangelogStream(DataStream, Schema)的反向操作.<br>该方法可以丰富产生的列数据类型.<br>如有必要,计划者可能会插入隐式强制转换.<br>可以将行时间写为元数据列.</li>
<li>toChangelogStream(Table, Schema, ChangelogMode)<br>完全控制如何将表转换为变更日志流.<br>传递ChangelogMode帮助计划者区分insert-only/ upsert或retract行为.</li>
</ol>
<p>从 Table API 的角度来看,与 DataStream API 之间的转换类似于读取或写入已使用 SQL中的CREATE TABLEDDL定义的虚拟表连接器.</p>
<p>因为fromChangelogStream行为类似于fromDataStream,我们建议在继续之前阅读上一节.</p>
<p>此虚拟连接器还支持读取和写入rowtime流记录的元数据.</p>
<p>虚拟表源实现SupportsSourceWatermark.</p>
<h3 id="fromChangelogStream示例"><a href="#fromChangelogStream示例" class="headerlink" title="fromChangelogStream示例"></a>fromChangelogStream示例</h3><p>下面的代码展示了如何fromChangelogStream用于不同的场景.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.connector.ChangelogMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.RowKind;</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 1 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the stream as a retract stream</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// create a changelog DataStream</span></span><br><span class="line">DataStream&lt;Row&gt; dataStream =</span><br><span class="line">    env.fromElements(</span><br><span class="line">        Row.ofKind(RowKind.INSERT, <span class="string">&quot;Alice&quot;</span>, <span class="number">12</span>),</span><br><span class="line">        Row.ofKind(RowKind.INSERT, <span class="string">&quot;Bob&quot;</span>, <span class="number">5</span>),</span><br><span class="line">        Row.ofKind(RowKind.UPDATE_BEFORE, <span class="string">&quot;Alice&quot;</span>, <span class="number">12</span>),</span><br><span class="line">        Row.ofKind(RowKind.UPDATE_AFTER, <span class="string">&quot;Alice&quot;</span>, <span class="number">100</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the DataStream as a Table</span></span><br><span class="line">Table table = tableEnv.fromChangelogStream(dataStream);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the table under a name and perform an aggregation</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;InputTable&quot;</span>, table);</span><br><span class="line">tableEnv</span><br><span class="line">    .executeSql(<span class="string">&quot;SELECT f0 AS name, SUM(f1) AS score FROM InputTable GROUP BY f0&quot;</span>)</span><br><span class="line">    .print();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// +----+--------------------------------+-------------+</span></span><br><span class="line"><span class="comment">// | op |                           name |       score |</span></span><br><span class="line"><span class="comment">// +----+--------------------------------+-------------+</span></span><br><span class="line"><span class="comment">// | +I |                            Bob |           5 |</span></span><br><span class="line"><span class="comment">// | +I |                          Alice |          12 |</span></span><br><span class="line"><span class="comment">// | -D |                          Alice |          12 |</span></span><br><span class="line"><span class="comment">// | +I |                          Alice |         100 |</span></span><br><span class="line"><span class="comment">// +----+--------------------------------+-------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 2 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the stream as an upsert stream (without a need for UPDATE_BEFORE)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// create a changelog DataStream</span></span><br><span class="line">DataStream&lt;Row&gt; dataStream =</span><br><span class="line">    env.fromElements(</span><br><span class="line">        Row.ofKind(RowKind.INSERT, <span class="string">&quot;Alice&quot;</span>, <span class="number">12</span>),</span><br><span class="line">        Row.ofKind(RowKind.INSERT, <span class="string">&quot;Bob&quot;</span>, <span class="number">5</span>),</span><br><span class="line">        Row.ofKind(RowKind.UPDATE_AFTER, <span class="string">&quot;Alice&quot;</span>, <span class="number">100</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// interpret the DataStream as a Table</span></span><br><span class="line">Table table =</span><br><span class="line">    tableEnv.fromChangelogStream(</span><br><span class="line">        dataStream,</span><br><span class="line">        Schema.newBuilder().primaryKey(<span class="string">&quot;f0&quot;</span>).build(),</span><br><span class="line">        ChangelogMode.upsert());</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the table under a name and perform an aggregation</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;InputTable&quot;</span>, table);</span><br><span class="line">tableEnv</span><br><span class="line">    .executeSql(<span class="string">&quot;SELECT f0 AS name, SUM(f1) AS score FROM InputTable GROUP BY f0&quot;</span>)</span><br><span class="line">    .print();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// +----+--------------------------------+-------------+</span></span><br><span class="line"><span class="comment">// | op |                           name |       score |</span></span><br><span class="line"><span class="comment">// +----+--------------------------------+-------------+</span></span><br><span class="line"><span class="comment">// | +I |                            Bob |           5 |</span></span><br><span class="line"><span class="comment">// | +I |                          Alice |          12 |</span></span><br><span class="line"><span class="comment">// | -U |                          Alice |          12 |</span></span><br><span class="line"><span class="comment">// | +U |                          Alice |         100 |</span></span><br><span class="line"><span class="comment">// +----+--------------------------------+-------------+</span></span><br></pre></td></tr></table></figure>

<p>示例 1 中显示的默认值ChangelogMode对于大多数用例来说应该足够了,因为它接受各种更改.</p>
<p>但是,示例 2 显示了如何通过使用 upsert 模式将更新消息的数量减少 50% 来限制传入更改的种类以提高效率.<br>可以通过为toChangelogStream.</p>
<h3 id="toChangelogStream示例"><a href="#toChangelogStream示例" class="headerlink" title="toChangelogStream示例"></a>toChangelogStream示例</h3><p>下面的代码展示了如何toChangelogStream用于不同的场景.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.data.StringData;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create Table with event-time</span></span><br><span class="line">tableEnv.executeSql(</span><br><span class="line">    <span class="string">&quot;CREATE TABLE GeneratedTable &quot;</span></span><br><span class="line">    + <span class="string">&quot;(&quot;</span></span><br><span class="line">    + <span class="string">&quot;  name STRING,&quot;</span></span><br><span class="line">    + <span class="string">&quot;  score INT,&quot;</span></span><br><span class="line">    + <span class="string">&quot;  event_time TIMESTAMP_LTZ(3),&quot;</span></span><br><span class="line">    + <span class="string">&quot;  WATERMARK FOR event_time AS event_time - INTERVAL &#x27;10&#x27; SECOND&quot;</span></span><br><span class="line">    + <span class="string">&quot;)&quot;</span></span><br><span class="line">    + <span class="string">&quot;WITH (&#x27;connector&#x27;=&#x27;datagen&#x27;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">Table table = tableEnv.from(<span class="string">&quot;GeneratedTable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 1 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// convert to DataStream in the simplest and most general way possible (no event-time)</span></span><br><span class="line"></span><br><span class="line">Table simpleTable = tableEnv</span><br><span class="line">    .fromValues(row(<span class="string">&quot;Alice&quot;</span>, <span class="number">12</span>), row(<span class="string">&quot;Alice&quot;</span>, <span class="number">2</span>), row(<span class="string">&quot;Bob&quot;</span>, <span class="number">12</span>))</span><br><span class="line">    .as(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;score&quot;</span>)</span><br><span class="line">    .groupBy($(<span class="string">&quot;name&quot;</span>))</span><br><span class="line">    .select($(<span class="string">&quot;name&quot;</span>), $(<span class="string">&quot;score&quot;</span>).sum());</span><br><span class="line"></span><br><span class="line">tableEnv</span><br><span class="line">    .toChangelogStream(simpleTable)</span><br><span class="line">    .executeAndCollect()</span><br><span class="line">    .forEachRemaining(System.out::println);</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints:</span></span><br><span class="line"><span class="comment">// +I[Bob, 12]</span></span><br><span class="line"><span class="comment">// +I[Alice, 12]</span></span><br><span class="line"><span class="comment">// -U[Alice, 12]</span></span><br><span class="line"><span class="comment">// +U[Alice, 14]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 2 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// convert to DataStream in the simplest and most general way possible (with event-time)</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Row&gt; dataStream = tableEnv.toChangelogStream(table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// since `event_time` is a single time attribute in the schema, it is set as the</span></span><br><span class="line"><span class="comment">// stream record&#x27;s timestamp by default; however, at the same time, it remains part of the Row</span></span><br><span class="line"></span><br><span class="line">dataStream.process(</span><br><span class="line">    <span class="keyword">new</span> ProcessFunction&lt;Row, Void&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Row row, Context ctx, Collector&lt;Void&gt; out)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">             <span class="comment">// prints: [name, score, event_time]</span></span><br><span class="line">             System.out.println(row.getFieldNames(<span class="keyword">true</span>));</span><br><span class="line"></span><br><span class="line">             <span class="comment">// timestamp exists twice</span></span><br><span class="line">             <span class="keyword">assert</span> ctx.timestamp() == row.&lt;Instant&gt;getFieldAs(<span class="string">&quot;event_time&quot;</span>).toEpochMilli();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 3 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// convert to DataStream but write out the time attribute as a metadata column which means</span></span><br><span class="line"><span class="comment">// it is not part of the physical schema anymore</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Row&gt; dataStream = tableEnv.toChangelogStream(</span><br><span class="line">    table,</span><br><span class="line">    Schema.newBuilder()</span><br><span class="line">        .column(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;STRING&quot;</span>)</span><br><span class="line">        .column(<span class="string">&quot;score&quot;</span>, <span class="string">&quot;INT&quot;</span>)</span><br><span class="line">        .columnByMetadata(<span class="string">&quot;rowtime&quot;</span>, <span class="string">&quot;TIMESTAMP_LTZ(3)&quot;</span>)</span><br><span class="line">        .build());</span><br><span class="line"></span><br><span class="line"><span class="comment">// the stream record&#x27;s timestamp is defined by the metadata; it is not part of the Row</span></span><br><span class="line"></span><br><span class="line">dataStream.process(</span><br><span class="line">    <span class="keyword">new</span> ProcessFunction&lt;Row, Void&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Row row, Context ctx, Collector&lt;Void&gt; out)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// prints: [name, score]</span></span><br><span class="line">            System.out.println(row.getFieldNames(<span class="keyword">true</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// timestamp exists once</span></span><br><span class="line">            System.out.println(ctx.timestamp());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// === EXAMPLE 4 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// for advanced users, it is also possible to use more internal data structures for efficiency</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// note that this is only mentioned here for completeness because using internal data structures</span></span><br><span class="line"><span class="comment">// adds complexity and additional type handling</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// however, converting a TIMESTAMP_LTZ column to `Long` or STRING to `byte[]` might be convenient,</span></span><br><span class="line"><span class="comment">// also structured types can be represented as `Row` if needed</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Row&gt; dataStream = tableEnv.toChangelogStream(</span><br><span class="line">    table,</span><br><span class="line">    Schema.newBuilder()</span><br><span class="line">        .column(</span><br><span class="line">            <span class="string">&quot;name&quot;</span>,</span><br><span class="line">            DataTypes.STRING().bridgedTo(StringData.class))</span><br><span class="line">        .column(</span><br><span class="line">            <span class="string">&quot;score&quot;</span>,</span><br><span class="line">            DataTypes.INT())</span><br><span class="line">        .column(</span><br><span class="line">            <span class="string">&quot;event_time&quot;</span>,</span><br><span class="line">            DataTypes.TIMESTAMP_LTZ(<span class="number">3</span>).bridgedTo(Long.class))</span><br><span class="line">        .build());</span><br><span class="line"></span><br><span class="line"><span class="comment">// leads to a stream of Row(name: StringData, score: Integer, event_time: Long)</span></span><br></pre></td></tr></table></figure>

<p>有关示例 4 中的数据类型支持哪些转换的更多信息,请参阅 Table API 的数据类型页面.</p>
<p>toChangelogStream(Table).executeAndCollect()的行为等于调用Table.execute().collect().<br>但是,toChangelogStream(Table)可能对测试更有用,因为它允许在后续ProcessFunction的 DataStream API 中访问生成的水印.</p>
<h2 id="将-Table-API-管道添加到-DataStream-API"><a href="#将-Table-API-管道添加到-DataStream-API" class="headerlink" title="将 Table API 管道添加到 DataStream API"></a>将 Table API 管道添加到 DataStream API</h2><p>一个 Flink 作业可以由多个彼此相邻运行的断开连接的管道组成.</p>
<p>在 Table API 中定义的 Source-to-sink 管道可以作为一个整体附加到StreamExecutionEnvironment,并且在调用DataStream API中的execute方法之一时将被提交.</p>
<p>但是,源不一定必须是表源,也可以是之前转换为 Table API 的另一个 DataStream 管道.<br>因此,可以为 DataStream API 程序使用表接收器.</p>
<p>该功能可通过使用StreamStatementSet创建的专用实例获得 StreamTableEnvironment.createStatementSet().<br>通过使用语句集,计划者可以一起优化所有添加的语句,并提出一个或多个端到端管道,这些管道 StreamExecutionEnvironment在调用时添加StreamStatementSet.attachAsDataStream().</p>
<p>以下示例显示了如何在一个作业中将表程序添加到 DataStream API 程序.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.DiscardingSink;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.*;</span><br><span class="line"></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line">StreamStatementSet statementSet = tableEnv.createStatementSet();</span><br><span class="line"></span><br><span class="line"><span class="comment">// create some source</span></span><br><span class="line">TableDescriptor sourceDescriptor =</span><br><span class="line">    TableDescriptor.forConnector(<span class="string">&quot;datagen&quot;</span>)</span><br><span class="line">        .option(<span class="string">&quot;number-of-rows&quot;</span>, <span class="string">&quot;3&quot;</span>)</span><br><span class="line">        .schema(</span><br><span class="line">            Schema.newBuilder()</span><br><span class="line">                .column(<span class="string">&quot;myCol&quot;</span>, DataTypes.INT())</span><br><span class="line">                .column(<span class="string">&quot;myOtherCol&quot;</span>, DataTypes.BOOLEAN())</span><br><span class="line">                .build())</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// create some sink</span></span><br><span class="line">TableDescriptor sinkDescriptor = TableDescriptor.forConnector(<span class="string">&quot;print&quot;</span>).build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// add a pure Table API pipeline</span></span><br><span class="line">Table tableFromSource = tableEnv.from(sourceDescriptor);</span><br><span class="line">statementSet.add(tableFromSource.insertInto(sinkDescriptor));</span><br><span class="line"></span><br><span class="line"><span class="comment">// use table sinks for the DataStream API pipeline</span></span><br><span class="line">DataStream&lt;Integer&gt; dataStream = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">Table tableFromStream = tableEnv.fromDataStream(dataStream);</span><br><span class="line">statementSet.add(tableFromStream.insertInto(sinkDescriptor));</span><br><span class="line"></span><br><span class="line"><span class="comment">// attach both pipelines to StreamExecutionEnvironment</span></span><br><span class="line"><span class="comment">// (the statement set will be cleared after calling this method)</span></span><br><span class="line">statementSet.attachAsDataStream();</span><br><span class="line"></span><br><span class="line"><span class="comment">// define other DataStream API parts</span></span><br><span class="line">env.fromElements(<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>).addSink(<span class="keyword">new</span> DiscardingSink&lt;&gt;());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use DataStream API to submit the pipelines</span></span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// prints similar to:</span></span><br><span class="line"><span class="comment">// +I[1618440447, false]</span></span><br><span class="line"><span class="comment">// +I[1259693645, true]</span></span><br><span class="line"><span class="comment">// +I[158588930, false]</span></span><br><span class="line"><span class="comment">// +I[1]</span></span><br><span class="line"><span class="comment">// +I[2]</span></span><br><span class="line"><span class="comment">// +I[3]</span></span><br></pre></td></tr></table></figure>

<h2 id="Scala-中的隐式转换"><a href="#Scala-中的隐式转换" class="headerlink" title="Scala 中的隐式转换"></a>Scala 中的隐式转换</h2><h2 id="TypeInformation-DataType-之间的映射"><a href="#TypeInformation-DataType-之间的映射" class="headerlink" title="TypeInformation/DataType 之间的映射"></a>TypeInformation/DataType 之间的映射</h2><p>DataStream API 使用实例org.apache.flink.api.common.typeinfo.TypeInformation来描述在流中传输的记录类型.<br>特别是,它定义了如何将记录从一个 DataStream 运算符序列化和反序列化到另一个.<br>它还有助于将状态序列化为保存点和检查点.</p>
<p>Table API 使用自定义数据结构在内部表示记录,org.apache.flink.table.types.DataType 并向用户公开以声明将数据结构转换为的外部格式,以便在sources/sinks/UDFs/DataStream API 中使用.</p>
<p>DataType比它更丰富,TypeInformation因为它还包括有关逻辑 SQL 类型的详细信息.<br>因此,在转换过程中会隐式添加一些细节.</p>
<p>Table的列名和类型自动从DataStream的TypeInformation驱动.用于DataStream.getType()检查是否已通过 DataStream API 的反射类型提取工具正确检测到类型信息.<br>如果最外面的记录 TypeInformation是 a CompositeType,则在派生表的模式时它将在第一级展平.</p>
<p>DataStream API 并不总是能够TypeInformation根据反射提取更具体的内容.<br>这通常会悄无声息地发生GenericTypeInfo,并得到通用 Kryo 序列化程序的支持.</p>
<p>例如,Row无法对类进行反射分析,并且始终需要明确的类型信息声明.<br>如果 DataStream API 中没有声明正确的类型信息,则该行将显示为RAW 数据类型,并且 Table API 无法访问其字段.<br>.map(...).returns(TypeInformation) 在 Java 或.map(...)(TypeInformation)Scala 中使用以显式声明类型信息.</p>
<h3 id="TypeInformation-到-DataType"><a href="#TypeInformation-到-DataType" class="headerlink" title="TypeInformation 到 DataType"></a>TypeInformation 到 DataType</h3><p>TypeInformation转换为DataType时适用以下规则:</p>
<ol>
<li>TypeInformation的所有子类都映射到逻辑类型,包括与 Flink 内置序列化器对齐的可空性.</li>
<li>TupleTypeInfoBase的子类被转换为行(for Row)或结构化类型(用于tuples/POJOs/case classes).</li>
<li>BigDecimal默认转换为DECIMAL(38, 18).</li>
<li>PojoTypeInfo字段的顺序由以所有字段作为参数的构造函数确定.<br>如果在转换过程中未找到,则字段顺序将按字母顺序排列.</li>
<li>GenericTypeInfo其他TypeInformation不能表示为org.apache.flink.table.api.DataTypes所列之一的将被视为黑盒RAW类型.<br>当前会话配置用于实现原始类型的序列化程序.<br>届时将无法访问复合嵌套字段.</li>
</ol>
<p>用于DataTypes.of(TypeInformation)在自定义模式声明或 UDF 中调用上述逻辑.</p>
<h3 id="DataType-到-TypeInformation"><a href="#DataType-到-TypeInformation" class="headerlink" title="DataType 到 TypeInformation"></a>DataType 到 TypeInformation</h3><p>表运行时将确保正确地将输出记录序列化到 DataStream API 的第一个运算符.</p>
<h2 id="旧版转换"><a href="#旧版转换" class="headerlink" title="旧版转换"></a>旧版转换</h2><p>以下部分描述了 API 中将在未来版本中删除的过时部分.</p>
<p>特别是,这些部分可能没有很好地集成到许多最近的新特性和重构中(例如RowKind,没有正确设置,类型系统不能顺利集成).</p>
<h3 id="将-DataStream-转换成表"><a href="#将-DataStream-转换成表" class="headerlink" title="将 DataStream 转换成表"></a>将 DataStream 转换成表</h3><p>DataStream 可以直接转换为 StreamTableEnvironment 中的 Table.<br>结果视图的架构取决于注册集合的数据类型.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; </span><br><span class="line">DataStream&lt;Tuple2&lt;Long, String&gt;&gt; stream = ...;</span><br><span class="line"></span><br><span class="line">Table table2 = tableEnv.fromDataStream(stream, $(<span class="string">&quot;myLong&quot;</span>), $(<span class="string">&quot;myString&quot;</span>));</span><br></pre></td></tr></table></figure>

<h3 id="将表转换成-DataStream"><a href="#将表转换成-DataStream" class="headerlink" title="将表转换成 DataStream"></a>将表转换成 DataStream</h3><p>Table 可以被转换成 DataStream.<br>通过这种方式,定制的 DataStream 程序就可以在 Table API 或者 SQL 的查询结果上运行了.</p>
<p>将 Table 转换为 DataStream 时,你需要指定生成的 DataStream 的数据类型,即,Table 的每行数据要转换成的数据类型.<br>通常最方便的选择是转换成 Row .<br>以下列表概述了不同选项的功能:</p>
<ol>
<li>Row: 字段按位置映射,字段数量任意,支持 null 值,无类型安全(type-safe)检查.</li>
<li>POJO: 字段按名称映射(POJO 必须按Table 中字段名称命名),字段数量任意,支持 null 值,无类型安全检查.</li>
<li>Case Class: 字段按位置映射,不支持 null 值,有类型安全检查.</li>
<li>Tuple: 字段按位置映射,字段数量少于 22(Scala)或者 25(Java),不支持 null 值,无类型安全检查.</li>
<li>Atomic Type: Table 必须有一个字段,不支持 null 值,有类型安全检查.</li>
</ol>
<h4 id="将表转换成-DataStream-1"><a href="#将表转换成-DataStream-1" class="headerlink" title="将表转换成 DataStream"></a>将表转换成 DataStream</h4><p>流式查询(streaming query)的结果表会动态更新,即,当新纪录到达查询的输入流时,查询结果会改变.<br>因此,像这样将动态查询结果转换成 DataStream 需要对表的更新方式进行编码.</p>
<p>将 Table 转换为 DataStream 有两种模式:</p>
<ol>
<li>Append Mode: 仅当动态 Table 仅通过INSERT更改进行修改时,才可以使用此模式,即,它仅是追加操作,并且之前输出的结果永远不会更新.</li>
<li>Retract Mode: 任何情形都可以使用此模式.<br>它使用 boolean 值对 INSERT 和 DELETE 操作的数据进行标记.<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; </span><br><span class="line"></span><br><span class="line">Table table = tableEnv.fromValues(</span><br><span class="line">    DataTypes.Row(</span><br><span class="line">        DataTypes.FIELD(<span class="string">&quot;name&quot;</span>, DataTypes.STRING()),</span><br><span class="line">        DataTypes.FIELD(<span class="string">&quot;age&quot;</span>, DataTypes.INT()),</span><br><span class="line">    row(<span class="string">&quot;john&quot;</span>, <span class="number">35</span>),</span><br><span class="line">    row(<span class="string">&quot;sarah&quot;</span>, <span class="number">32</span>)</span><br><span class="line">    )</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert the Table into an append DataStream of Row by specifying the class</span></span><br><span class="line">DataStream&lt;Row&gt; dsRow = tableEnv.toAppendStream(table, Row.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert the Table into an append DataStream of Tuple2&lt;String, Integer&gt; with TypeInformation</span></span><br><span class="line">TupleTypeInfo&lt;Tuple2&lt;String, Integer&gt;&gt; tupleType = <span class="keyword">new</span> TupleTypeInfo&lt;&gt;(Types.STRING(), Types.INT());</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dsTuple = tableEnv.toAppendStream(table, tupleType);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert the Table into a retract DataStream of Row.</span></span><br><span class="line"><span class="comment">// A retract stream of type X is a DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;. </span></span><br><span class="line"><span class="comment">// The boolean field indicates the type of the change. </span></span><br><span class="line"><span class="comment">// True is INSERT, false is DELETE.</span></span><br><span class="line">DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; retractStream = tableEnv.toRetractStream(table, Row.class);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>注意 一旦 Table 被转化为 DataStream,必须使用 StreamExecutionEnvironment 的 execute 方法执行该 DataStream 作业.</p>
<h3 id="数据类型到-Table-Schema-的映射"><a href="#数据类型到-Table-Schema-的映射" class="headerlink" title="数据类型到 Table Schema 的映射"></a>数据类型到 Table Schema 的映射</h3><p>Flink 的 DataStream API 支持多样的数据类型.<br>例如 Tuple(Scala 内置,Flink Java tuple 和 Python tuples)/POJO 类型/Scala case class 类型以及 Flink 的 Row 类型等允许嵌套且有多个可在表的表达式中访问的字段的复合数据类型.<br>其他类型被视为原子类型.<br>下面,我们讨论 Table API 如何将这些数据类型类型转换为内部 row 表示形式,并提供将 DataStream 转换成 Table 的样例.</p>
<p>数据类型到 table schema 的映射有两种方式:基于字段位置或基于字段名称.</p>
<h4 id="基于位置映射"><a href="#基于位置映射" class="headerlink" title="基于位置映射"></a>基于位置映射</h4><p>基于位置的映射可在保持字段顺序的同时为字段提供更有意义的名称.<br>这种映射方式可用于具有特定的字段顺序的复合数据类型以及原子类型.<br>如 tuple/row 以及 case class 这些复合数据类型都有这样的字段顺序.<br>然而,POJO 类型的字段则必须通过名称映射(参见下一章).<br>可以将字段投影出来,但不能使用as(Java 和 Scala) 或者 alias(Python)重命名.</p>
<p>定义基于位置的映射时,输入数据类型中一定不能存在指定的名称,否则 API 会假定应该基于字段名称进行映射.<br>如果未指定任何字段名称,则使用默认的字段名称和复合数据类型的字段顺序,或者使用 f0 表示原子类型.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; <span class="comment">// see &quot;Create a TableEnvironment&quot; section;</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;Long, Integer&gt;&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with field &quot;myLong&quot; only</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;myLong&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with field names &quot;myLong&quot; and &quot;myInt&quot;</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;myLong&quot;</span>), $(<span class="string">&quot;myInt&quot;</span>));</span><br></pre></td></tr></table></figure>

<h4 id="基于名称的映射"><a href="#基于名称的映射" class="headerlink" title="基于名称的映射"></a>基于名称的映射</h4><p>基于名称的映射适用于任何数据类型包括 POJO 类型.<br>这是定义 table schema 映射最灵活的方式.<br>映射中的所有字段均按名称引用,并且可以通过 as 重命名.<br>字段可以被重新排序和映射.</p>
<p>若果没有指定任何字段名称,则使用默认的字段名称和复合数据类型的字段顺序,或者使用 f0 表示原子类型.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; <span class="comment">// see &quot;Create a TableEnvironment&quot; section</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;Long, Integer&gt;&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with field &quot;f1&quot; only</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;f1&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with swapped fields</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;f1&quot;</span>), $(<span class="string">&quot;f0&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with swapped fields and field names &quot;myInt&quot; and &quot;myLong&quot;</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;f1&quot;</span>).as(<span class="string">&quot;myInt&quot;</span>), $(<span class="string">&quot;f0&quot;</span>).as(<span class="string">&quot;myLong&quot;</span>));</span><br></pre></td></tr></table></figure>

<h4 id="原子类型"><a href="#原子类型" class="headerlink" title="原子类型"></a>原子类型</h4><p>Flink 将基础数据类型(Integer/Double/String)或者通用数据类型(不可再拆分的数据类型)视为原子类型.<br>原子类型的 DataStream 会被转换成只有一条属性的 Table.<br>属性的数据类型可以由原子类型推断出,还可以重新命名属性.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...;</span><br><span class="line"></span><br><span class="line">DataStream&lt;Long&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert DataStream into Table with field name &quot;myLong&quot;</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;myLong&quot;</span>));</span><br></pre></td></tr></table></figure>

<h4 id="Tuple类型-Scala-Java-和-Python-和-Case-Class类型-仅-Scala"><a href="#Tuple类型-Scala-Java-和-Python-和-Case-Class类型-仅-Scala" class="headerlink" title="Tuple类型(Scala , Java 和 Python)和 Case Class类型(仅 Scala)"></a>Tuple类型(Scala , Java 和 Python)和 Case Class类型(仅 Scala)</h4><p>Flink 支持 Scala 的内置 tuple 类型并给 Java 提供自己的 tuple 类型.<br>两种 tuple 的 DataStream 都能被转换成表.<br>可以通过提供所有字段名称来重命名字段(基于位置映射).<br>如果没有指明任何字段名称,则会使用默认的字段名称.<br>如果引用了原始字段名称(对于 Flink tuple 为f0/f1 … …,对于 Scala tuple 为_1/_2 … …),则 API 会假定映射是基于名称的而不是基于位置的.<br>基于名称的映射可以通过 as 对字段和投影进行重新排序.</p>
<p>Flink 给 Java 提供自己的 tuple 类型.<br>tuple 的 DataStream 都能被转换成表.<br>可以通过提供所有字段名称来重命名字段(基于位置映射).<br>如果没有指明任何字段名称,则会使用默认的字段名称.<br>如果引用了原始字段名称(对于 Flink tuple 为f0/f1 … …),则 API 会假定映射是基于名称的而不是基于位置的.<br>基于名称的映射可以通过 as 对字段和投影进行重新排序.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; <span class="comment">// see &quot;Create a TableEnvironment&quot; section</span></span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;Long, String&gt;&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with renamed field names &quot;myLong&quot;, &quot;myString&quot; (position-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;myLong&quot;</span>), $(<span class="string">&quot;myString&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with reordered fields &quot;f1&quot;, &quot;f0&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;f1&quot;</span>), $(<span class="string">&quot;f0&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with projected field &quot;f1&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;f1&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with reordered and aliased fields &quot;myString&quot;, &quot;myLong&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;f1&quot;</span>).as(<span class="string">&quot;myString&quot;</span>), $(<span class="string">&quot;f0&quot;</span>).as(<span class="string">&quot;myLong&quot;</span>));</span><br></pre></td></tr></table></figure>

<h4 id="POJO-类型-Java-和-Scala"><a href="#POJO-类型-Java-和-Scala" class="headerlink" title="POJO 类型 (Java 和 Scala)"></a>POJO 类型 (Java 和 Scala)</h4><p>Flink 支持 POJO 类型作为复合类型.<br>确定 POJO 类型的规则记录在这里.</p>
<p>在不指定字段名称的情况下将 POJO 类型的 DataStream 转换成 Table 时,将使用原始 POJO 类型字段的名称.<br>名称映射需要原始名称,并且不能按位置进行.<br>字段可以使用别名(带有 as 关键字)来重命名,重新排序和投影.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; <span class="comment">// see &quot;Create a TableEnvironment&quot; section</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Person is a POJO with fields &quot;name&quot; and &quot;age&quot;</span></span><br><span class="line">DataStream&lt;Person&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with renamed fields &quot;myAge&quot;, &quot;myName&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;age&quot;</span>).as(<span class="string">&quot;myAge&quot;</span>), $(<span class="string">&quot;name&quot;</span>).as(<span class="string">&quot;myName&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with projected field &quot;name&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert DataStream into Table with projected and renamed field &quot;myName&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;name&quot;</span>).as(<span class="string">&quot;myName&quot;</span>));</span><br></pre></td></tr></table></figure>

<h4 id="Row类型"><a href="#Row类型" class="headerlink" title="Row类型"></a>Row类型</h4><p>Row 类型支持任意数量的字段以及具有 null 值的字段.<br>字段名称可以通过 RowTypeInfo 指定,也可以在将 Row 的 DataStream 转换为 Table 时指定.<br>Row 类型的字段映射支持基于名称和基于位置两种方式.<br>字段可以通过提供所有字段的名称的方式重命名(基于位置映射)或者分别选择进行投影/排序/重命名(基于名称映射).</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">StreamTableEnvironment tableEnv = ...; </span><br><span class="line"></span><br><span class="line"><span class="comment">// DataStream of Row with two fields &quot;name&quot; and &quot;age&quot; specified in `RowTypeInfo`</span></span><br><span class="line">DataStream&lt;Row&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert DataStream into Table with renamed field names &quot;myName&quot;, &quot;myAge&quot; (position-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;myName&quot;</span>), $(<span class="string">&quot;myAge&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert DataStream into Table with renamed fields &quot;myName&quot;, &quot;myAge&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;name&quot;</span>).as(<span class="string">&quot;myName&quot;</span>), $(<span class="string">&quot;age&quot;</span>).as(<span class="string">&quot;myAge&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert DataStream into Table with projected field &quot;name&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert DataStream into Table with projected and renamed field &quot;myName&quot; (name-based)</span></span><br><span class="line">Table table = tableEnv.fromDataStream(stream, $(<span class="string">&quot;name&quot;</span>).as(<span class="string">&quot;myName&quot;</span>));</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/flink/" rel="tag"># flink</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/08/22/flink%20sql/" rel="prev" title="flink sql">
                  <i class="fa fa-chevron-left"></i> flink sql
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/22/flink%20sql-%E5%87%BD%E6%95%B0/" rel="next" title="flink sql-函数">
                  flink sql-函数 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
