<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maoeryu.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.1","exturl":false,"sidebar":{"position":"left","width":200,"display":"post","padding":7,"offset":5},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>
<meta name="description" content="配置:对于全局配置,通过设置$FLINK_HOME&#x2F;conf&#x2F;flink-conf.yaml.对于每个作业配置,通过Table Option设置.写入数据:Flink 支持不同的写入模式,例如CDC Ingestion&#x2F;Bulk Insert&#x2F;Index Bootstrap&#x2F;Changelog Mode和Append Mode.查询数据:Flink 支持不同的读取模式,例如Streaming Qu">
<meta property="og:type" content="article">
<meta property="og:title" content="hudi集成flink">
<meta property="og:url" content="https://maoeryu.github.io/2022/10/17/hudi%E9%9B%86%E6%88%90flink/index.html">
<meta property="og:site_name" content="FlyingPig">
<meta property="og:description" content="配置:对于全局配置,通过设置$FLINK_HOME&#x2F;conf&#x2F;flink-conf.yaml.对于每个作业配置,通过Table Option设置.写入数据:Flink 支持不同的写入模式,例如CDC Ingestion&#x2F;Bulk Insert&#x2F;Index Bootstrap&#x2F;Changelog Mode和Append Mode.查询数据:Flink 支持不同的读取模式,例如Streaming Qu">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1061.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1062.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1063.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1064.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1065.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1066.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1067.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1218.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1219.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1220.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1221.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1222.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1223.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1224.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1225.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1226.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1227.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1228.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1229.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1230.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1231.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1232.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1235.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1233.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1234.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1236.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1237.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1238.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1239.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1240.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1125.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1126.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1128.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1129.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1074.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1075.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1186.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1073.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1127.png">
<meta property="og:image" content="https://maoeryu.github.io/images/fly1187.png">
<meta property="article:published_time" content="2022-10-16T16:00:00.000Z">
<meta property="article:modified_time" content="2022-11-07T07:23:09.984Z">
<meta property="article:author" content="maoeryu">
<meta property="article:tag" content="flink">
<meta property="article:tag" content="hudi">
<meta property="article:tag" content="hive">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://maoeryu.github.io/images/fly1061.png">


<link rel="canonical" href="https://maoeryu.github.io/2022/10/17/hudi%E9%9B%86%E6%88%90flink/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>hudi集成flink | FlyingPig</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlyingPig</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"><span class="nav-number">1.</span> <span class="nav-text">快速开始</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sql"><span class="nav-number">1.1.</span> <span class="nav-text">sql</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.1.1.</span> <span class="nav-text">设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BB%BA%E8%A1%A8%E6%96%B9%E5%BC%8F"><span class="nav-number">1.1.2.</span> <span class="nav-text">建表方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD-%E4%B8%8D%E5%90%8C%E6%AD%A5Hive%E8%A1%A8"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">建在内存中,不同步Hive表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="nav-number">1.1.2.1.1.</span> <span class="nav-text">创建表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E8%A1%A8%E5%8F%8A%E7%BB%93%E6%9E%84"><span class="nav-number">1.1.2.1.2.</span> <span class="nav-text">查看表及结构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.2.1.3.</span> <span class="nav-text">插入数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.2.1.4.</span> <span class="nav-text">查询数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.2.1.5.</span> <span class="nav-text">更新数据</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E5%9C%A8Hive-Catalog%E4%B8%AD-%E4%B8%8D%E5%90%8C%E6%AD%A5Hive%E8%A1%A8"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">建在Hive Catalog中,不同步Hive表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD-%E5%90%8C%E6%AD%A5Hive%E8%A1%A8"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">建在内存中,同步Hive表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#mor"><span class="nav-number">1.1.2.3.1.</span> <span class="nav-text">mor</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#cow"><span class="nav-number">1.1.2.3.2.</span> <span class="nav-text">cow</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E5%9C%A8Hive-Catalog%E4%B8%AD-%E5%90%8C%E6%AD%A5Hive%E8%A1%A8"><span class="nav-number">1.1.2.4.</span> <span class="nav-text">建在Hive Catalog中,同步Hive表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#mor-1"><span class="nav-number">1.1.2.4.1.</span> <span class="nav-text">mor</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#cow-1"><span class="nav-number">1.1.2.4.2.</span> <span class="nav-text">cow</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E8%BF%87Hudi-HMS-Catalog%E8%AF%BB%E5%86%99Hudi%E5%B9%B6%E5%90%8C%E6%AD%A5Hive%E8%A1%A8"><span class="nav-number">1.1.2.5.</span> <span class="nav-text">通过Hudi HMS Catalog读写Hudi并同步Hive表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAFlink-Hudi-HMS-Catalog"><span class="nav-number">1.1.2.5.1.</span> <span class="nav-text">创建Flink Hudi HMS Catalog</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#mor-2"><span class="nav-number">1.1.2.5.2.</span> <span class="nav-text">mor</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#cow-2"><span class="nav-number">1.1.2.5.3.</span> <span class="nav-text">cow</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E9%AA%8C%E8%AF%81"><span class="nav-number">1.1.2.5.4.</span> <span class="nav-text">一致性验证</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%81%E5%BC%8F%E6%9F%A5%E8%AF%A2"><span class="nav-number">1.1.3.</span> <span class="nav-text">流式查询</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8-1"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">创建表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE-1"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">查询数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE-1"><span class="nav-number">1.1.3.3.</span> <span class="nav-text">插入数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.3.4.</span> <span class="nav-text">删除数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#java"><span class="nav-number">1.2.</span> <span class="nav-text">java</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE-2"><span class="nav-number">1.2.2.</span> <span class="nav-text">插入数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE-2"><span class="nav-number">1.2.3.</span> <span class="nav-text">查询数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%81%E5%A4%84%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">流处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sql-1"><span class="nav-number">2.1.</span> <span class="nav-text">sql</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8-2"><span class="nav-number">2.1.1.</span> <span class="nav-text">创建表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2"><span class="nav-number">2.1.2.</span> <span class="nav-text">数据转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E5%85%A5hudi"><span class="nav-number">2.1.3.</span> <span class="nav-text">写入hudi</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE-3"><span class="nav-number">2.1.4.</span> <span class="nav-text">查询数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#java-1"><span class="nav-number">2.2.</span> <span class="nav-text">java</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pom"><span class="nav-number">2.2.1.</span> <span class="nav-text">pom</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E5%85%A5hudi-1"><span class="nav-number">2.2.2.</span> <span class="nav-text">写入hudi</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE-4"><span class="nav-number">2.2.3.</span> <span class="nav-text">查询数据</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">maoeryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">222</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://maoeryu.github.io/2022/10/17/hudi%E9%9B%86%E6%88%90flink/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="maoeryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlyingPig">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hudi集成flink
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-10-17 00:00:00" itemprop="dateCreated datePublished" datetime="2022-10-17T00:00:00+08:00">2022-10-17</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-11-07 15:23:09" itemprop="dateModified" datetime="2022-11-07T15:23:09+08:00">2022-11-07</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%8F%E5%90%8C%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">协同框架</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%8F%E5%90%8C%E6%A1%86%E6%9E%B6/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>配置:对于全局配置,通过设置<code>$FLINK_HOME/conf/flink-conf.yaml</code>.对于每个作业配置,通过<code>Table Option</code>设置.<br>写入数据:Flink 支持不同的写入模式,例如<code>CDC Ingestion</code>/<code>Bulk Insert</code>/<code>Index Bootstrap</code>/<code>Changelog Mode</code>和<code>Append Mode</code>.<br>查询数据:Flink 支持不同的读取模式,例如<code>Streaming Query</code>和<code>Incremental Query</code>.<br>调优:对于写/读任务,例如<code>内存优化</code>和<code>写入速率限制</code>.<br>优化:支持<code>离线压缩</code>.<br>查询引擎:除了 Flink,还集成了很多其他引擎:<code>Hive Query</code>/<code>Presto Query</code>.</p>
<p>hadoop:存储数据<br>hudi:管理数据<br>flink:插入和查询数据</p>
<p>flink 1.15.2<br>hudi 0.12.1</p>
<p>将以下包放入<code>$FLINK_HOME/lib</code>下.<br>hudi-flink1.15-bundle-0.12.1.jar(集成hive时,需要编译hudi)<br>flink-sql-connector-kafka-1.15.2.jar<br>flink-table-common-1.15.2.jar</p>
<span id="more"></span>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><h2 id="sql"><a href="#sql" class="headerlink" title="sql"></a>sql</h2><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/sql-client.sh embedded</span><br></pre></td></tr></table></figure>

<p>jar包未放入到lib下时,通过参数-j xxx.jar指定jar包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/sql-client.sh embedded \</span><br><span class="line">-j /xxx/xxx/hudi-flink1.15-bundle-0.12.0.jar shell</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--设置表模式</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">&#x27;sql-client.execution.result-mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;tableau&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>建议使用 hadoop 2.9.x+ 版本,因为某些对象存储只有在此之后才有文件系统实现<br>flink-parquet 和 flink-avro 格式已经打包到 hudi-flink-bundle jar 中.</p>
<h3 id="建表方式"><a href="#建表方式" class="headerlink" title="建表方式"></a>建表方式</h3><h4 id="建在内存中-不同步Hive表"><a href="#建在内存中-不同步Hive表" class="headerlink" title="建在内存中,不同步Hive表"></a>建在内存中,不同步Hive表</h4><p>这种建表方式,元数据在内存中,退出SQL客户端后,需要重新建表(表数据文件还在).<br>通过Flink查询出来的结果是没有Hudi的元数据字段的.</p>
<h5 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h5><p>创建表t1,数据存储到Hudi表中,底层HDFS存储,表的类型:MOR.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1(</span><br><span class="line">  <span class="comment">--uuid VARCHAR(20) PRIMARY KEY NOT ENFORCED,</span></span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `dt` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`dt`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;write.tasks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;compaction.tasks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>可以设置其它属性.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#39;hoodie.datasource.write.keygenerator.class&#39; &#x3D; &#39;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#39;,</span><br><span class="line">&#39;hoodie.datasource.write.recordkey.field&#39; &#x3D; &#39;uuid&#39;,</span><br><span class="line">&#39;hoodie.datasource.write.hive_style_partitioning&#39; &#x3D; &#39;true&#39;</span><br></pre></td></tr></table></figure>

<p>PRIMARY KEY和<code>hoodie.datasource.write.recordkey.field</code>作用相同,联合主键时,可以单独放在最后.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink1 (</span><br><span class="line">  id1 <span class="type">int</span>,</span><br><span class="line">  id2 <span class="type">int</span>,</span><br><span class="line">  ...</span><br><span class="line">  dt <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (id1, id2) <span class="keyword">NOT</span> ENFORCED</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h5 id="查看表及结构"><a href="#查看表及结构" class="headerlink" title="查看表及结构"></a>查看表及结构</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Flink SQL&gt; desc t1;</span><br><span class="line">+------+--------------+------+-----+--------+-----------+</span><br><span class="line">| name |         type | null | key | extras | watermark |</span><br><span class="line">+------+--------------+------+-----+--------+-----------+</span><br><span class="line">| uuid |  VARCHAR(20) | TRUE |     |        |           |</span><br><span class="line">| name |  VARCHAR(10) | TRUE |     |        |           |</span><br><span class="line">|  age |          INT | TRUE |     |        |           |</span><br><span class="line">|   ts | TIMESTAMP(3) | TRUE |     |        |           |</span><br><span class="line">|   dt |  VARCHAR(20) | TRUE |     |        |           |</span><br><span class="line">+------+--------------+------+-----+--------+-----------+</span><br><span class="line">5 rows in set</span><br></pre></td></tr></table></figure>

<h5 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h5><p>向t1中插入数据,其中t1表为分区表,字段名称:dt,插入数据时字段值有:<code>part1/part2/part3/part4</code>.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span></span><br><span class="line">(<span class="string">&#x27;id1&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span></span><br><span class="line">(<span class="string">&#x27;id2&#x27;</span>,<span class="string">&#x27;Stephen&#x27;</span>,<span class="number">33</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:02&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;id3&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par2&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;id4&#x27;</span>,<span class="string">&#x27;Fabian&#x27;</span>,<span class="number">31</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:04&#x27;</span>,<span class="string">&#x27;par2&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;id5&#x27;</span>,<span class="string">&#x27;Sophia&#x27;</span>,<span class="number">18</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:05&#x27;</span>,<span class="string">&#x27;par3&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;id6&#x27;</span>,<span class="string">&#x27;Emma&#x27;</span>,<span class="number">20</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:06&#x27;</span>,<span class="string">&#x27;par3&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;id7&#x27;</span>,<span class="string">&#x27;Bob&#x27;</span>,<span class="number">44</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:07&#x27;</span>,<span class="string">&#x27;par4&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;id8&#x27;</span>,<span class="string">&#x27;Han&#x27;</span>,<span class="number">56</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:08&#x27;</span>,<span class="string">&#x27;par4&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="/images/fly1061.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1062.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>查询HDFS上数据存储目录.<br><img src="/images/fly1063.png" style="margin-left: 0px; padding-bottom: 10px;"><br><img src="/images/fly1064.png" style="margin-left: 0px; padding-bottom: 10px;"></p>
<h5 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> <span class="string">&#x27;sql-client.execution.result-mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;table&#x27;</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1065.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>通过在 WHERE 子句中添加 partition 路径来裁剪 partition.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> <span class="string">&#x27;sql-client.execution.result-mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;tableau&#x27;</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 <span class="keyword">where</span> `<span class="keyword">partition</span>` <span class="operator">=</span> <span class="string">&#x27;par1&#x27;</span> ;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1066.png" style="margin-left: 0px; padding-bottom: 10px;">

<h5 id="更新数据"><a href="#更新数据" class="headerlink" title="更新数据"></a>更新数据</h5><p>将id1的数据age由23变为了27.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span> (<span class="string">&#x27;id1&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">27</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="/images/fly1067.png" style="margin-left: 0px; padding-bottom: 10px;">

<h4 id="建在Hive-Catalog中-不同步Hive表"><a href="#建在Hive-Catalog中-不同步Hive表" class="headerlink" title="建在Hive Catalog中,不同步Hive表"></a>建在Hive Catalog中,不同步Hive表</h4><p>这种建表方式,会在对应的Hive中创建表.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">CREATE</span> CATALOG hive_catalog <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hive&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;default-database&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;default&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive-conf-dir&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/opt/hive/conf&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">use catalog hive_catalog;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink2 (</span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `dt` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`dt`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;uuid&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink2 <span class="keyword">values</span> (<span class="string">&#x27;id1&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>),(<span class="string">&#x27;id3&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par2&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink2;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1218.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1219.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1220.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1221.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>当退出SQL客户端后,再重新启动一个新的SQL客户端,可以直接使用Hive Catalog中的表,进行读写数据.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> CATALOG hive_catalog <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hive&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;default-database&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;default&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive-conf-dir&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/opt/hive/conf&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">use catalog hive_catalog;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink2;</span><br></pre></td></tr></table></figure>

<p>同样地也无法查询Hudi的元数据字段.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> test_hudi_flink2;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `hive_catalog`.`<span class="keyword">default</span>`.`test_hudi_flink2` (</span><br><span class="line">  `uuid` <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">  `name` <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  `age` <span class="type">INT</span>,</span><br><span class="line">  `ts` <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `dt` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (`dt`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;uuid&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br></pre></td></tr></table></figure>

<p>在Hive中查询此表时报错.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">default</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.016</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> test_hudi_flink2;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `test_hudi_flink2`(</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT SERDE </span><br><span class="line">  <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#x27;</span> </span><br><span class="line">STORED <span class="keyword">AS</span> INPUTFORMAT </span><br><span class="line">  <span class="string">&#x27;org.apache.hadoop.mapred.TextInputFormat&#x27;</span> </span><br><span class="line">OUTPUTFORMAT </span><br><span class="line">  <span class="string">&#x27;org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat&#x27;</span></span><br><span class="line">LOCATION</span><br><span class="line">  <span class="string">&#x27;hdfs://mycluster/user/hive/warehouse/test_hudi_flink2&#x27;</span></span><br><span class="line">TBLPROPERTIES (</span><br><span class="line">  <span class="string">&#x27;flink.comment&#x27;</span><span class="operator">=</span><span class="string">&#x27;&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.connector&#x27;</span><span class="operator">=</span><span class="string">&#x27;hudi&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.hoodie.datasource.write.hive_style_partitioning&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.hoodie.datasource.write.keygenerator.class&#x27;</span><span class="operator">=</span><span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.hoodie.datasource.write.recordkey.field&#x27;</span><span class="operator">=</span><span class="string">&#x27;uuid&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.partition.keys.0.name&#x27;</span><span class="operator">=</span><span class="string">&#x27;dt&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.path&#x27;</span><span class="operator">=</span><span class="string">&#x27;/hudi-warehouse/hudi-t2&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.0.data-type&#x27;</span><span class="operator">=</span><span class="string">&#x27;VARCHAR(20)&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.0.name&#x27;</span><span class="operator">=</span><span class="string">&#x27;uuid&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.1.data-type&#x27;</span><span class="operator">=</span><span class="string">&#x27;VARCHAR(10)&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.1.name&#x27;</span><span class="operator">=</span><span class="string">&#x27;name&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.2.data-type&#x27;</span><span class="operator">=</span><span class="string">&#x27;INT&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.2.name&#x27;</span><span class="operator">=</span><span class="string">&#x27;age&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.3.data-type&#x27;</span><span class="operator">=</span><span class="string">&#x27;TIMESTAMP(3)&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.3.name&#x27;</span><span class="operator">=</span><span class="string">&#x27;ts&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.4.data-type&#x27;</span><span class="operator">=</span><span class="string">&#x27;VARCHAR(20)&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;flink.schema.4.name&#x27;</span><span class="operator">=</span><span class="string">&#x27;dt&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;transient_lastDdlTime&#x27;</span><span class="operator">=</span><span class="string">&#x27;1667787388&#x27;</span>)</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.134</span> seconds, Fetched: <span class="number">29</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink2;</span><br><span class="line">FAILED: SemanticException Line <span class="number">0</span>:<span class="number">-1</span> Invalid <span class="keyword">column</span> reference <span class="string">&#x27;TOK_ALLCOLREF&#x27;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> partitions test_hudi_flink2;</span><br><span class="line">FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> <span class="keyword">from</span> org.apache.hadoop.hive.ql.exec.DDLTask. <span class="keyword">Table</span> test_hudi_flink2 <span class="keyword">is</span> <span class="keyword">not</span> a partitioned <span class="keyword">table</span></span><br><span class="line">hive<span class="operator">&gt;</span> </span><br></pre></td></tr></table></figure>

<h4 id="建在内存中-同步Hive表"><a href="#建在内存中-同步Hive表" class="headerlink" title="建在内存中,同步Hive表"></a>建在内存中,同步Hive表</h4><p>利用同步到Hive中的表,通过Hive SQL和Spark SQL查询,也可以利用Spark进行insert/update等.<br>Flink SQL客户端退出后,不能利用Hive中的表进行写数据,需要再重新建表.</p>
<h5 id="mor"><a href="#mor" class="headerlink" title="mor"></a>mor</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink3 (</span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `dt` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`dt`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t3&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;uuid&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.enable&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hms&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.metastore.uris&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;thrift://hadoop-sh1-core1:9083&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.conf.dir&#x27;</span><span class="operator">=</span><span class="string">&#x27;/opt/hive/conf&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.db&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.table&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test_hudi_flink3&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.partition_fields&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;dt&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.partition_extractor_class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.hive.HiveStylePartitionValueExtractor&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>配置环境变量<code>HIVE_CONF_DIR</code>.<br><code>HIVE_CONF_DIR</code>和<code>hive_sync.conf.dir</code>作用是一样的,如果没有配置<code>hive_sync.conf.dir</code>的话就会取<code>HIVE_CONF_DIR</code>,如果都没有配置,同步会有异常.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_CONF_DIR&#x3D;&#x2F;usr&#x2F;hdp&#x2F;3.1.0.0-78&#x2F;hive&#x2F;conf</span><br></pre></td></tr></table></figure>

<p>只有在写数据的时候才会触发同步Hive表.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink3 <span class="keyword">values</span> (<span class="string">&#x27;id1&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>),(<span class="string">&#x27;id3&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par2&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>可以看到在Hive库中生成了两张表test_hudi_flink3_ro/test_hudi_flink3_rt,这和使用Spark SQL同步的表是一样的,可以用Hive查询,也可以用Spark查询/写数据.</p>
<p>MOR表一开始没有生成parquet文件,在Hive里查询为空(RO/RT都为空),可以在SparkSQL里再插入几条数据,就可以查询出数据来了.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--spark sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink3_ro <span class="keyword">values</span> (<span class="string">&#x27;id2&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par3&#x27;</span>),(<span class="string">&#x27;id4&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par4&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink3_rt <span class="keyword">values</span> (<span class="string">&#x27;id5&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par5&#x27;</span>),(<span class="string">&#x27;id6&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par6&#x27;</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">desc</span> test_hudi_flink3_ro;</span><br><span class="line">OK</span><br><span class="line">_hoodie_commit_time   string                                    </span><br><span class="line">_hoodie_commit_seqno  string                                    </span><br><span class="line">_hoodie_record_key    string                                    </span><br><span class="line">_hoodie_partition_path  string                                    </span><br><span class="line">_hoodie_file_name     string                                    </span><br><span class="line">uuid                  string                                    </span><br><span class="line">name                  string                                    </span><br><span class="line">age                   <span class="type">int</span>                                       </span><br><span class="line">ts                    <span class="type">bigint</span>                                    </span><br><span class="line">dt                    string                                    </span><br><span class="line">     </span><br><span class="line"># <span class="keyword">Partition</span> Information    </span><br><span class="line"># col_name              data_type             comment             </span><br><span class="line">     </span><br><span class="line">dt                    string                                    </span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.069</span> seconds, Fetched: <span class="number">15</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">desc</span> test_hudi_flink3_rt;</span><br><span class="line">OK</span><br><span class="line">_hoodie_commit_time   string                                    </span><br><span class="line">_hoodie_commit_seqno  string                                    </span><br><span class="line">_hoodie_record_key    string                                    </span><br><span class="line">_hoodie_partition_path  string                                    </span><br><span class="line">_hoodie_file_name     string                                    </span><br><span class="line">uuid                  string                                    </span><br><span class="line">name                  string                                    </span><br><span class="line">age                   <span class="type">int</span>                                       </span><br><span class="line">ts                    <span class="type">bigint</span>                                    </span><br><span class="line">dt                    string                                    </span><br><span class="line">     </span><br><span class="line"># <span class="keyword">Partition</span> Information    </span><br><span class="line"># col_name              data_type             comment             </span><br><span class="line">     </span><br><span class="line">dt                    string                                    </span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.125</span> seconds, Fetched: <span class="number">15</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink3_ro;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.277</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink3_rt;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.154</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> </span><br></pre></td></tr></table></figure>

<img src="/images/fly1222.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>hive中查询不出数据,spark插入数据时异常信息如下,<br>Caused by: org.apache.hudi.hive.HoodieHiveSyncException: Could not convert field Type from BIGINT to TIMESTAMP for field ts<br>  at org.apache.hudi.hive.util.HiveSchemaUtil.getSchemaDifference(HiveSchemaUtil.java:109)<br>  at org.apache.hudi.hive.HiveSyncTool.syncSchema(HiveSyncTool.java:285)<br>  at org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:217)<br>  at org.apache.hudi.hive.HiveSyncTool.doSync(HiveSyncTool.java:158)<br>  at org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:142)</p>
<blockquote>
<p>关于Flink SQL和Spark SQL配置一致性问题:</p>
</blockquote>
<p>1.<code>hoodie.datasource.write.keygenerator.class</code><br>这里设置的为ComplexAvroKeyGenerator,也就是复合主键,原因是Fink SQL 默认值为SimpleKey,但是SparkSQL默认值SqlKeyGenerator,它是ComplexKeyGenerator,也就是默认值为复合主键,但是由于ComplexKeyGenerator在hudi-spark-client中,flink模块没有,所以flink中需要设置hudi-client-common中的ComplexAvroKeyGenerator即可保持一致性(如果keygenerator不一致会导致重复数据).<br>2.<code>hoodie.datasource.write.hive_style_partitioning</code><br>flink sql默认值为false,但是SparkSQL为true,所以这里设置为true.<br>3.<code>hive_sync.partition_extractor_class</code><br>SparkSQL中默认值为MultiPartKeysValueExtractor,对于本例中的字符串类型的分区字段是支持的,但是Flink SQL中的默认值为SlashEncodedDayPartitionValueExtractor,它要求分区字段必须是日期格式的,所以这里设置为HiveStylePartitionValueExtractor即可解决.<br>4.<code>hoodie.allow.operation.metadata.field</code><br>Flink支持这个配置项,当为true时,Hudi元数据字段中会多一个<code>_hoodie_operation</code>,但是目前Spark还不支持,所以对于这种,对于Flink SQL同步的Hive表,不能再通过Spark SQL写数据.</p>
<h5 id="cow"><a href="#cow" class="headerlink" title="cow"></a>cow</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink33 (</span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `dt` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`dt`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t33&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;COPY_ON_WRITE&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;uuid&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.enable&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hms&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.metastore.uris&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;thrift://hadoop-sh1-core1:9083&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.conf.dir&#x27;</span><span class="operator">=</span><span class="string">&#x27;/opt/hive/conf&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.db&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.table&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test_hudi_flink33&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.partition_fields&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;dt&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.partition_extractor_class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.hive.HiveStylePartitionValueExtractor&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>写数据触发同步Hive表.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink33 <span class="keyword">values</span> (<span class="string">&#x27;id1&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>),(<span class="string">&#x27;id3&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par2&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>因为COW表只有RT表,所以不会通过_rt来区分,同步的表名和配置的表名一致.<br>hive/spark查询数据/分区均正常.</p>
<img src="/images/fly1223.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1224.png" style="margin-left: 0px; padding-bottom: 10px;">

<h4 id="建在Hive-Catalog中-同步Hive表"><a href="#建在Hive-Catalog中-同步Hive表" class="headerlink" title="建在Hive Catalog中,同步Hive表"></a>建在Hive Catalog中,同步Hive表</h4><p>利用Hive Catalog中的表通过Flink SQL写数据,也可以利用同步的Hive表通过Hive SQL查询/Spark SQL读写.</p>
<h5 id="mor-1"><a href="#mor-1" class="headerlink" title="mor"></a>mor</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> CATALOG hive_catalog <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hive&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;default-database&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;default&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive-conf-dir&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/opt/hive/conf&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">use catalog hive_catalog;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink4 (</span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `dt` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`dt`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t4&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;uuid&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.enable&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hms&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.metastore.uris&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;thrift://hadoop-sh1-core1:9083&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.conf.dir&#x27;</span><span class="operator">=</span><span class="string">&#x27;/opt/hive/conf&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.db&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.table&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test_hudi_flink4&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.partition_fields&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;dt&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.partition_extractor_class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.hive.HiveStylePartitionValueExtractor&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>写数据触发同步Hive表.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink4 <span class="keyword">values</span> (<span class="string">&#x27;id1&#x27;</span>,<span class="string">&#x27;Danny&#x27;</span>,<span class="number">23</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par1&#x27;</span>),(<span class="string">&#x27;id3&#x27;</span>,<span class="string">&#x27;Julian&#x27;</span>,<span class="number">53</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:03&#x27;</span>,<span class="string">&#x27;par2&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>在Hive库中生成了三张表test_hudi_flink4/test_hudi_flink4_ro/test_hudi_flink4_rt,其中,<br>test_hudi_flink4是Flink格式的,不能用Hive查询,但是可以在Flink中写数据/查询数据.<br>test_hudi_flink4_ro/test_hudi_flink4_rt,可以用Hive查询,也可以用Spark查询/写数据.</p>
<p>其中hive中查询不出数据,spark中rt表可查询出数据.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink4_rt;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.253</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink4_ro;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.199</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> </span><br></pre></td></tr></table></figure>

<img src="/images/fly1225.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1226.png" style="margin-left: 0px; padding-bottom: 10px;">

<h5 id="cow-1"><a href="#cow-1" class="headerlink" title="cow"></a>cow</h5><p>对于COW表来说因为同步的表名没有<code>_rt</code>,也就是和Hive Catalog表名一样,需要区分出Hive Catalog表和同步的表名.<br>一种方式是修改<code>hive_sync.table</code>,另一种方式是Hive Catalog表和同步表保存在不同的Hive Database中.</p>
<h4 id="通过Hudi-HMS-Catalog读写Hudi并同步Hive表"><a href="#通过Hudi-HMS-Catalog读写Hudi并同步Hive表" class="headerlink" title="通过Hudi HMS Catalog读写Hudi并同步Hive表"></a>通过Hudi HMS Catalog读写Hudi并同步Hive表</h4><h5 id="创建Flink-Hudi-HMS-Catalog"><a href="#创建Flink-Hudi-HMS-Catalog" class="headerlink" title="创建Flink Hudi HMS Catalog"></a>创建Flink Hudi HMS Catalog</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> CATALOG hudi_catalog <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hms&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;default-database&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;default&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive.conf.dir&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/opt/hive/conf&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.external&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">--在Hive中创建数据库test_flink</span></span><br><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> hudi_catalog.test_flink;</span><br><span class="line"><span class="comment">--切换到数据库test_flink</span></span><br><span class="line">use hudi_catalog.test_flink;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Flink SQL&gt; show databases;</span><br><span class="line">+---------------+</span><br><span class="line">| database name |</span><br><span class="line">+---------------+</span><br><span class="line">|       default |</span><br><span class="line">|          test |</span><br><span class="line">|    test_flink |</span><br><span class="line">+---------------+</span><br><span class="line">3 rows in set</span><br></pre></td></tr></table></figure>

<p>支持的配置项:<br><a target="_blank" rel="noopener" href="https://hudi.apache.org/docs/table_management#flink">https://hudi.apache.org/docs/table_management#flink</a></p>
<p>和<code>hive catalog</code>的配置项差不多,只是type为hudi,这里mode必须是hms,默认值是dfs.<br><code>hive catalog</code>中的配置项为<code>hive-conf-dir</code>,但是hudi的为<code>hive.conf.dir</code>.<br><code>table.external</code>是否为外部表,默认false,也就是默认内部表.</p>
<p>mode默认值为dfs,只有mode为hms时,才会使用HoodieHiveCatalog.</p>
<img src="/images/fly1227.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1228.png" style="margin-left: 0px; padding-bottom: 10px;">

<h5 id="mor-2"><a href="#mor-2" class="headerlink" title="mor"></a>mor</h5><p>使用catalog时path可以不用指定,不指定的话,路径就是<code>Hive库路径+表名</code>.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink_mor (</span><br><span class="line">  id <span class="type">int</span> <span class="keyword">PRIMARY</span> KEY <span class="keyword">NOT</span> ENFORCED,</span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  price <span class="type">int</span>,</span><br><span class="line">  ts <span class="type">int</span>,</span><br><span class="line">  dt <span class="type">VARCHAR</span>(<span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (dt)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t5&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;id&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.conf.dir&#x27;</span><span class="operator">=</span><span class="string">&#x27;/opt/hive/conf&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink_mor <span class="keyword">values</span> (<span class="number">1</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="/images/fly1229.png" style="margin-left: 0px; padding-bottom: 10px;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">default</span></span><br><span class="line">test</span><br><span class="line">test_flink</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.018</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> use test_flink;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.043</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">test_hudi_flink_mor</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.023</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink_mor;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.333</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">test_hudi_flink_mor</span><br><span class="line">test_hudi_flink_mor_ro</span><br><span class="line">test_hudi_flink_mor_rt</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.054</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink_mor;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.272</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink_mor_ro;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.376</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_hudi_flink_mor_rt;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.241</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> </span><br></pre></td></tr></table></figure>

<img src="/images/fly1230.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1231.png" style="margin-left: 0px; padding-bottom: 10px;">

<h5 id="cow-2"><a href="#cow-2" class="headerlink" title="cow"></a>cow</h5><p>未指定path.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_hudi_flink_cow (</span><br><span class="line">  id <span class="type">int</span> <span class="keyword">PRIMARY</span> KEY <span class="keyword">NOT</span> ENFORCED,</span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  price <span class="type">int</span>,</span><br><span class="line">  ts <span class="type">int</span>,</span><br><span class="line">  dt <span class="type">VARCHAR</span>(<span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (dt)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.keygenerator.class&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;org.apache.hudi.keygen.ComplexAvroKeyGenerator&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;id&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.hive_style_partitioning&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hive_sync.conf.dir&#x27;</span><span class="operator">=</span><span class="string">&#x27;/opt/hive/conf&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<img src="/images/fly1232.png" style="margin-left: 0px; padding-bottom: 10px;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--flink sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink_cow <span class="keyword">values</span> (<span class="number">1</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="/images/fly1235.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1233.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1234.png" style="margin-left: 0px; padding-bottom: 10px;">

<h5 id="一致性验证"><a href="#一致性验证" class="headerlink" title="一致性验证"></a>一致性验证</h5><p>通过Spark SQL分别往每个表写几条数据,再用Spark/Hive/Flink查询.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink_mor <span class="keyword">values</span> (<span class="number">3</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink_mor_ro <span class="keyword">values</span> (<span class="number">4</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink_mor_rt <span class="keyword">values</span> (<span class="number">5</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_hudi_flink_cow <span class="keyword">values</span> (<span class="number">3</span>,<span class="string">&#x27;hudi&#x27;</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="string">&#x27;2022-10-31&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="/images/fly1236.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1237.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1238.png" style="margin-left: 0px; padding-bottom: 10px;">

<img src="/images/fly1239.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1240.png" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="流式查询"><a href="#流式查询" class="headerlink" title="流式查询"></a>流式查询</h3><p>Flink插入Hudi表数据时,支持以流的方式加载数据,增量查询分析.<br>如果想要在给定的提交之后进行所有更改,不需要指定 endTime.</p>
<h4 id="创建表-1"><a href="#创建表-1" class="headerlink" title="创建表"></a>创建表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t2(</span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>) <span class="keyword">PRIMARY</span> KEY <span class="keyword">NOT</span> ENFORCED,</span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `<span class="keyword">partition</span>` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`<span class="keyword">partition</span>`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;read.tasks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;read.streaming.enabled&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,  <span class="comment">-- this option enable the streaming read</span></span><br><span class="line">  <span class="string">&#x27;read.start-commit&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;20210316134557&#x27;</span>, <span class="comment">-- specifies the start commit instant time</span></span><br><span class="line">  <span class="string">&#x27;read.streaming.check-interval&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;4&#x27;</span> <span class="comment">-- specifies the check interval for finding new source commits, default 60s.</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>这将给出<code>read.streaming.start-commit</code>提交后发生的所有更改.</p>
<p>核心参数选项说明:</p>
<ol>
<li>read.streaming.enabled<br>设置为 true,表明通过 streaming 的方式读取表数据.</li>
<li>read.streaming.check-interval<br>指定了 source 监控新的 commits 的间隔为 4s.</li>
<li>table.type:<br>设置表类型为 MERGE_ON_READ.</li>
</ol>
<h4 id="查询数据-1"><a href="#查询数据-1" class="headerlink" title="查询数据"></a>查询数据</h4><p>创建表t2 以后,此时表的数据就是前面批Batch模式写入的数据.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t2 ;</span><br></pre></td></tr></table></figure>

<p>插入显示表中所有数据,光标在一直闪动,每隔4秒,再依据commit timestamp增量查询.</p>
<img src="/images/fly1125.png" style="margin-left: 0px; padding-bottom: 10px;">

<h4 id="插入数据-1"><a href="#插入数据-1" class="headerlink" title="插入数据"></a>插入数据</h4><p>重新开启Terminal启动Flink SQL CLI,重新创建表t1,采用批Batch模式插入1条数据.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1(</span><br><span class="line">  uuid <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  age <span class="type">INT</span>,</span><br><span class="line">  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  `<span class="keyword">partition</span>` <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (`<span class="keyword">partition</span>`)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/hudi-t1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;write.tasks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;compaction.tasks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span> (<span class="string">&#x27;id9&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="number">27</span>,<span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01&#x27;</span>,<span class="string">&#x27;par5&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>几秒后在流表中可以读取到一条新增的数据(前面插入的一条数据).</p>
<img src="/images/fly1126.png" style="margin-left: 0px; padding-bottom: 10px;">

<h4 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h4><p>在流式查询中消费数据时,Hudi Flink 源也可以接受来自底层数据源的更改日志,然后可以按行级别应用 <code>UPDATE</code> 和 <code>DELETE</code>.<br>然后,您可以在 Hudi 上为各种 RDBMS 同步 NEAR-REAL-TIME 快照.</p>
<h2 id="java"><a href="#java" class="headerlink" title="java"></a>java</h2><h3 id="设置-1"><a href="#设置-1" class="headerlink" title="设置"></a>设置</h3><p>添加依赖项.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Flink 1.13 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hudi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hudi-flink1.13-bundle<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Flink 1.14 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hudi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hudi-flink1.14-bundle<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Flink 1.15 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hudi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hudi-flink1.15-bundle<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="插入数据-2"><a href="#插入数据-2" class="headerlink" title="插入数据"></a>插入数据</h3><p>首先创建一个 Flink Hudi 表,并使用 DataStream API 将数据插入到 Hudi 表中.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.data.RowData;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.common.model.HoodieTableType;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.configuration.FlinkOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.util.HoodiePipeline;</span><br><span class="line"></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">String targetTable = <span class="string">&quot;t1&quot;</span>;</span><br><span class="line">String basePath = <span class="string">&quot;file:///tmp/t1&quot;</span>;</span><br><span class="line"></span><br><span class="line">Map&lt;String, String&gt; options = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">options.put(FlinkOptions.PATH.key(), basePath);</span><br><span class="line">options.put(FlinkOptions.TABLE_TYPE.key(), HoodieTableType.MERGE_ON_READ.name());</span><br><span class="line">options.put(FlinkOptions.PRECOMBINE_FIELD.key(), <span class="string">&quot;ts&quot;</span>);</span><br><span class="line"></span><br><span class="line">DataStream&lt;RowData&gt; dataStream = env.addSource(...);</span><br><span class="line">HoodiePipeline.Builder builder = HoodiePipeline.builder(targetTable)</span><br><span class="line">    .column(<span class="string">&quot;uuid VARCHAR(20)&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;name VARCHAR(10)&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;age INT&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;ts TIMESTAMP(3)&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;`partition` VARCHAR(20)&quot;</span>)</span><br><span class="line">    .pk(<span class="string">&quot;uuid&quot;</span>)</span><br><span class="line">    .partition(<span class="string">&quot;partition&quot;</span>)</span><br><span class="line">    .options(options);</span><br><span class="line"></span><br><span class="line">builder.sink(dataStream, <span class="keyword">false</span>); <span class="comment">// The second parameter indicating whether the input data stream is bounded</span></span><br><span class="line">env.execute(<span class="string">&quot;Api_Sink&quot;</span>);</span><br></pre></td></tr></table></figure>

<h3 id="查询数据-2"><a href="#查询数据-2" class="headerlink" title="查询数据"></a>查询数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.data.RowData;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.common.model.HoodieTableType;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.configuration.FlinkOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.util.HoodiePipeline;</span><br><span class="line"></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">String targetTable = <span class="string">&quot;t1&quot;</span>;</span><br><span class="line">String basePath = <span class="string">&quot;file:///tmp/t1&quot;</span>;</span><br><span class="line"></span><br><span class="line">Map&lt;String, String&gt; options = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">options.put(FlinkOptions.PATH.key(), basePath);</span><br><span class="line">options.put(FlinkOptions.TABLE_TYPE.key(), HoodieTableType.MERGE_ON_READ.name());</span><br><span class="line">options.put(FlinkOptions.READ_AS_STREAMING.key(), <span class="string">&quot;true&quot;</span>); <span class="comment">// this option enable the streaming read</span></span><br><span class="line">options.put(FlinkOptions.READ_START_COMMIT.key(), <span class="string">&quot;&#x27;20210316134557&#x27;&quot;</span>); <span class="comment">// specifies the start commit instant time</span></span><br><span class="line">    </span><br><span class="line">HoodiePipeline.Builder builder = HoodiePipeline.builder(targetTable)</span><br><span class="line">    .column(<span class="string">&quot;uuid VARCHAR(20)&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;name VARCHAR(10)&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;age INT&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;ts TIMESTAMP(3)&quot;</span>)</span><br><span class="line">    .column(<span class="string">&quot;`partition` VARCHAR(20)&quot;</span>)</span><br><span class="line">    .pk(<span class="string">&quot;uuid&quot;</span>)</span><br><span class="line">    .partition(<span class="string">&quot;partition&quot;</span>)</span><br><span class="line">    .options(options);</span><br><span class="line"></span><br><span class="line">DataStream&lt;RowData&gt; rowDataDataStream = builder.source(env);</span><br><span class="line">rowDataDataStream.print();</span><br><span class="line">env.execute(<span class="string">&quot;Api_Source&quot;</span>);</span><br></pre></td></tr></table></figure>

<h1 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h1><p>从Kafka消费数据,将数据保存值Hudi表中,查询Hudi表数据.</p>
<h2 id="sql-1"><a href="#sql-1" class="headerlink" title="sql"></a>sql</h2><p>首先创建输入表:从Kafka消费数据,其次编写SQL提取字段值,再创建输出表:将数据保存值Hudi表中,最后编写SQL查询Hudi表数据.</p>
<h3 id="创建表-2"><a href="#创建表-2" class="headerlink" title="创建表"></a>创建表</h3><p>创建输入表,关联Kafka Topic.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 输入表:Kafka Source</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> order_kafka_source (</span><br><span class="line">  orderId STRING,</span><br><span class="line">  userId STRING,</span><br><span class="line">  orderTime STRING,</span><br><span class="line">  ip STRING,</span><br><span class="line">  orderMoney <span class="keyword">DOUBLE</span>,</span><br><span class="line">  orderStatus <span class="type">INT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi-demo&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;oceanbase004:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;gid-1001&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;json.fail-on-missing-field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;false&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> orderId, userId, orderTime, ip, orderMoney, orderStatus <span class="keyword">FROM</span> order_kafka_source ;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1128.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>创建输出表,保存数据至Hudi表,设置相关属性.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> order_hudi_sink (</span><br><span class="line">  orderId STRING <span class="keyword">PRIMARY</span> KEY <span class="keyword">NOT</span> ENFORCED,</span><br><span class="line">  userId STRING,</span><br><span class="line">  orderTime STRING,</span><br><span class="line">  ip STRING,</span><br><span class="line">  orderMoney <span class="keyword">DOUBLE</span>,</span><br><span class="line">  orderStatus <span class="type">INT</span>,</span><br><span class="line">  ts STRING,</span><br><span class="line">  partition_day STRING</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (partition_day) </span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hudi&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;/hudi-warehouse/order_hudi_sink&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;table.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;MERGE_ON_READ&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;write.operation&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;upsert&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hoodie.datasource.write.recordkey.field&#x27;</span><span class="operator">=</span> <span class="string">&#x27;orderId&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;write.precombine.field&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;ts&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;write.tasks&#x27;</span><span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;compaction.tasks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;compaction.async.enabled&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;compaction.trigger.strategy&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;num_commits&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;compaction.delta_commits&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<h3 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h3><p>处理获取Kafka消息数据,提取字段值.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">  orderId, userId, orderTime, ip, orderMoney, orderStatus, </span><br><span class="line">  <span class="built_in">substring</span>(orderId, <span class="number">0</span>, <span class="number">17</span>) <span class="keyword">AS</span> ts, <span class="built_in">substring</span>(orderTime, <span class="number">0</span>, <span class="number">10</span>) <span class="keyword">AS</span> partition_day </span><br><span class="line"><span class="keyword">FROM</span> order_kafka_source ;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1129.png" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="写入hudi"><a href="#写入hudi" class="headerlink" title="写入hudi"></a>写入hudi</h3><p>开启flink checkpoint.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="string">&#x27;execution.checkpointing.interval&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10s&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>使用INSERT INTO语句,将数据保存Hudi表.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 子查询插入INSERT ... SELECT ...</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> order_hudi_sink </span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  orderId, userId, orderTime, ip, orderMoney, orderStatus,</span><br><span class="line">  <span class="built_in">substring</span>(orderId, <span class="number">0</span>, <span class="number">17</span>) <span class="keyword">AS</span> ts, <span class="built_in">substring</span>(orderTime, <span class="number">0</span>, <span class="number">10</span>) <span class="keyword">AS</span> partition_day </span><br><span class="line"><span class="keyword">FROM</span> order_kafka_source ;</span><br></pre></td></tr></table></figure>

<p>此时,提交Flink Job运行在FlinkStandalone集群上.</p>
<img src="/images/fly1074.png" style="margin-left: 0px; padding-bottom: 10px;">
<img src="/images/fly1075.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>只要运行模拟交易订单数据程序,就会将数据发送到Kafka,最后转换保存至Hudi表.</p>
<h3 id="查询数据-3"><a href="#查询数据-3" class="headerlink" title="查询数据"></a>查询数据</h3><p>编写SELECT语句,查询Hudi表交易订单数据.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询Hudi表数据</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> order_hudi_sink;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1186.png" style="margin-left: 0px; padding-bottom: 10px;">

<h2 id="java-1"><a href="#java-1" class="headerlink" title="java"></a>java</h2><p>实时从Kafka消费Topic数据,解析转换后,存储至Hudi表中.</p>
<h3 id="pom"><a href="#pom" class="headerlink" title="pom"></a>pom</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hudi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hudi-flink1.15-bundle<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hudi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hudi-hadoop-mr-bundle<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-shaded-hadoop-2-uber<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.5-10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="写入hudi-1"><a href="#写入hudi-1" class="headerlink" title="写入hudi"></a>写入hudi</h3><p>从Kafka消费数据,转换后,保存到Hudi表.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.$;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkSQLHudiDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1-获取表执行环境</span></span><br><span class="line">    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    env.setParallelism(<span class="number">1</span>);</span><br><span class="line">    env.enableCheckpointing(<span class="number">5000</span>);</span><br><span class="line">    EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">        .newInstance()</span><br><span class="line">        .inStreamingMode()</span><br><span class="line">        .build();</span><br><span class="line">    StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2-创建输入表,从Kafka消费数据</span></span><br><span class="line">    tableEnv.executeSql(</span><br><span class="line">        <span class="string">&quot;CREATE TABLE order_kafka_source (\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderId STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  userId STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderTime STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  ip STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderMoney DOUBLE,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderStatus INT\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;) WITH (\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;connector&#x27; = &#x27;kafka&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;topic&#x27; = &#x27;hudi-demo&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;properties.bootstrap.servers&#x27; = &#x27;oceanbase004:9092&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;properties.group.id&#x27; = &#x27;gid-1001&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;scan.startup.mode&#x27; = &#x27;latest-offset&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;format&#x27; = &#x27;json&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;json.fail-on-missing-field&#x27; = &#x27;false&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;json.ignore-parse-errors&#x27; = &#x27;true&#x27;\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;)&quot;</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3-数据转换:提取订单时间中订单日期,作为Hudi表分区字段值</span></span><br><span class="line">    Table etlTable = tableEnv</span><br><span class="line">        .from(<span class="string">&quot;order_kafka_source&quot;</span>)</span><br><span class="line">        .addColumns(</span><br><span class="line">            $(<span class="string">&quot;orderId&quot;</span>).substring(<span class="number">0</span>, <span class="number">17</span>).as(<span class="string">&quot;ts&quot;</span>)</span><br><span class="line">        )</span><br><span class="line">        .addColumns(</span><br><span class="line">            $(<span class="string">&quot;orderTime&quot;</span>).substring(<span class="number">0</span>, <span class="number">10</span>).as(<span class="string">&quot;partition_day&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">    tableEnv.createTemporaryView(<span class="string">&quot;view_order&quot;</span>, etlTable);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4-定义输出表,数据保存到Hudi表中</span></span><br><span class="line">    tableEnv.executeSql(</span><br><span class="line">        <span class="string">&quot;CREATE TABLE order_hudi_sink (\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderId STRING PRIMARY KEY NOT ENFORCED,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  userId STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderTime STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  ip STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderMoney DOUBLE,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderStatus INT,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  ts STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  partition_day STRING\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;)\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;PARTITIONED BY (partition_day) \n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;WITH (\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;connector&#x27; = &#x27;hudi&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;path&#x27; = &#x27;/flink_hudi_order&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;table.type&#x27; = &#x27;MERGE_ON_READ&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;write.operation&#x27; = &#x27;upsert&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;hoodie.datasource.write.recordkey.field&#x27; = &#x27;orderId&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;write.precombine.field&#x27; = &#x27;ts&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;write.tasks&#x27;= &#x27;1&#x27;\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;)&quot;</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5-通过子查询方式,将数据写入输出表</span></span><br><span class="line">    tableEnv.executeSql(</span><br><span class="line">        <span class="string">&quot;INSERT INTO order_hudi_sink\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;SELECT\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderId, userId, orderTime, ip, orderMoney, orderStatus, ts, partition_day\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;FROM view_order&quot;</span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行上述编写流式程序,查看本地文件系统目录,保存Hudi表数据结构信息.</p>
<img src="/images/fly1073.png" style="margin-left: 0px; padding-bottom: 10px;">

<p>将core/hdfs-site.xml添加到resources目录下,数据将写入到hdfs.</p>
<img src="/images/fly1127.png" style="margin-left: 0px; padding-bottom: 10px;">

<h3 id="查询数据-4"><a href="#查询数据-4" class="headerlink" title="查询数据"></a>查询数据</h3><p>加载Hudi表中数据,采用流式方式读取,同样创建表,映射关联到Hudi表数据存储目录中.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkSQLReadDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2-创建输入表,加载Hudi表查询数据</span></span><br><span class="line">    tableEnv.executeSql(</span><br><span class="line">        <span class="string">&quot;CREATE TABLE order_hudi(\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderId STRING PRIMARY KEY NOT ENFORCED,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  userId STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderTime STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  ip STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderMoney DOUBLE,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderStatus INT,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  ts STRING,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  partition_day STRING\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;)\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;PARTITIONED BY (partition_day)\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;WITH (\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;connector&#x27; = &#x27;hudi&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;path&#x27; = &#x27;/flink_hudi_order&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;table.type&#x27; = &#x27;MERGE_ON_READ&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;read.streaming.enabled&#x27; = &#x27;true&#x27;,\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  &#x27;read.streaming.check-interval&#x27; = &#x27;4&#x27;\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;)&quot;</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3-通过子查询方式,将数据写入输出表</span></span><br><span class="line">    tableEnv.executeSql(</span><br><span class="line">        <span class="string">&quot;SELECT \n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;  orderId, userId, orderTime, ip, orderMoney, orderStatus, ts ,partition_day \n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;FROM order_hudi&quot;</span></span><br><span class="line">    ).print();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="/images/fly1187.png" style="margin-left: 0px; padding-bottom: 10px;">


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/flink/" rel="tag"># flink</a>
              <a href="/tags/hudi/" rel="tag"># hudi</a>
              <a href="/tags/hive/" rel="tag"># hive</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/10/17/redis%20try/" rel="prev" title="redis try">
                  <i class="fa fa-chevron-left"></i> redis try
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/17/hudi%E7%BC%96%E8%AF%91/" rel="next" title="hudi编译">
                  hudi编译 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maoeryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  





</body>
</html>
